{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f934c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "#from keybert import KeyBERT\n",
    "import yake\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a613e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sds_text = pd.read_csv('../data/sds_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a299939b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>guest_info</th>\n",
       "      <th>text_episode</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_day</th>\n",
       "      <th>host_episode</th>\n",
       "      <th>speaker</th>\n",
       "      <th>episode_split_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Kirill</td>\n",
       "      <td>This is episode number one with ex-chemical e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Kirill</td>\n",
       "      <td>Hey guys, welcome to the Podcast. I’ve got Ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Ruben</td>\n",
       "      <td>Thank you! Thanks for having me over. I’m doi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Kirill</td>\n",
       "      <td>Awesome. It’s great to hear you and for those...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Ruben</td>\n",
       "      <td>Yeah sure. So, I’m the senior manager of anal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       episode_name  \\\n",
       "0           0   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "1           0   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "2           0   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "3           0   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "4           0   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "\n",
       "   length_episode                 context_episode     guest_name  \\\n",
       "0              42  Business Data Science Database   Ruben Kogel    \n",
       "1              42  Business Data Science Database   Ruben Kogel    \n",
       "2              42  Business Data Science Database   Ruben Kogel    \n",
       "3              42  Business Data Science Database   Ruben Kogel    \n",
       "4              42  Business Data Science Database   Ruben Kogel    \n",
       "\n",
       "                                          guest_info  \\\n",
       "0  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "1  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "2  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "3  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "4  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "\n",
       "                                        text_episode  episode_number  \\\n",
       "0  Kirill: This is episode number one with ex-che...               1   \n",
       "1  Kirill: This is episode number one with ex-che...               1   \n",
       "2  Kirill: This is episode number one with ex-che...               1   \n",
       "3  Kirill: This is episode number one with ex-che...               1   \n",
       "4  Kirill: This is episode number one with ex-che...               1   \n",
       "\n",
       "   episode_date episode_day     host_episode speaker  \\\n",
       "0  Sep 10, 2016    Saturday  Kirril Eremenko  Kirill   \n",
       "1  Sep 10, 2016    Saturday  Kirril Eremenko  Kirill   \n",
       "2  Sep 10, 2016    Saturday  Kirril Eremenko   Ruben   \n",
       "3  Sep 10, 2016    Saturday  Kirril Eremenko  Kirill   \n",
       "4  Sep 10, 2016    Saturday  Kirril Eremenko   Ruben   \n",
       "\n",
       "                                  episode_split_text  \n",
       "0   This is episode number one with ex-chemical e...  \n",
       "1   Hey guys, welcome to the Podcast. I’ve got Ru...  \n",
       "2   Thank you! Thanks for having me over. I’m doi...  \n",
       "3   Awesome. It’s great to hear you and for those...  \n",
       "4   Yeah sure. So, I’m the senior manager of anal...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds_text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36542acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text = sds_text.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d8088d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sds_processed = pd.DataFrame(sds_text.groupby(['episode_number', 'episode_name', 'length_episode', 'context_episode', 'guest_name', 'host_episode', 'episode_date'])['episode_split_text'].agg(lambda x: ' '.join(x))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b732d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the text \n",
    "def processed_text(text):  \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation from the text\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Remove digits from the text\n",
    "    text = ''.join(char for char in text if not char.isdigit())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1d358c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_split_text'] = sds_processed['episode_split_text'].apply(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c52fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>host_episode</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_split_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>this is episode number one with exchemical en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Machine Learning, Recommender Systems and the...</td>\n",
       "      <td>51</td>\n",
       "      <td>Machine Learning Data Science</td>\n",
       "      <td>Hadelin de Ponteves</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 14, 2016</td>\n",
       "      <td>this is session number two with machine learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Defining the Data Problem, Data Science in Ma...</td>\n",
       "      <td>53</td>\n",
       "      <td>Machine Learning R Programming Data Science</td>\n",
       "      <td>Dr. Wilson Pok</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 25, 2016</td>\n",
       "      <td>this is episode number three with nanophysics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data and Strategy, three Pillars of Research ...</td>\n",
       "      <td>60</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Brendan Hogan</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Oct 02, 2016</td>\n",
       "      <td>this is episode four with business strategy e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Computer Forensics, Fraud Analytics and knowi...</td>\n",
       "      <td>63</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Dmitry Korneev</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Oct 09, 2016</td>\n",
       "      <td>this is episode number five with forensics inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>679</td>\n",
       "      <td>The A.I. and Machine Learning Landscape, with...</td>\n",
       "      <td>94</td>\n",
       "      <td>Business Data Science Artificial Intelligence</td>\n",
       "      <td>George Mathew</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 16, 2023</td>\n",
       "      <td>this is episode number  with george matthew ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>680</td>\n",
       "      <td>Automating Industrial Machines with Data Scie...</td>\n",
       "      <td>30</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Allegra Alessi</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 19, 2023</td>\n",
       "      <td>this is episode number  with allegra alessi io...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>681</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>72</td>\n",
       "      <td>Machine Learning Data Science Python</td>\n",
       "      <td>Matt Harrison</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 23, 2023</td>\n",
       "      <td>this is episode number  with matt harrison man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>682</td>\n",
       "      <td>Business Intelligence Tools, with Mico Yuk</td>\n",
       "      <td>28</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Mico Yuk</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>this is episode number  with mico yuk host of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>683</td>\n",
       "      <td>Contextual A.I. for Adapting to Adversaries, ...</td>\n",
       "      <td>81</td>\n",
       "      <td>Data Science Artificial Intelligence</td>\n",
       "      <td>Matar Haller</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 30, 2023</td>\n",
       "      <td>this is episode number  with dr matar haller v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     episode_number                                       episode_name  \\\n",
       "0                 1   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "1                 2   Machine Learning, Recommender Systems and the...   \n",
       "2                 3   Defining the Data Problem, Data Science in Ma...   \n",
       "3                 4   Data and Strategy, three Pillars of Research ...   \n",
       "4                 5   Computer Forensics, Fraud Analytics and knowi...   \n",
       "..              ...                                                ...   \n",
       "675             679   The A.I. and Machine Learning Landscape, with...   \n",
       "676             680   Automating Industrial Machines with Data Scie...   \n",
       "677             681                                            XGBoost   \n",
       "678             682         Business Intelligence Tools, with Mico Yuk   \n",
       "679             683   Contextual A.I. for Adapting to Adversaries, ...   \n",
       "\n",
       "     length_episode                                context_episode  \\\n",
       "0                42                 Business Data Science Database   \n",
       "1                51                  Machine Learning Data Science   \n",
       "2                53    Machine Learning R Programming Data Science   \n",
       "3                60                          Business Data Science   \n",
       "4                63                                   Data Science   \n",
       "..              ...                                            ...   \n",
       "675              94  Business Data Science Artificial Intelligence   \n",
       "676              30                          Business Data Science   \n",
       "677              72           Machine Learning Data Science Python   \n",
       "678              28                          Business Data Science   \n",
       "679              81           Data Science Artificial Intelligence   \n",
       "\n",
       "                guest_name     host_episode  episode_date  \\\n",
       "0             Ruben Kogel   Kirril Eremenko  Sep 10, 2016   \n",
       "1     Hadelin de Ponteves   Kirril Eremenko  Sep 14, 2016   \n",
       "2          Dr. Wilson Pok   Kirril Eremenko  Sep 25, 2016   \n",
       "3           Brendan Hogan   Kirril Eremenko  Oct 02, 2016   \n",
       "4          Dmitry Korneev   Kirril Eremenko  Oct 09, 2016   \n",
       "..                     ...              ...           ...   \n",
       "675         George Mathew         Jon Krohn  May 16, 2023   \n",
       "676        Allegra Alessi         Jon Krohn  May 19, 2023   \n",
       "677         Matt Harrison         Jon Krohn  May 23, 2023   \n",
       "678              Mico Yuk         Jon Krohn  May 26, 2023   \n",
       "679          Matar Haller         Jon Krohn  May 30, 2023   \n",
       "\n",
       "                                    episode_split_text  \n",
       "0     this is episode number one with exchemical en...  \n",
       "1     this is session number two with machine learn...  \n",
       "2    this is episode number three with nanophysics ...  \n",
       "3     this is episode four with business strategy e...  \n",
       "4    this is episode number five with forensics inv...  \n",
       "..                                                 ...  \n",
       "675  this is episode number  with george matthew ma...  \n",
       "676  this is episode number  with allegra alessi io...  \n",
       "677  this is episode number  with matt harrison man...  \n",
       "678  this is episode number  with mico yuk host of ...  \n",
       "679  this is episode number  with dr matar haller v...  \n",
       "\n",
       "[680 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2881ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate 100 keywords per episode using Yake library\n",
    "\n",
    "def yake_keyword_extractor(doc):\n",
    "    global sds_processed\n",
    "\n",
    "    for i, episode_text in doc.iteritems():\n",
    "        max_ngram_size = 3\n",
    "        deduplication_threshold = 0.3\n",
    "        windowSize = 1\n",
    "        numOfKeywords = 100\n",
    "        kw_extractor = yake.KeywordExtractor(n=max_ngram_size, dedupLim=deduplication_threshold, windowsSize=windowSize, top=numOfKeywords)\n",
    "        keywords = kw_extractor.extract_keywords(episode_text)\n",
    "\n",
    "        # Create separate columns for each keyword\n",
    "        for j, keyword in enumerate(keywords):\n",
    "            column_name = f'episode_keyword{j+1}'\n",
    "            sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f95ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n"
     ]
    }
   ],
   "source": [
    "yake_keyword_extractor(sds_processed['episode_split_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yake_keyword_extractor(doc):\n",
    "    global sds_processed\n",
    "    \n",
    "    for i, episode_text in doc.iteritems():\n",
    "        max_ngram_size = 3\n",
    "        deduplication_threshold = 0.3\n",
    "        windowSize = 1\n",
    "        numOfKeywords = 100\n",
    "        kw_extractor = yake.KeywordExtractor(n = max_ngram_size, dedupLim = deduplication_threshold , windowsSize = windowSize, top = numOfKeywords)\n",
    "        keywords = kw_extractor.extract_keywords(episode_text)\n",
    "        sds_processed.at[i, 'episode_keywords'] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "yake_keyword_extractor(sds_processed['episode_split_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411bb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a229cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_keywords'].loc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c759df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b64772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_processed.to_csv('../data/sds_yake_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273410ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_keywords = pd.read_csv('../data/sds_yake_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39719cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1 = sds_processed[sds_processed['episode_number'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36759c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['episode_keywords'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075992e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['keywords'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_extractor(row):\n",
    "    words = [t[0] for t in row]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['keywords'] = sds_processed['episode_keywords'].apply(tuple_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88da21c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sds_processed['keywords'].loc[677])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f18f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d444fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['episode_keywords'].apply(lambda x: tuple_extractor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a24ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecebb391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_extractor(word_tuples):\n",
    "    global sds_1\n",
    "    words = [t[0] for t in word_tuples]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b42861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'] = sds_1['episode_keywords'].apply(lambda x: tuple_extractor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3361d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'] = sds_1['episode_keywords'].apply(tuple_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_extractor(tuple):\n",
    "    global sds_keywords\n",
    "    words = []\n",
    "    #for i, episode_text in doc.iteritems():\n",
    "    for i, word_tuple in tuple.iteritems():\n",
    "        words = [t[0] for t in word_tuple]\n",
    "        sds_keywords['keywords'] = words\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49255973",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_keywords['episode_keywords'].apply(tuple_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b4d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c80ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'] = sds_1['episode_keywords'].apply(tuple_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1295cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t[0] for t in sds_1['episode_keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabdd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_keywords'] = [t[0] for t in sds_processed['episode_keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54633f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f04dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_keywords'].loc[678]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de4b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doca = sds_processed['episode_split_text'].loc[1]\n",
    "docb = sds_processed['episode_split_text'].loc[150]\n",
    "docc = sds_processed['episode_split_text'].loc[400]\n",
    "docd = sds_processed['episode_split_text'].loc[679]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_extractor(doc):\n",
    "    kw_model = KeyBERT()\n",
    "    global sds_processed\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    \n",
    "    for i, episode_text in doc.iteritems():\n",
    "        keywords = kw_model.extract_keywords(episode_text, keyphrase_ngram_range=(1, 1), stop_words = stopwords, top_n = 100, use_mmr=True, diversity=0.7)\n",
    "        sds_processed.at[i, 'episode_keywords'] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce178cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()\n",
    "stopwords = list(STOP_WORDS)\n",
    "keywords = kw_model.extract_keywords(doca, keyphrase_ngram_range=(1, 2), stop_words = stopwords, top_n = 100, use_mmr=True, diversity=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e849c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_extractor(sds_processed['episode_split_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6229dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d02cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_processed['episode_split_text'][1:5].apply(keyword_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe33bc54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c26d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://maartengr.github.io/BERTopic/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
