{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f934c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "#from keybert import KeyBERT\n",
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a613e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text = pd.read_csv('../data/sds_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3573316",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text = sds_text.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed = pd.DataFrame(sds_text.groupby(['episode_number', 'episode_name', 'length_episode', 'context_episode', 'guest_name', 'host_episode', 'episode_date'])['episode_split_text'].agg(lambda x: ' '.join(x))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58bb85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic function to clean the text \n",
    "def clean_text(text):     \n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447cf30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_split_text'] = sds_processed['episode_split_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d241ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3944c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_keywords'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yake_keyword_extractor(doc):\n",
    "    global sds_processed\n",
    "    \n",
    "    for i, episode_text in doc.iteritems():\n",
    "        max_ngram_size = 3\n",
    "        deduplication_threshold = 0.3\n",
    "        windowSize = 1\n",
    "        numOfKeywords = 100\n",
    "        kw_extractor = yake.KeywordExtractor(n = max_ngram_size, dedupLim = deduplication_threshold , windowsSize = windowSize, top = numOfKeywords)\n",
    "        keywords = kw_extractor.extract_keywords(episode_text)\n",
    "        sds_processed.at[i, 'episode_keywords'] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "yake_keyword_extractor(sds_processed['episode_split_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed.to_csv('../data/sds_yake_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b38f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sds_keywords = pd.read_csv('../data/sds_yake_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602f05fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>host_episode</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_split_text</th>\n",
       "      <th>episode_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>this is episode number one with ex-chemical e...</td>\n",
       "      <td>[('data', 0.0010532908775940833), ('data scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Machine Learning, Recommender Systems and the...</td>\n",
       "      <td>51</td>\n",
       "      <td>Machine Learning Data Science</td>\n",
       "      <td>Hadelin de Ponteves</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 14, 2016</td>\n",
       "      <td>this is session number two with machine learn...</td>\n",
       "      <td>[('machine learning', 0.000631846276923455), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Defining the Data Problem, Data Science in Ma...</td>\n",
       "      <td>53</td>\n",
       "      <td>Machine Learning R Programming Data Science</td>\n",
       "      <td>Dr. Wilson Pok</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 25, 2016</td>\n",
       "      <td>this is episode number three with nanophysics ...</td>\n",
       "      <td>[('data', 0.0016868502795001298), ('lot', 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Data and Strategy, three Pillars of Research ...</td>\n",
       "      <td>60</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Brendan Hogan</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Oct 02, 2016</td>\n",
       "      <td>this is episode four with business strategy e...</td>\n",
       "      <td>[('data', 0.001790873287731643), ('research', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Computer Forensics, Fraud Analytics and knowi...</td>\n",
       "      <td>63</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Dmitry Korneev</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Oct 09, 2016</td>\n",
       "      <td>this is episode number five with forensics inv...</td>\n",
       "      <td>[('data', 0.0017176889343680037), ('yeah', 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>675</td>\n",
       "      <td>679</td>\n",
       "      <td>The A.I. and Machine Learning Landscape, with...</td>\n",
       "      <td>94</td>\n",
       "      <td>Business Data Science Artificial Intelligence</td>\n",
       "      <td>George Mathew</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 16, 2023</td>\n",
       "      <td>this is episode number 679 with george matthew...</td>\n",
       "      <td>[('data', 0.0024952473539939482), ('models', 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>676</td>\n",
       "      <td>680</td>\n",
       "      <td>Automating Industrial Machines with Data Scie...</td>\n",
       "      <td>30</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Allegra Alessi</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 19, 2023</td>\n",
       "      <td>this is episode number 680 with allegra alessi...</td>\n",
       "      <td>[('product owner', 0.0034842819203336774), ('d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>677</td>\n",
       "      <td>681</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>72</td>\n",
       "      <td>Machine Learning Data Science Python</td>\n",
       "      <td>Matt Harrison</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 23, 2023</td>\n",
       "      <td>this is episode number 681 with matt harrison,...</td>\n",
       "      <td>[('data', 0.0016667966735911916), ('xgboost', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>678</td>\n",
       "      <td>682</td>\n",
       "      <td>Business Intelligence Tools, with Mico Yuk</td>\n",
       "      <td>28</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Mico Yuk</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>this is episode number 682 with mico yuk, host...</td>\n",
       "      <td>[('yeah', 0.003595094849223796), ('data', 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>679</td>\n",
       "      <td>683</td>\n",
       "      <td>Contextual A.I. for Adapting to Adversaries, ...</td>\n",
       "      <td>81</td>\n",
       "      <td>Data Science Artificial Intelligence</td>\n",
       "      <td>Matar Haller</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 30, 2023</td>\n",
       "      <td>this is episode number 683 with dr. matar hall...</td>\n",
       "      <td>[('sort', 0.0030308098144709197), ('basically'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  episode_number  \\\n",
       "0             0               1   \n",
       "1             1               2   \n",
       "2             2               3   \n",
       "3             3               4   \n",
       "4             4               5   \n",
       "..          ...             ...   \n",
       "675         675             679   \n",
       "676         676             680   \n",
       "677         677             681   \n",
       "678         678             682   \n",
       "679         679             683   \n",
       "\n",
       "                                          episode_name  length_episode  \\\n",
       "0     Ruben Kogel on Self-Serve Analytics, R vs Pyt...              42   \n",
       "1     Machine Learning, Recommender Systems and the...              51   \n",
       "2     Defining the Data Problem, Data Science in Ma...              53   \n",
       "3     Data and Strategy, three Pillars of Research ...              60   \n",
       "4     Computer Forensics, Fraud Analytics and knowi...              63   \n",
       "..                                                 ...             ...   \n",
       "675   The A.I. and Machine Learning Landscape, with...              94   \n",
       "676   Automating Industrial Machines with Data Scie...              30   \n",
       "677                                            XGBoost              72   \n",
       "678         Business Intelligence Tools, with Mico Yuk              28   \n",
       "679   Contextual A.I. for Adapting to Adversaries, ...              81   \n",
       "\n",
       "                                   context_episode             guest_name  \\\n",
       "0                   Business Data Science Database           Ruben Kogel    \n",
       "1                    Machine Learning Data Science   Hadelin de Ponteves    \n",
       "2      Machine Learning R Programming Data Science        Dr. Wilson Pok    \n",
       "3                            Business Data Science         Brendan Hogan    \n",
       "4                                     Data Science        Dmitry Korneev    \n",
       "..                                             ...                    ...   \n",
       "675  Business Data Science Artificial Intelligence         George Mathew    \n",
       "676                          Business Data Science        Allegra Alessi    \n",
       "677           Machine Learning Data Science Python         Matt Harrison    \n",
       "678                          Business Data Science              Mico Yuk    \n",
       "679           Data Science Artificial Intelligence          Matar Haller    \n",
       "\n",
       "        host_episode  episode_date  \\\n",
       "0    Kirril Eremenko  Sep 10, 2016   \n",
       "1    Kirril Eremenko  Sep 14, 2016   \n",
       "2    Kirril Eremenko  Sep 25, 2016   \n",
       "3    Kirril Eremenko  Oct 02, 2016   \n",
       "4    Kirril Eremenko  Oct 09, 2016   \n",
       "..               ...           ...   \n",
       "675        Jon Krohn  May 16, 2023   \n",
       "676        Jon Krohn  May 19, 2023   \n",
       "677        Jon Krohn  May 23, 2023   \n",
       "678        Jon Krohn  May 26, 2023   \n",
       "679        Jon Krohn  May 30, 2023   \n",
       "\n",
       "                                    episode_split_text  \\\n",
       "0     this is episode number one with ex-chemical e...   \n",
       "1     this is session number two with machine learn...   \n",
       "2    this is episode number three with nanophysics ...   \n",
       "3     this is episode four with business strategy e...   \n",
       "4    this is episode number five with forensics inv...   \n",
       "..                                                 ...   \n",
       "675  this is episode number 679 with george matthew...   \n",
       "676  this is episode number 680 with allegra alessi...   \n",
       "677  this is episode number 681 with matt harrison,...   \n",
       "678  this is episode number 682 with mico yuk, host...   \n",
       "679  this is episode number 683 with dr. matar hall...   \n",
       "\n",
       "                                      episode_keywords  \n",
       "0    [('data', 0.0010532908775940833), ('data scien...  \n",
       "1    [('machine learning', 0.000631846276923455), (...  \n",
       "2    [('data', 0.0016868502795001298), ('lot', 0.00...  \n",
       "3    [('data', 0.001790873287731643), ('research', ...  \n",
       "4    [('data', 0.0017176889343680037), ('yeah', 0.0...  \n",
       "..                                                 ...  \n",
       "675  [('data', 0.0024952473539939482), ('models', 0...  \n",
       "676  [('product owner', 0.0034842819203336774), ('d...  \n",
       "677  [('data', 0.0016667966735911916), ('xgboost', ...  \n",
       "678  [('yeah', 0.003595094849223796), ('data', 0.00...  \n",
       "679  [('sort', 0.0030308098144709197), ('basically'...  \n",
       "\n",
       "[680 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1 = sds_keywords[sds_keywords['episode_number'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a3924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['episode_keywords'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tuples = [('data', 0.0010532908775940833), ('data scientist', 0.0029141325644050945), ('people', 0.005422867923900782), ('n’t', 0.006871265577956575), ('’re', 0.008884744001205683), ('analysis', 0.01281082680029214), ('udemy', 0.016638427011567425), ('thing', 0.018489819573940445), ('work', 0.026106167845171176), ('ruben', 0.028702291819461337), ('build', 0.03003168690508715), ('team', 0.032220440860286116), ('show', 0.040495101361532), ('question', 0.04063280878564204), ('make', 0.04448616608751784), ('important', 0.04568613147206454), ('insights', 0.050842033371277406), ('powerful', 0.05251763498491655), ('sql', 0.059737659259588516), ('listeners', 0.060455501278664454), ('red shift', 0.06452519251510098), ('background', 0.06521651854598134), ('sensitive data', 0.06798193640183485), ('elemental data problems', 0.06808923752012126), ('totally', 0.07980158442301752), ('end', 0.09462167394867813), ('communication skills', 0.09901294474504588), ('engineering', 0.1135042667193427), ('platform', 0.1139030943265721), ('statistical', 0.11869365178842255), ('influence', 0.11922058764723066), ('project', 0.12777923082182785), ('science wizard', 0.1361525255478297), ('convey', 0.1427370340547599), ('job', 0.14407934432290917), ('episode', 0.14483249042899463), ('n’t wanna work', 0.15254512892072472), ('problem solving thing', 0.16422008206512995), ('’ve learned', 0.16981820700395897), ('pretty cool', 0.17067999701657272), ('size', 0.1821297897355906), ('people who specialize', 0.18974036853129833), ('explain', 0.19046069125821452), ('ability', 0.19388868834551098), ('aws', 0.19481837195406812), ('articles', 0.21889215391276715), ('ruben kogel.welcome', 0.2383267121932403), ('strategy', 0.26597500290820864), ('leverage', 0.26943937566389226), ('push', 0.2706788376330779), ('check', 0.2745931680444767), ('fact', 0.27542786666192787), ('breiman', 0.27573806523021577), ('’re quickly', 0.2869003093342987), ('metric', 0.39239618738482207), ('discussed lots', 0.4224813160987914), ('jump', 0.42569932503668617), ('biggest', 0.43062024110563135), ('scalable', 0.4348002572368825), ('summary', 0.43507210437225546), ('half', 0.43566181067001614), ('view', 0.43632798500045983), ('advanced', 0.43821567421603597), ('trustworthy', 0.43914585044899046), ('behavior', 0.44014923866039657), ('ex-chemical engineer', 0.47417419541876416), ('yeah yeah', 0.47748801172975774), ('efficient analytics team', 0.49106273295984), ('techniques you ’re', 0.5568305258185692), ('translate a lot', 0.6642515176584556), ('stakeholders coming', 0.6709457645693998), ('lots of regression', 0.7080528578956833), ('noise by nate', 0.7367804020215138), ('thing in communication', 0.74777341131578), ('good idea', 0.8026798733239394), ('measuring student', 0.8130853605951406), ('off.', 0.8512416854015954), ('guys', 0.869753315936046), ('glad', 0.8775854997392524), ('blog', 0.8785492259628155), ('skills nevertheless. yeah', 0.8870029931682176), ('touched', 0.9085820192716929), ('self-served', 0.9085820192716929), ('width', 0.9201510701708244), ('director', 0.9205577391019704), ('one.the', 0.9235531647655699), ('fix', 0.9279796911765633), ('anymore', 0.9293875146481567), ('uhuh', 0.9299820716737279), ('prioritized', 0.93152190035003), ('graphics', 0.9323728330400206), ('occur', 0.9328737183606961), ('stuff', 0.9333168252017048), ('10-12', 0.9340346598369818), ('necessarily', 0.9353005575308527), ('divisions in udemy', 0.9430098537561858), ('analytics and predictive', 1.1000320353744777), ('complex technical', 1.1592371306994007), ('kirill eremenko', 1.1877887135345484), ('kicking things off.', 1.2619808102396495)]\n",
    "\n",
    "words = [t[0] for t in word_tuples]\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "785e5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_extractor(tuple):\n",
    "    global sds_keywords\n",
    "    words = []\n",
    "    for word_tuple in tuple:\n",
    "        words = [t[0] for t in word_tuples]\n",
    "        return words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6eb42eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tuples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sds_keywords[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeywords\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msds_keywords\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepisode_keywords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuple_extractor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36mtuple_extractor\u001b[0;34m(tuple)\u001b[0m\n\u001b[1;32m      3\u001b[0m words \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word_tuple \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m     words \u001b[38;5;241m=\u001b[39m [t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[43mword_tuples\u001b[49m]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m words\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_tuples' is not defined"
     ]
    }
   ],
   "source": [
    "sds_keywords['keywords'] = sds_keywords['episode_keywords'].apply(tuple_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e263b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'] = sds_1['episode_keywords'].apply(tuple_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3156cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t[0] for t in sds_1['episode_keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f28d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_keywords'] = [t[0] for t in sds_processed['episode_keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f68db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2848d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_keywords'].loc[678]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb32dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doca = sds_processed['episode_split_text'].loc[1]\n",
    "docb = sds_processed['episode_split_text'].loc[150]\n",
    "docc = sds_processed['episode_split_text'].loc[400]\n",
    "docd = sds_processed['episode_split_text'].loc[679]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_extractor(doc):\n",
    "    kw_model = KeyBERT()\n",
    "    global sds_processed\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    \n",
    "    for i, episode_text in doc.iteritems():\n",
    "        keywords = kw_model.extract_keywords(episode_text, keyphrase_ngram_range=(1, 1), stop_words = stopwords, top_n = 100, use_mmr=True, diversity=0.7)\n",
    "        sds_processed.at[i, 'episode_keywords'] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a301758",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()\n",
    "stopwords = list(STOP_WORDS)\n",
    "keywords = kw_model.extract_keywords(doca, keyphrase_ngram_range=(1, 2), stop_words = stopwords, top_n = 100, use_mmr=True, diversity=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e849c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_extractor(sds_processed['episode_split_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_processed['episode_split_text'][1:5].apply(keyword_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faace0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ac90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://maartengr.github.io/BERTopic/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
