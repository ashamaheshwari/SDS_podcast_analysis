{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f934c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "#from keybert import KeyBERT\n",
    "import yake\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a613e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sds_text = pd.read_csv('../data/sds_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a299939b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>guest_info</th>\n",
       "      <th>text_episode</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_day</th>\n",
       "      <th>host_episode</th>\n",
       "      <th>speaker</th>\n",
       "      <th>episode_split_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Kirill</td>\n",
       "      <td>This is episode number one with ex-chemical e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Kirill</td>\n",
       "      <td>Hey guys, welcome to the Podcast. I’ve got Ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Ruben</td>\n",
       "      <td>Thank you! Thanks for having me over. I’m doi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Kirill</td>\n",
       "      <td>Awesome. It’s great to hear you and for those...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Ruben</td>\n",
       "      <td>Yeah sure. So, I’m the senior manager of anal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       episode_name  \\\n",
       "0           0   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "1           0   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "2           0   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "3           0   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "4           0   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "\n",
       "   length_episode                 context_episode     guest_name  \\\n",
       "0              42  Business Data Science Database   Ruben Kogel    \n",
       "1              42  Business Data Science Database   Ruben Kogel    \n",
       "2              42  Business Data Science Database   Ruben Kogel    \n",
       "3              42  Business Data Science Database   Ruben Kogel    \n",
       "4              42  Business Data Science Database   Ruben Kogel    \n",
       "\n",
       "                                          guest_info  \\\n",
       "0  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "1  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "2  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "3  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "4  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "\n",
       "                                        text_episode  episode_number  \\\n",
       "0  Kirill: This is episode number one with ex-che...               1   \n",
       "1  Kirill: This is episode number one with ex-che...               1   \n",
       "2  Kirill: This is episode number one with ex-che...               1   \n",
       "3  Kirill: This is episode number one with ex-che...               1   \n",
       "4  Kirill: This is episode number one with ex-che...               1   \n",
       "\n",
       "   episode_date episode_day     host_episode speaker  \\\n",
       "0  Sep 10, 2016    Saturday  Kirril Eremenko  Kirill   \n",
       "1  Sep 10, 2016    Saturday  Kirril Eremenko  Kirill   \n",
       "2  Sep 10, 2016    Saturday  Kirril Eremenko   Ruben   \n",
       "3  Sep 10, 2016    Saturday  Kirril Eremenko  Kirill   \n",
       "4  Sep 10, 2016    Saturday  Kirril Eremenko   Ruben   \n",
       "\n",
       "                                  episode_split_text  \n",
       "0   This is episode number one with ex-chemical e...  \n",
       "1   Hey guys, welcome to the Podcast. I’ve got Ru...  \n",
       "2   Thank you! Thanks for having me over. I’m doi...  \n",
       "3   Awesome. It’s great to hear you and for those...  \n",
       "4   Yeah sure. So, I’m the senior manager of anal...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds_text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3628d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text = sds_text.set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d8088d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sds_processed = pd.DataFrame(sds_text.groupby(['episode_number', 'episode_name', 'length_episode', 'context_episode', 'guest_name', 'host_episode', 'episode_date'])['episode_split_text'].agg(lambda x: ' '.join(x))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "826d945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the text \n",
    "def processed_text(text):  \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation from the text\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Remove digits from the text\n",
    "    text = ''.join(char for char in text if not char.isdigit())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876eba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_split_text'] = sds_processed['episode_split_text'].apply(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "313aef64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>host_episode</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_split_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>this is episode number one with exchemical en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Machine Learning, Recommender Systems and the...</td>\n",
       "      <td>51</td>\n",
       "      <td>Machine Learning Data Science</td>\n",
       "      <td>Hadelin de Ponteves</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 14, 2016</td>\n",
       "      <td>this is session number two with machine learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Defining the Data Problem, Data Science in Ma...</td>\n",
       "      <td>53</td>\n",
       "      <td>Machine Learning R Programming Data Science</td>\n",
       "      <td>Dr. Wilson Pok</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 25, 2016</td>\n",
       "      <td>this is episode number three with nanophysics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data and Strategy, three Pillars of Research ...</td>\n",
       "      <td>60</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Brendan Hogan</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Oct 02, 2016</td>\n",
       "      <td>this is episode four with business strategy e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Computer Forensics, Fraud Analytics and knowi...</td>\n",
       "      <td>63</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Dmitry Korneev</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Oct 09, 2016</td>\n",
       "      <td>this is episode number five with forensics inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>679</td>\n",
       "      <td>The A.I. and Machine Learning Landscape, with...</td>\n",
       "      <td>94</td>\n",
       "      <td>Business Data Science Artificial Intelligence</td>\n",
       "      <td>George Mathew</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 16, 2023</td>\n",
       "      <td>this is episode number  with george matthew ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>680</td>\n",
       "      <td>Automating Industrial Machines with Data Scie...</td>\n",
       "      <td>30</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Allegra Alessi</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 19, 2023</td>\n",
       "      <td>this is episode number  with allegra alessi io...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>681</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>72</td>\n",
       "      <td>Machine Learning Data Science Python</td>\n",
       "      <td>Matt Harrison</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 23, 2023</td>\n",
       "      <td>this is episode number  with matt harrison man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>682</td>\n",
       "      <td>Business Intelligence Tools, with Mico Yuk</td>\n",
       "      <td>28</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Mico Yuk</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>this is episode number  with mico yuk host of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>683</td>\n",
       "      <td>Contextual A.I. for Adapting to Adversaries, ...</td>\n",
       "      <td>81</td>\n",
       "      <td>Data Science Artificial Intelligence</td>\n",
       "      <td>Matar Haller</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 30, 2023</td>\n",
       "      <td>this is episode number  with dr matar haller v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     episode_number                                       episode_name  \\\n",
       "0                 1   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "1                 2   Machine Learning, Recommender Systems and the...   \n",
       "2                 3   Defining the Data Problem, Data Science in Ma...   \n",
       "3                 4   Data and Strategy, three Pillars of Research ...   \n",
       "4                 5   Computer Forensics, Fraud Analytics and knowi...   \n",
       "..              ...                                                ...   \n",
       "675             679   The A.I. and Machine Learning Landscape, with...   \n",
       "676             680   Automating Industrial Machines with Data Scie...   \n",
       "677             681                                            XGBoost   \n",
       "678             682         Business Intelligence Tools, with Mico Yuk   \n",
       "679             683   Contextual A.I. for Adapting to Adversaries, ...   \n",
       "\n",
       "     length_episode                                context_episode  \\\n",
       "0                42                 Business Data Science Database   \n",
       "1                51                  Machine Learning Data Science   \n",
       "2                53    Machine Learning R Programming Data Science   \n",
       "3                60                          Business Data Science   \n",
       "4                63                                   Data Science   \n",
       "..              ...                                            ...   \n",
       "675              94  Business Data Science Artificial Intelligence   \n",
       "676              30                          Business Data Science   \n",
       "677              72           Machine Learning Data Science Python   \n",
       "678              28                          Business Data Science   \n",
       "679              81           Data Science Artificial Intelligence   \n",
       "\n",
       "                guest_name     host_episode  episode_date  \\\n",
       "0             Ruben Kogel   Kirril Eremenko  Sep 10, 2016   \n",
       "1     Hadelin de Ponteves   Kirril Eremenko  Sep 14, 2016   \n",
       "2          Dr. Wilson Pok   Kirril Eremenko  Sep 25, 2016   \n",
       "3           Brendan Hogan   Kirril Eremenko  Oct 02, 2016   \n",
       "4          Dmitry Korneev   Kirril Eremenko  Oct 09, 2016   \n",
       "..                     ...              ...           ...   \n",
       "675         George Mathew         Jon Krohn  May 16, 2023   \n",
       "676        Allegra Alessi         Jon Krohn  May 19, 2023   \n",
       "677         Matt Harrison         Jon Krohn  May 23, 2023   \n",
       "678              Mico Yuk         Jon Krohn  May 26, 2023   \n",
       "679          Matar Haller         Jon Krohn  May 30, 2023   \n",
       "\n",
       "                                    episode_split_text  \n",
       "0     this is episode number one with exchemical en...  \n",
       "1     this is session number two with machine learn...  \n",
       "2    this is episode number three with nanophysics ...  \n",
       "3     this is episode four with business strategy e...  \n",
       "4    this is episode number five with forensics inv...  \n",
       "..                                                 ...  \n",
       "675  this is episode number  with george matthew ma...  \n",
       "676  this is episode number  with allegra alessi io...  \n",
       "677  this is episode number  with matt harrison man...  \n",
       "678  this is episode number  with mico yuk host of ...  \n",
       "679  this is episode number  with dr matar haller v...  \n",
       "\n",
       "[680 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b19a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>host_episode</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_split_text</th>\n",
       "      <th>episode_keyword1</th>\n",
       "      <th>episode_keyword2</th>\n",
       "      <th>...</th>\n",
       "      <th>episode_keyword91</th>\n",
       "      <th>episode_keyword92</th>\n",
       "      <th>episode_keyword93</th>\n",
       "      <th>episode_keyword94</th>\n",
       "      <th>episode_keyword95</th>\n",
       "      <th>episode_keyword96</th>\n",
       "      <th>episode_keyword97</th>\n",
       "      <th>episode_keyword98</th>\n",
       "      <th>episode_keyword99</th>\n",
       "      <th>episode_keyword100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>Career transitioning to Data Science</td>\n",
       "      <td>58</td>\n",
       "      <td>Data Science Database</td>\n",
       "      <td>Virginia Mendonca</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>May 18, 2017</td>\n",
       "      <td>this is episode number  with aspiring data sci...</td>\n",
       "      <td>data science</td>\n",
       "      <td>find meaningful data</td>\n",
       "      <td>...</td>\n",
       "      <td>analytics what triggered</td>\n",
       "      <td>podcast we talked</td>\n",
       "      <td>long way dreams</td>\n",
       "      <td>tips</td>\n",
       "      <td>mendonca</td>\n",
       "      <td>long</td>\n",
       "      <td>flow</td>\n",
       "      <td>overview</td>\n",
       "      <td>asked</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    episode_number                           episode_name  length_episode  \\\n",
       "52              53   Career transitioning to Data Science              58   \n",
       "\n",
       "          context_episode           guest_name     host_episode  episode_date  \\\n",
       "52  Data Science Database   Virginia Mendonca   Kirril Eremenko  May 18, 2017   \n",
       "\n",
       "                                   episode_split_text episode_keyword1  \\\n",
       "52  this is episode number  with aspiring data sci...     data science   \n",
       "\n",
       "        episode_keyword2  ...         episode_keyword91  episode_keyword92  \\\n",
       "52  find meaningful data  ...  analytics what triggered  podcast we talked   \n",
       "\n",
       "   episode_keyword93 episode_keyword94 episode_keyword95 episode_keyword96  \\\n",
       "52   long way dreams              tips          mendonca              long   \n",
       "\n",
       "   episode_keyword97 episode_keyword98 episode_keyword99 episode_keyword100  \n",
       "52              flow          overview             asked            helpful  \n",
       "\n",
       "[1 rows x 108 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds_processed[sds_processed['episode_number'] == 53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ec5498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate 100 keywords per episode using Yake library\n",
    "\n",
    "def yake_keyword_extractor(doc):\n",
    "    global sds_processed\n",
    "\n",
    "    for i, episode_text in doc.iteritems():\n",
    "        max_ngram_size = 3\n",
    "        deduplication_threshold = 0.3\n",
    "        windowSize = 1\n",
    "        numOfKeywords = 100\n",
    "        kw_extractor = yake.KeywordExtractor(n=max_ngram_size, dedupLim=deduplication_threshold, windowsSize=windowSize, top=numOfKeywords)\n",
    "        keywords = kw_extractor.extract_keywords(episode_text)\n",
    "\n",
    "        # Create separate columns for each keyword\n",
    "        for j, keyword in enumerate(keywords):\n",
    "            column_name = f'episode_keyword{j+1}'\n",
    "            sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4294932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_12016/3233365722.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  sds_processed.at[i, column_name] = keyword[0]  # Store the keyword value in the respective column\n"
     ]
    }
   ],
   "source": [
    "yake_keyword_extractor(sds_processed['episode_split_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df4ace1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>host_episode</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_split_text</th>\n",
       "      <th>episode_keyword1</th>\n",
       "      <th>episode_keyword2</th>\n",
       "      <th>...</th>\n",
       "      <th>episode_keyword91</th>\n",
       "      <th>episode_keyword92</th>\n",
       "      <th>episode_keyword93</th>\n",
       "      <th>episode_keyword94</th>\n",
       "      <th>episode_keyword95</th>\n",
       "      <th>episode_keyword96</th>\n",
       "      <th>episode_keyword97</th>\n",
       "      <th>episode_keyword98</th>\n",
       "      <th>episode_keyword99</th>\n",
       "      <th>episode_keyword100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>this is episode number one with exchemical en...</td>\n",
       "      <td>data science</td>\n",
       "      <td>elemental data problems</td>\n",
       "      <td>...</td>\n",
       "      <td>physics and chemistry</td>\n",
       "      <td>successes you ’ll</td>\n",
       "      <td>size</td>\n",
       "      <td>episode</td>\n",
       "      <td>explain</td>\n",
       "      <td>typical for data</td>\n",
       "      <td>metrics</td>\n",
       "      <td>agree i ’ve</td>\n",
       "      <td>inflow</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Machine Learning, Recommender Systems and the...</td>\n",
       "      <td>51</td>\n",
       "      <td>Machine Learning Data Science</td>\n",
       "      <td>Hadelin de Ponteves</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 14, 2016</td>\n",
       "      <td>this is session number two with machine learn...</td>\n",
       "      <td>machine learning machine</td>\n",
       "      <td>data data science</td>\n",
       "      <td>...</td>\n",
       "      <td>check</td>\n",
       "      <td>ago</td>\n",
       "      <td>super</td>\n",
       "      <td>company</td>\n",
       "      <td>life</td>\n",
       "      <td>forward</td>\n",
       "      <td>todaybefore we continue</td>\n",
       "      <td>corpus of text</td>\n",
       "      <td>apparently a required</td>\n",
       "      <td>musk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Defining the Data Problem, Data Science in Ma...</td>\n",
       "      <td>53</td>\n",
       "      <td>Machine Learning R Programming Data Science</td>\n",
       "      <td>Dr. Wilson Pok</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Sep 25, 2016</td>\n",
       "      <td>this is episode number three with nanophysics ...</td>\n",
       "      <td>data science podcast</td>\n",
       "      <td>approach data science</td>\n",
       "      <td>...</td>\n",
       "      <td>buzz passwords</td>\n",
       "      <td>show</td>\n",
       "      <td>number</td>\n",
       "      <td>run</td>\n",
       "      <td>stayed in touchnow</td>\n",
       "      <td>emotions involved</td>\n",
       "      <td>nitty gritty</td>\n",
       "      <td>transferable skillsbut</td>\n",
       "      <td>changemy gut</td>\n",
       "      <td>truethere is prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data and Strategy, three Pillars of Research ...</td>\n",
       "      <td>60</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Brendan Hogan</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Oct 02, 2016</td>\n",
       "      <td>this is episode four with business strategy e...</td>\n",
       "      <td>data scientist role</td>\n",
       "      <td>research youre working</td>\n",
       "      <td>...</td>\n",
       "      <td>keen</td>\n",
       "      <td>ago</td>\n",
       "      <td>stuff</td>\n",
       "      <td>hard to communicate</td>\n",
       "      <td>python</td>\n",
       "      <td>analyst</td>\n",
       "      <td>view</td>\n",
       "      <td>happy</td>\n",
       "      <td>kirill</td>\n",
       "      <td>cmos the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Computer Forensics, Fraud Analytics and knowi...</td>\n",
       "      <td>63</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Dmitry Korneev</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Oct 09, 2016</td>\n",
       "      <td>this is episode number five with forensics inv...</td>\n",
       "      <td>unstructured data analytics</td>\n",
       "      <td>data analytics techniques</td>\n",
       "      <td>...</td>\n",
       "      <td>stay current</td>\n",
       "      <td>term</td>\n",
       "      <td>show</td>\n",
       "      <td>step</td>\n",
       "      <td>machine</td>\n",
       "      <td>today</td>\n",
       "      <td>key</td>\n",
       "      <td>music</td>\n",
       "      <td>brisbane</td>\n",
       "      <td>recover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>679</td>\n",
       "      <td>The A.I. and Machine Learning Landscape, with...</td>\n",
       "      <td>94</td>\n",
       "      <td>Business Data Science Artificial Intelligence</td>\n",
       "      <td>George Mathew</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 16, 2023</td>\n",
       "      <td>this is episode number  with george matthew ma...</td>\n",
       "      <td>product market fit</td>\n",
       "      <td>large language models</td>\n",
       "      <td>...</td>\n",
       "      <td>gpt cell</td>\n",
       "      <td>case</td>\n",
       "      <td>tremendous innovation</td>\n",
       "      <td>show</td>\n",
       "      <td>aka gpt</td>\n",
       "      <td>humanmachine symbiosis</td>\n",
       "      <td>weeks ago</td>\n",
       "      <td>media profiles</td>\n",
       "      <td>weve</td>\n",
       "      <td>gonna occur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>680</td>\n",
       "      <td>Automating Industrial Machines with Data Scie...</td>\n",
       "      <td>30</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Allegra Alessi</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 19, 2023</td>\n",
       "      <td>this is episode number  with allegra alessi io...</td>\n",
       "      <td>product owner role</td>\n",
       "      <td>data scienceoriented product</td>\n",
       "      <td>...</td>\n",
       "      <td>episode</td>\n",
       "      <td>paris</td>\n",
       "      <td>explanation very easy</td>\n",
       "      <td>alessivery very fun</td>\n",
       "      <td>concept of factory</td>\n",
       "      <td>ago</td>\n",
       "      <td>depends</td>\n",
       "      <td>edge</td>\n",
       "      <td>back</td>\n",
       "      <td>key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>681</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>72</td>\n",
       "      <td>Machine Learning Data Science Python</td>\n",
       "      <td>Matt Harrison</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 23, 2023</td>\n",
       "      <td>this is episode number  with matt harrison man...</td>\n",
       "      <td>xgboost model yeah</td>\n",
       "      <td>decision tree models</td>\n",
       "      <td>...</td>\n",
       "      <td>golf clubs</td>\n",
       "      <td>speed issue</td>\n",
       "      <td>high probability</td>\n",
       "      <td>thinking skills</td>\n",
       "      <td>shap directly</td>\n",
       "      <td>mistakesyour golf</td>\n",
       "      <td>harrison manytime</td>\n",
       "      <td>convenient wrappers</td>\n",
       "      <td>episodematt harrisonyeah</td>\n",
       "      <td>individuals teams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>682</td>\n",
       "      <td>Business Intelligence Tools, with Mico Yuk</td>\n",
       "      <td>28</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Mico Yuk</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>this is episode number  with mico yuk host of ...</td>\n",
       "      <td>yeah yeah yeah</td>\n",
       "      <td>data storytelling framework</td>\n",
       "      <td>...</td>\n",
       "      <td>put</td>\n",
       "      <td>guess</td>\n",
       "      <td>quickly</td>\n",
       "      <td>amazing</td>\n",
       "      <td>hey</td>\n",
       "      <td>time</td>\n",
       "      <td>medium the output</td>\n",
       "      <td>connectivity with azure</td>\n",
       "      <td>portfolio of research</td>\n",
       "      <td>kagan from appsumo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>683</td>\n",
       "      <td>Contextual A.I. for Adapting to Adversaries, ...</td>\n",
       "      <td>81</td>\n",
       "      <td>Data Science Artificial Intelligence</td>\n",
       "      <td>Matar Haller</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>May 30, 2023</td>\n",
       "      <td>this is episode number  with dr matar haller v...</td>\n",
       "      <td>insight data science</td>\n",
       "      <td>data model basically</td>\n",
       "      <td>...</td>\n",
       "      <td>mentioned potentially</td>\n",
       "      <td>great answer</td>\n",
       "      <td>rich understanding</td>\n",
       "      <td>show</td>\n",
       "      <td>decision</td>\n",
       "      <td>surprised i guess</td>\n",
       "      <td>audio text</td>\n",
       "      <td>fellowship program</td>\n",
       "      <td>super</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     episode_number                                       episode_name  \\\n",
       "0                 1   Ruben Kogel on Self-Serve Analytics, R vs Pyt...   \n",
       "1                 2   Machine Learning, Recommender Systems and the...   \n",
       "2                 3   Defining the Data Problem, Data Science in Ma...   \n",
       "3                 4   Data and Strategy, three Pillars of Research ...   \n",
       "4                 5   Computer Forensics, Fraud Analytics and knowi...   \n",
       "..              ...                                                ...   \n",
       "675             679   The A.I. and Machine Learning Landscape, with...   \n",
       "676             680   Automating Industrial Machines with Data Scie...   \n",
       "677             681                                            XGBoost   \n",
       "678             682         Business Intelligence Tools, with Mico Yuk   \n",
       "679             683   Contextual A.I. for Adapting to Adversaries, ...   \n",
       "\n",
       "     length_episode                                context_episode  \\\n",
       "0                42                 Business Data Science Database   \n",
       "1                51                  Machine Learning Data Science   \n",
       "2                53    Machine Learning R Programming Data Science   \n",
       "3                60                          Business Data Science   \n",
       "4                63                                   Data Science   \n",
       "..              ...                                            ...   \n",
       "675              94  Business Data Science Artificial Intelligence   \n",
       "676              30                          Business Data Science   \n",
       "677              72           Machine Learning Data Science Python   \n",
       "678              28                          Business Data Science   \n",
       "679              81           Data Science Artificial Intelligence   \n",
       "\n",
       "                guest_name     host_episode  episode_date  \\\n",
       "0             Ruben Kogel   Kirril Eremenko  Sep 10, 2016   \n",
       "1     Hadelin de Ponteves   Kirril Eremenko  Sep 14, 2016   \n",
       "2          Dr. Wilson Pok   Kirril Eremenko  Sep 25, 2016   \n",
       "3           Brendan Hogan   Kirril Eremenko  Oct 02, 2016   \n",
       "4          Dmitry Korneev   Kirril Eremenko  Oct 09, 2016   \n",
       "..                     ...              ...           ...   \n",
       "675         George Mathew         Jon Krohn  May 16, 2023   \n",
       "676        Allegra Alessi         Jon Krohn  May 19, 2023   \n",
       "677         Matt Harrison         Jon Krohn  May 23, 2023   \n",
       "678              Mico Yuk         Jon Krohn  May 26, 2023   \n",
       "679          Matar Haller         Jon Krohn  May 30, 2023   \n",
       "\n",
       "                                    episode_split_text  \\\n",
       "0     this is episode number one with exchemical en...   \n",
       "1     this is session number two with machine learn...   \n",
       "2    this is episode number three with nanophysics ...   \n",
       "3     this is episode four with business strategy e...   \n",
       "4    this is episode number five with forensics inv...   \n",
       "..                                                 ...   \n",
       "675  this is episode number  with george matthew ma...   \n",
       "676  this is episode number  with allegra alessi io...   \n",
       "677  this is episode number  with matt harrison man...   \n",
       "678  this is episode number  with mico yuk host of ...   \n",
       "679  this is episode number  with dr matar haller v...   \n",
       "\n",
       "                episode_keyword1              episode_keyword2  ...  \\\n",
       "0                   data science       elemental data problems  ...   \n",
       "1       machine learning machine             data data science  ...   \n",
       "2           data science podcast         approach data science  ...   \n",
       "3            data scientist role        research youre working  ...   \n",
       "4    unstructured data analytics     data analytics techniques  ...   \n",
       "..                           ...                           ...  ...   \n",
       "675           product market fit         large language models  ...   \n",
       "676           product owner role  data scienceoriented product  ...   \n",
       "677           xgboost model yeah          decision tree models  ...   \n",
       "678               yeah yeah yeah   data storytelling framework  ...   \n",
       "679         insight data science          data model basically  ...   \n",
       "\n",
       "         episode_keyword91  episode_keyword92      episode_keyword93  \\\n",
       "0    physics and chemistry  successes you ’ll                   size   \n",
       "1                    check                ago                  super   \n",
       "2           buzz passwords               show                 number   \n",
       "3                     keen                ago                  stuff   \n",
       "4             stay current               term                   show   \n",
       "..                     ...                ...                    ...   \n",
       "675               gpt cell               case  tremendous innovation   \n",
       "676                episode              paris  explanation very easy   \n",
       "677             golf clubs        speed issue       high probability   \n",
       "678                    put              guess                quickly   \n",
       "679  mentioned potentially       great answer     rich understanding   \n",
       "\n",
       "       episode_keyword94   episode_keyword95       episode_keyword96  \\\n",
       "0                episode             explain        typical for data   \n",
       "1                company                life                 forward   \n",
       "2                    run  stayed in touchnow       emotions involved   \n",
       "3    hard to communicate              python                 analyst   \n",
       "4                   step             machine                   today   \n",
       "..                   ...                 ...                     ...   \n",
       "675                 show             aka gpt  humanmachine symbiosis   \n",
       "676  alessivery very fun  concept of factory                     ago   \n",
       "677      thinking skills       shap directly       mistakesyour golf   \n",
       "678              amazing                 hey                    time   \n",
       "679                 show            decision       surprised i guess   \n",
       "\n",
       "           episode_keyword97        episode_keyword98  \\\n",
       "0                    metrics              agree i ’ve   \n",
       "1    todaybefore we continue           corpus of text   \n",
       "2               nitty gritty   transferable skillsbut   \n",
       "3                       view                    happy   \n",
       "4                        key                    music   \n",
       "..                       ...                      ...   \n",
       "675                weeks ago           media profiles   \n",
       "676                  depends                     edge   \n",
       "677        harrison manytime      convenient wrappers   \n",
       "678        medium the output  connectivity with azure   \n",
       "679               audio text       fellowship program   \n",
       "\n",
       "            episode_keyword99  episode_keyword100  \n",
       "0                      inflow               cloud  \n",
       "1       apparently a required                musk  \n",
       "2                changemy gut  truethere is prior  \n",
       "3                      kirill      cmos the world  \n",
       "4                    brisbane             recover  \n",
       "..                        ...                 ...  \n",
       "675                      weve         gonna occur  \n",
       "676                      back                 key  \n",
       "677  episodematt harrisonyeah   individuals teams  \n",
       "678     portfolio of research  kagan from appsumo  \n",
       "679                     super                nice  \n",
       "\n",
       "[680 rows x 108 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675a2cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yake_keyword_extractor(doc):\n",
    "    global sds_processed\n",
    "    \n",
    "    for i, episode_text in doc.iteritems():\n",
    "        max_ngram_size = 3\n",
    "        deduplication_threshold = 0.3\n",
    "        windowSize = 1\n",
    "        numOfKeywords = 100\n",
    "        kw_extractor = yake.KeywordExtractor(n = max_ngram_size, dedupLim = deduplication_threshold , windowsSize = windowSize, top = numOfKeywords)\n",
    "        keywords = kw_extractor.extract_keywords(episode_text)\n",
    "        sds_processed.at[i, 'episode_keywords'] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4279d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yake_keyword_extractor(sds_processed['episode_split_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1170cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641275c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_keywords'].loc[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe979e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_processed.to_csv('../data/sds_yake_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d651d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_keywords = pd.read_csv('../data/sds_yake_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4091697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1 = sds_processed[sds_processed['episode_number'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4856f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d573c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ef9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['episode_keywords'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071fc414",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47637c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['keywords'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_extractor(row):\n",
    "    words = [t[0] for t in row]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['keywords'] = sds_processed['episode_keywords'].apply(tuple_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee976a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sds_processed['keywords'].loc[677])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee71966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['episode_keywords'].apply(lambda x: tuple_extractor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b2b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b460cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_extractor(word_tuples):\n",
    "    global sds_1\n",
    "    words = [t[0] for t in word_tuples]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e351c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'] = sds_1['episode_keywords'].apply(lambda x: tuple_extractor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0471b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505af419",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'] = sds_1['episode_keywords'].apply(tuple_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f643b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_extractor(tuple):\n",
    "    global sds_keywords\n",
    "    words = []\n",
    "    #for i, episode_text in doc.iteritems():\n",
    "    for i, word_tuple in tuple.iteritems():\n",
    "        words = [t[0] for t in word_tuple]\n",
    "        sds_keywords['keywords'] = words\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7595dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_keywords['episode_keywords'].apply(tuple_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dd196b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3068760",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1['keywords'] = sds_1['episode_keywords'].apply(tuple_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03be2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "[t[0] for t in sds_1['episode_keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_keywords'] = [t[0] for t in sds_processed['episode_keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f60e0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b8272",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_processed['episode_keywords'].loc[678]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "doca = sds_processed['episode_split_text'].loc[1]\n",
    "docb = sds_processed['episode_split_text'].loc[150]\n",
    "docc = sds_processed['episode_split_text'].loc[400]\n",
    "docd = sds_processed['episode_split_text'].loc[679]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_extractor(doc):\n",
    "    kw_model = KeyBERT()\n",
    "    global sds_processed\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    \n",
    "    for i, episode_text in doc.iteritems():\n",
    "        keywords = kw_model.extract_keywords(episode_text, keyphrase_ngram_range=(1, 1), stop_words = stopwords, top_n = 100, use_mmr=True, diversity=0.7)\n",
    "        sds_processed.at[i, 'episode_keywords'] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7bfd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()\n",
    "stopwords = list(STOP_WORDS)\n",
    "keywords = kw_model.extract_keywords(doca, keyphrase_ngram_range=(1, 2), stop_words = stopwords, top_n = 100, use_mmr=True, diversity=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc5d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e849c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_extractor(sds_processed['episode_split_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63270580",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a224f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_processed['episode_split_text'][1:5].apply(keyword_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce751d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffee6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://maartengr.github.io/BERTopic/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
