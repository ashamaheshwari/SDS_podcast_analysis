{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc878e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f86ed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3885 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m ARTICLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m A zoot is... I don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt know how offensive that is in French. Do we need to bleep that out as long as we don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt mention any parts of the church, which Quebec is very violent curse words. Yeah, so that touches on the point that I know we\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve talked about separately, and that is worth mentioning on air that there are guardrails that have been set up by OpenAI, the developers of ChatGPT, but it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms a matter of months before organizations other than OpenAI are providing access to similar kinds of functionality where those guardrails aren\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt in place and where- Absolutely. All right, all right, all right. All right. All right. So I guess it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms more debatable than I thought as to whether a hotdog is a sandwich or not. So maybe that is not a great example of it having low-quality sub-A minus work. But back to specific examples. We\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve gone on off on a number of tangents after tangents after tangents. You were going to have I think a comedy output that you\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124md had from ChatGPT that was particularly good. All right. Hope you enjoyed this special Friday guest episode with Zack Weinberg on extracting commercial value from ChatGPT today, regardless of your level of technical data science expertise. Until next time, keep on rocking it out there folks, and I\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mm looking forward to enjoying another round of the SuperDataScience Podcast with you very soon. And that\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms literally what you\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve already been doing, right? You\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve been doing that kind of thing. Was it you that was telling me about you had ideas like stretching back years of blog posts that you wanted to write? And we got talking recently about ChatGPT. You are frequently sending me messages about the latest and greatest things in AI as a kind of citizen user of these tools, which in 2022 there were these explosions of these different kinds of tools in different kinds of modalities. So you\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mre sending me lots of fun examples of images that you\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124md created with DALLÂ·E 2, for example. And more recently you\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124md been sending me incredible conversations that you\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124md been having with ChatGPT, and recently we were in-person having a conversation and not only were you sharing with me very funny ChatGPT outputs, which we\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mll get to later in the show, but you also were talking about practical commercial ways that you were using this tool. And so for background for our listeners, the reason why I thought that this would be a really interesting podcast episode, we often have guests come on the show who are expert data scientists, and they\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve come up with a new way of developing a model. They can do some new thing or applying some model in some new way. But I will, in the show notes for this episode, I will provide links to posts by my friends Allie Miller and Sadie St. Lawrence. Sadie\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms been on the show a whole bunch of times, including for our data science trends episode that kicked off the year number 641. And both Allie and Sadie have put together great posts summarizing more practical things that you can do with ChatGPT right now. So I\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mll be sure to put those in the show notes. So similar to the kinds of examples that Zack was giving, you can be generating marketing copy, you can be generating blog posts and just don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt do it nefariously if you heard about it on the show, come on, scouts honor.Another really cool example that I have here from the social media post that I made asking about people with really cool examples. We have one here from Danny Richmond. So this specifically, it was brought up by Julia McDonald. She posted it as a comment on LinkedIn to my post asking for tips for this episode. And she had this really cool... It\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms GPT-3 powered in this case. So not ChatGPT, but the ChatGPT interface relies on these GPT language models in the background.And actually we have tons of GPT specific content for you from one of the first authors of the original GPT-3 paper. That\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms Melanie Subbiah. So she\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms in episode number 559 of this show detailing the kinds of language models that are working in behind the ChatGPT interface. Anyway, so this guy, Dannie Richmond, he used GPT-3 with his Gmail account to take very simple original text that he provides and convert that into something that\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms business appropriate. So he writes, Sally, I am starts work at yours Monday from Dave. That\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms the original text that goes in, and GPT-3 converts that to \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDear Sally, I hope this email finds you well. I\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mm ready to let you know that I\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mll be starting work with you on Monday. I am really looking forward to getting started. If you have any questions or need help with anything, please don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt hesitate to get in touch. Best wishes, Dave\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. ChatGPT, how can I advance my data science career? And then it can give you ideas, and then you can provide more context. Like, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHey, your idea one is perfect, but actually I have more years of experience than that, or I have this particular specialization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m And you can do that for anything. It\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms not like just data science careers. It\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms like, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHey, ChatGPT, how can I increase revenue in my business? How can I make my business profitable?\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m And you can have a conversation about it. And there\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms also these things about I found, I saw a really funny tweet that somebody was like, men won\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt go to therapy, but they will have conversations with ChatGPT about their feelings. Did you ask ChatGPT about that? All right. All right. I do that too. Yeah. It\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms a Canadian thing, I\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mm sure. My pleasure, man. It\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms been great. Yeah, and that\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms great. This is a Five-Minute Friday episode. I\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve never thought to wish people a great weekend at the end of it. Nice. Ontario, that\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms some kind of Canada thing. Not today. So, Zack, have you ever written a line of code? Oh, there you go. Right. Right. So yeah, at this time I think it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms somewhat constrained. It\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms an interesting thing. What I was about to say is that its creativity is somewhat constrained by what already exists out there, but then kind of the Larry David and the rain thing seems to see as- So the best episode that we\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve had on that is episode number 565 with Jeremie Harris. I think it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms about two hours long. It\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms one of my favorite conversations that I\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve had in my life. Actually, I can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt remember if I mentioned this on air during the filming of that episode or not, but Jeremie and I talked for two hours before we started recording, then we recorded a two-hour-long episode and then immediately went and talked for another two hours off air. So he\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms a fascinating guy and he is very concerned about AGI, Artificial General Intelligence, a algorithm that has the same learning capacity as an individual human. He is concerned about that happening in the coming years and it having very negative consequences for mankind potentially. There\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms potentially very big risks. So that\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms a great episode to listen to get the kind of general lay of the land there.This development of ChatGPT has made my relative skepticism about AGI happening. I don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt think it could happen in the coming years. Maybe it could happen in the coming decades. The big gap that we don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt currently have any viable solutions for is that these systems don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt have an appreciation for cause and effect. So they are only capable of correlation, and they do amazing things with that, but they are taking in a sequence of words as input, a sequence of characters as inputs. In the case of this ChatGPT model, the input is natural language characters, and then that information flows through a neural network, a weights and biases model parameters and an output comes out the other end. There\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms no point within that process where there\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms the kind of cognition that humans do, or that puppies do, or infants do, where they can take one example of something having had happened and make inferences draw conclusions from that.So there\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms this lack of cause and effect that deep neural networks as we\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve conceived of them today, don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt handle. And all of the big advancements in AI in the last decade or two have been as a result of these neural networks that are purely, one directional... So there\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms hurdles to overcome I think towards having the kind of reasoning that humans have. But these machines, just as a calculator has for decades been able to do things that we can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt, so too can ChatGPT. Okay, so it can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt reason like a person, but it can in seconds create a rap in a style of Snoop Dogg about hops and introduce the concepts of brewing to people. There\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms not many people, maybe Snoop Dogg can do that, and maybe a few other people on the planet, we have this algorithm that can do that and then you can say, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOkay, now do it in a screenplay in the style of Larry David.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m And it can do that too.And so it has so much knowledge and so many different styles that it can imitate effectively an infinite amount when you think about different variations, when you\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mre like, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive me a Larry David style script with Snoop Dogg in it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Yeah, there\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms an infinite amount of variation there, right? So I guess I\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mm off on a big tangent here. So one, I think that there potentially are concerns that we need to have with AGI in our lifetimes. Two, I don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt think that the exact path that we\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mre on now, which primarily just involves adding more model parameters is going to give us intelligence that is exactly like ours. But the third big thing is that we will still end up creating models that are capable of incredible things, things that we can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt do as humans. We don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt need to worry about why replicate exactly human intelligence. We can be having different kinds of capabilities. And that\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms exactly what we see with ChatGPT. So we\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve known each other for 20 years. We just did the math. So we\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124md met in 2003 in my first year of chemistry lab. That\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms a cool productivity thing there. This is episode number 646 with Zack Weinberg on how to extract commercial value from ChatGPT today.For today\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms episode, my longtime friend Zack Weinberg, a brewer and owner of a homebrew supply store, joins me to provide ideas and actionable guidance on how anyone, whether you have a technical background or not, can this very day extract tons of commercial value from the ChatGPT interface that has taken the world by storm in recent months. Let\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms jump right into our conversation.Zack Weinberg, welcome to the SuperDataScience Podcast. What a treat to have you here, man. Where in the world were you calling in from? Well, and then you just use the term self-aware, which is another thing that I certainly don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt think machines have any more than a calculator has. But to give you an example of how in some circumstances it is giving much worse than A minus results. So Ken Jee, who was a guest on this show in episode number 555, brilliant data scientist and content creator, super popular on YouTube. I made a LinkedIn post just before recording this episode where I said, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mm filming a podcast episode that highlights the most mind-blowing ChatGPT output conversations, what are the coolest dialogues you\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve elicited or seen others elicit?\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m And Ken Jee commented that he asked ChatGPT if a hotdog was a sandwich and it gave the wrong answer. And so that\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms much worse than A minus. Well, no, a hotdog is a sandwich. Well, that\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms perfect because that\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms kind of the point of having you here. Yeah, I really like how you phrased that as something for your listeners, but that sounds like a really great idea, particularly for you. Yeah, hops are one of the key ingredients in beer for those of our listeners who aren\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt aware and very important for getting the flavor that you want, if you want to learn more about that, just ask your local ChatGPT browser and make sure that you get it sung to you by Snoop Dogg. So yeah, perfect. So this is exactly what I wanted to accomplish with this episode, with this relatively short, it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms not actually going to be just five minutes on this Five-Minute Friday. I think whenever we bring in a guest like this on a Friday and ends up being a bit longer than five minutes. But this was exactly what I wanted to accomplish was to be able to show to our listeners whether you\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mre technical or not, there are things that you can be doing to generate content with ChatGPT out of the box today that can be creating real commercial value for you.And you can be doing that without having to write a line of code, without necessarily any experience as a data scientist or any kind of a relevant occupation like that. So already kind of mission accomplished in terms of the episode, but I also thought this would be a great opportunity to just share some fun examples beyond just commercially viable ones. So we already did an episode, episode number 638 of this podcast was written by ChatGPT. And I tell you that at the onset of the episode, maybe someday in the future I\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mll be doing it, you won\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt even know. It hasn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt happened yet. But episode number 638 was a year-end holiday greeting. I asked ChatGPT to create it, I gave it the parameters. I said, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour name is Jon Krohn, you host a podcast called SuperDataScience. Write a year-end holiday greeting.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m And it did it perfectly. First shot just copied and pasted it into a script and I read it on air. Yeah, maybe in any field. Yeah. Yeah. But potentially the risk of it at this time, I think you always want to be reviewing it before it goes out probably because of this risk that we\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mre seeing of it being very confidently introducing errors. So yeah, so lots of fun stuff. Potentially it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms going to destroy all of humankind, but for now you can create some great marketing copy. I\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mll be sure to include a link in the show notes to the LinkedIn and Twitter posts that I made asking for people\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms top prompts and results that they\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124md seen with ChatGPT. There\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms lots of fun stuff in there like Kramer on Seinfeld pitching a crypto exchange. There\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms, somebody asked ChatGPT to write a biblical verse in the style of the King James Bible explaining how to remove a peanut butter sandwich from a VCR and it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms hilarious.So yeah, that kind of thing. We\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mve got an entire paper that was written by ChatGPT... Sorry, an entire book that was essentially written by ChatGPT. So all those links will be sure to include the post that has all of those different examples in the show notes. And one thing that we haven\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt even touched on yet in this episode that is really relevant to our technical listeners out there, especially those listeners that are just getting started with a data science career or with a software development career, is that ChatGPT can write code, and they can do it in lots of different languages and can do it very well. So one final example that I have is Douglas McLean, who\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms a lead data scientist at Tesco Bank. He says that he used ChatGPT to write Python code to hedge the interest rate risk in a swap portfolio, and then he asked it to do it all again in Spanish. So there\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms an enormous amount of potential beyond just generating natural language, but generating code as well. Yeah. Really great points. I don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt have answers to all those questions. I think maybe nobody does. We don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt know where these things are going. I do know that today I don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt have tips for people who want to do really nefarious things. Yeah. So also, there are lots of examples of it giving outputs that are nonsense when you ask it things like that. So it doesn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt... Because it is just probabilities of it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms predicting what character would make sense next or what word would make sense next in a sequence based on what\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms already happened in the conversation. There are lots of highly probable words that don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt make any sense and that sometimes it outputs, but it will output that very confidently. So for example, a listener at home, based on the advice that we gave it in this episode, could go to ChatGPT and ask what\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms involved in brewing beer. And it might very confidently give you an answer that has big inaccuracies and there\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms no way to know that as the reader unless you are already a beer brewing expert. Yeah. So that blew my mind when you first read that to me. I hadn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt been trying any comedy at that point, and it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms that context. It\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms Larry in the rain with a wrinkled suit giving this, it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms a really subtle sense of how to have some poetry around the idea of describing a global recession in a script. So yeah, that kind of nuance and the ability to nail comedy has really, really surprised me. Yeah. So, Zack, do you have some funny ChatGPT conversations that you had? Yeah. Yeah. It\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms like the subtle context there. Yeah. So there are very, I guess, scary going back to the AGI idea and Jeremie Harris in episode number 565, we don\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt need to have AGI, an algorithm that\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms capable of learning as broadly as human to have very powerful AI tools that are wreaking havoc. You\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mre also, you\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mre selling yourself a little bit short at least because you do run a big business that is mostly digital. You do have a physical store. So if people are watching the YouTube version of this episode, you can actually see a really beautiful setup that you created for filming today, Zack, in one of your homebrew supply stores, physical stores. But mostly your business is online, and so you spend a lot of time with digital websites, and with digital advertising, and that kind of thing. And so with the advent of the mind-blowing ChatGPT outputs late 2022, you had some ideas for how you could be driving real commercial value immediately with that tool. Do you want to tell us about some of those? Zack, it\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms been fun having you on the show today talking about immediate commercial value that anyone can derive from AI today, specifically from ChatGPT. Thanks so much for being on the show and having a laugh with us. Is there any way that people should follow you or get in touch with you after the episode if they have questions? Yeah,\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msummarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mARTICLE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:250\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m          ids of the summary.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:150\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m    155\u001b[0m     ):\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py:1074\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1074\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py:1081\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1080\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1081\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py:990\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m    989\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 990\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py:172\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generate_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_length)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m], generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 172\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/transformers/generation_utils.py:1339\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1331\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1332\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1333\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1334\u001b[0m         )\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1339\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;66;03m# 4. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/transformers/generation_utils.py:583\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    581\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    582\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 583\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:804\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    802\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_scale\n\u001b[0;32m--> 804\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m embed_pos\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    807\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:139\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[0;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[1;32m    134\u001b[0m bsz, seq_len \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    135\u001b[0m positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m    136\u001b[0m     past_key_values_length, past_key_values_length \u001b[38;5;241m+\u001b[39m seq_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    137\u001b[0m )\u001b[38;5;241m.\u001b[39mexpand(bsz, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "ARTICLE = \"\"\" A zoot is... I don\\'t know how offensive that is in French. Do we need to bleep that out as long as we don\\'t mention any parts of the church, which Quebec is very violent curse words. Yeah, so that touches on the point that I know we\\'ve talked about separately, and that is worth mentioning on air that there are guardrails that have been set up by OpenAI, the developers of ChatGPT, but it\\'s a matter of months before organizations other than OpenAI are providing access to similar kinds of functionality where those guardrails aren\\'t in place and where- Absolutely. All right, all right, all right. All right. All right. So I guess it\\'s more debatable than I thought as to whether a hotdog is a sandwich or not. So maybe that is not a great example of it having low-quality sub-A minus work. But back to specific examples. We\\'ve gone on off on a number of tangents after tangents after tangents. You were going to have I think a comedy output that you\\'d had from ChatGPT that was particularly good. All right. Hope you enjoyed this special Friday guest episode with Zack Weinberg on extracting commercial value from ChatGPT today, regardless of your level of technical data science expertise. Until next time, keep on rocking it out there folks, and I\\'m looking forward to enjoying another round of the SuperDataScience Podcast with you very soon. And that\\'s literally what you\\'ve already been doing, right? You\\'ve been doing that kind of thing. Was it you that was telling me about you had ideas like stretching back years of blog posts that you wanted to write? And we got talking recently about ChatGPT. You are frequently sending me messages about the latest and greatest things in AI as a kind of citizen user of these tools, which in 2022 there were these explosions of these different kinds of tools in different kinds of modalities. So you\\'re sending me lots of fun examples of images that you\\'d created with DALLÂ·E 2, for example. And more recently you\\'d been sending me incredible conversations that you\\'d been having with ChatGPT, and recently we were in-person having a conversation and not only were you sharing with me very funny ChatGPT outputs, which we\\'ll get to later in the show, but you also were talking about practical commercial ways that you were using this tool. And so for background for our listeners, the reason why I thought that this would be a really interesting podcast episode, we often have guests come on the show who are expert data scientists, and they\\'ve come up with a new way of developing a model. They can do some new thing or applying some model in some new way. But I will, in the show notes for this episode, I will provide links to posts by my friends Allie Miller and Sadie St. Lawrence. Sadie\\'s been on the show a whole bunch of times, including for our data science trends episode that kicked off the year number 641. And both Allie and Sadie have put together great posts summarizing more practical things that you can do with ChatGPT right now. So I\\'ll be sure to put those in the show notes. So similar to the kinds of examples that Zack was giving, you can be generating marketing copy, you can be generating blog posts and just don\\'t do it nefariously if you heard about it on the show, come on, scouts honor.Another really cool example that I have here from the social media post that I made asking about people with really cool examples. We have one here from Danny Richmond. So this specifically, it was brought up by Julia McDonald. She posted it as a comment on LinkedIn to my post asking for tips for this episode. And she had this really cool... It\\'s GPT-3 powered in this case. So not ChatGPT, but the ChatGPT interface relies on these GPT language models in the background.And actually we have tons of GPT specific content for you from one of the first authors of the original GPT-3 paper. That\\'s Melanie Subbiah. So she\\'s in episode number 559 of this show detailing the kinds of language models that are working in behind the ChatGPT interface. Anyway, so this guy, Dannie Richmond, he used GPT-3 with his Gmail account to take very simple original text that he provides and convert that into something that\\'s business appropriate. So he writes, Sally, I am starts work at yours Monday from Dave. That\\'s the original text that goes in, and GPT-3 converts that to \"Dear Sally, I hope this email finds you well. I\\'m ready to let you know that I\\'ll be starting work with you on Monday. I am really looking forward to getting started. If you have any questions or need help with anything, please don\\'t hesitate to get in touch. Best wishes, Dave\". ChatGPT, how can I advance my data science career? And then it can give you ideas, and then you can provide more context. Like, \"Hey, your idea one is perfect, but actually I have more years of experience than that, or I have this particular specialization.\" And you can do that for anything. It\\'s not like just data science careers. It\\'s like, \"Hey, ChatGPT, how can I increase revenue in my business? How can I make my business profitable?\" And you can have a conversation about it. And there\\'s also these things about I found, I saw a really funny tweet that somebody was like, men won\\'t go to therapy, but they will have conversations with ChatGPT about their feelings. Did you ask ChatGPT about that? All right. All right. I do that too. Yeah. It\\'s a Canadian thing, I\\'m sure. My pleasure, man. It\\'s been great. Yeah, and that\\'s great. This is a Five-Minute Friday episode. I\\'ve never thought to wish people a great weekend at the end of it. Nice. Ontario, that\\'s some kind of Canada thing. Not today. So, Zack, have you ever written a line of code? Oh, there you go. Right. Right. So yeah, at this time I think it\\'s somewhat constrained. It\\'s an interesting thing. What I was about to say is that its creativity is somewhat constrained by what already exists out there, but then kind of the Larry David and the rain thing seems to see as- So the best episode that we\\'ve had on that is episode number 565 with Jeremie Harris. I think it\\'s about two hours long. It\\'s one of my favorite conversations that I\\'ve had in my life. Actually, I can\\'t remember if I mentioned this on air during the filming of that episode or not, but Jeremie and I talked for two hours before we started recording, then we recorded a two-hour-long episode and then immediately went and talked for another two hours off air. So he\\'s a fascinating guy and he is very concerned about AGI, Artificial General Intelligence, a algorithm that has the same learning capacity as an individual human. He is concerned about that happening in the coming years and it having very negative consequences for mankind potentially. There\\'s potentially very big risks. So that\\'s a great episode to listen to get the kind of general lay of the land there.This development of ChatGPT has made my relative skepticism about AGI happening. I don\\'t think it could happen in the coming years. Maybe it could happen in the coming decades. The big gap that we don\\'t currently have any viable solutions for is that these systems don\\'t have an appreciation for cause and effect. So they are only capable of correlation, and they do amazing things with that, but they are taking in a sequence of words as input, a sequence of characters as inputs. In the case of this ChatGPT model, the input is natural language characters, and then that information flows through a neural network, a weights and biases model parameters and an output comes out the other end. There\\'s no point within that process where there\\'s the kind of cognition that humans do, or that puppies do, or infants do, where they can take one example of something having had happened and make inferences draw conclusions from that.So there\\'s this lack of cause and effect that deep neural networks as we\\'ve conceived of them today, don\\'t handle. And all of the big advancements in AI in the last decade or two have been as a result of these neural networks that are purely, one directional... So there\\'s hurdles to overcome I think towards having the kind of reasoning that humans have. But these machines, just as a calculator has for decades been able to do things that we can\\'t, so too can ChatGPT. Okay, so it can\\'t reason like a person, but it can in seconds create a rap in a style of Snoop Dogg about hops and introduce the concepts of brewing to people. There\\'s not many people, maybe Snoop Dogg can do that, and maybe a few other people on the planet, we have this algorithm that can do that and then you can say, \"Okay, now do it in a screenplay in the style of Larry David.\" And it can do that too.And so it has so much knowledge and so many different styles that it can imitate effectively an infinite amount when you think about different variations, when you\\'re like, \"Give me a Larry David style script with Snoop Dogg in it.\" Yeah, there\\'s an infinite amount of variation there, right? So I guess I\\'m off on a big tangent here. So one, I think that there potentially are concerns that we need to have with AGI in our lifetimes. Two, I don\\'t think that the exact path that we\\'re on now, which primarily just involves adding more model parameters is going to give us intelligence that is exactly like ours. But the third big thing is that we will still end up creating models that are capable of incredible things, things that we can\\'t do as humans. We don\\'t need to worry about why replicate exactly human intelligence. We can be having different kinds of capabilities. And that\\'s exactly what we see with ChatGPT. So we\\'ve known each other for 20 years. We just did the math. So we\\'d met in 2003 in my first year of chemistry lab. That\\'s a cool productivity thing there. This is episode number 646 with Zack Weinberg on how to extract commercial value from ChatGPT today.For today\\'s episode, my longtime friend Zack Weinberg, a brewer and owner of a homebrew supply store, joins me to provide ideas and actionable guidance on how anyone, whether you have a technical background or not, can this very day extract tons of commercial value from the ChatGPT interface that has taken the world by storm in recent months. Let\\'s jump right into our conversation.Zack Weinberg, welcome to the SuperDataScience Podcast. What a treat to have you here, man. Where in the world were you calling in from? Well, and then you just use the term self-aware, which is another thing that I certainly don\\'t think machines have any more than a calculator has. But to give you an example of how in some circumstances it is giving much worse than A minus results. So Ken Jee, who was a guest on this show in episode number 555, brilliant data scientist and content creator, super popular on YouTube. I made a LinkedIn post just before recording this episode where I said, \"I\\'m filming a podcast episode that highlights the most mind-blowing ChatGPT output conversations, what are the coolest dialogues you\\'ve elicited or seen others elicit?\" And Ken Jee commented that he asked ChatGPT if a hotdog was a sandwich and it gave the wrong answer. And so that\\'s much worse than A minus. Well, no, a hotdog is a sandwich. Well, that\\'s perfect because that\\'s kind of the point of having you here. Yeah, I really like how you phrased that as something for your listeners, but that sounds like a really great idea, particularly for you. Yeah, hops are one of the key ingredients in beer for those of our listeners who aren\\'t aware and very important for getting the flavor that you want, if you want to learn more about that, just ask your local ChatGPT browser and make sure that you get it sung to you by Snoop Dogg. So yeah, perfect. So this is exactly what I wanted to accomplish with this episode, with this relatively short, it\\'s not actually going to be just five minutes on this Five-Minute Friday. I think whenever we bring in a guest like this on a Friday and ends up being a bit longer than five minutes. But this was exactly what I wanted to accomplish was to be able to show to our listeners whether you\\'re technical or not, there are things that you can be doing to generate content with ChatGPT out of the box today that can be creating real commercial value for you.And you can be doing that without having to write a line of code, without necessarily any experience as a data scientist or any kind of a relevant occupation like that. So already kind of mission accomplished in terms of the episode, but I also thought this would be a great opportunity to just share some fun examples beyond just commercially viable ones. So we already did an episode, episode number 638 of this podcast was written by ChatGPT. And I tell you that at the onset of the episode, maybe someday in the future I\\'ll be doing it, you won\\'t even know. It hasn\\'t happened yet. But episode number 638 was a year-end holiday greeting. I asked ChatGPT to create it, I gave it the parameters. I said, \"Your name is Jon Krohn, you host a podcast called SuperDataScience. Write a year-end holiday greeting.\" And it did it perfectly. First shot just copied and pasted it into a script and I read it on air. Yeah, maybe in any field. Yeah. Yeah. But potentially the risk of it at this time, I think you always want to be reviewing it before it goes out probably because of this risk that we\\'re seeing of it being very confidently introducing errors. So yeah, so lots of fun stuff. Potentially it\\'s going to destroy all of humankind, but for now you can create some great marketing copy. I\\'ll be sure to include a link in the show notes to the LinkedIn and Twitter posts that I made asking for people\\'s top prompts and results that they\\'d seen with ChatGPT. There\\'s lots of fun stuff in there like Kramer on Seinfeld pitching a crypto exchange. There\\'s, somebody asked ChatGPT to write a biblical verse in the style of the King James Bible explaining how to remove a peanut butter sandwich from a VCR and it\\'s hilarious.So yeah, that kind of thing. We\\'ve got an entire paper that was written by ChatGPT... Sorry, an entire book that was essentially written by ChatGPT. So all those links will be sure to include the post that has all of those different examples in the show notes. And one thing that we haven\\'t even touched on yet in this episode that is really relevant to our technical listeners out there, especially those listeners that are just getting started with a data science career or with a software development career, is that ChatGPT can write code, and they can do it in lots of different languages and can do it very well. So one final example that I have is Douglas McLean, who\\'s a lead data scientist at Tesco Bank. He says that he used ChatGPT to write Python code to hedge the interest rate risk in a swap portfolio, and then he asked it to do it all again in Spanish. So there\\'s an enormous amount of potential beyond just generating natural language, but generating code as well. Yeah. Really great points. I don\\'t have answers to all those questions. I think maybe nobody does. We don\\'t know where these things are going. I do know that today I don\\'t have tips for people who want to do really nefarious things. Yeah. So also, there are lots of examples of it giving outputs that are nonsense when you ask it things like that. So it doesn\\'t... Because it is just probabilities of it\\'s predicting what character would make sense next or what word would make sense next in a sequence based on what\\'s already happened in the conversation. There are lots of highly probable words that don\\'t make any sense and that sometimes it outputs, but it will output that very confidently. So for example, a listener at home, based on the advice that we gave it in this episode, could go to ChatGPT and ask what\\'s involved in brewing beer. And it might very confidently give you an answer that has big inaccuracies and there\\'s no way to know that as the reader unless you are already a beer brewing expert. Yeah. So that blew my mind when you first read that to me. I hadn\\'t been trying any comedy at that point, and it\\'s that context. It\\'s Larry in the rain with a wrinkled suit giving this, it\\'s a really subtle sense of how to have some poetry around the idea of describing a global recession in a script. So yeah, that kind of nuance and the ability to nail comedy has really, really surprised me. Yeah. So, Zack, do you have some funny ChatGPT conversations that you had? Yeah. Yeah. It\\'s like the subtle context there. Yeah. So there are very, I guess, scary going back to the AGI idea and Jeremie Harris in episode number 565, we don\\'t need to have AGI, an algorithm that\\'s capable of learning as broadly as human to have very powerful AI tools that are wreaking havoc. You\\'re also, you\\'re selling yourself a little bit short at least because you do run a big business that is mostly digital. You do have a physical store. So if people are watching the YouTube version of this episode, you can actually see a really beautiful setup that you created for filming today, Zack, in one of your homebrew supply stores, physical stores. But mostly your business is online, and so you spend a lot of time with digital websites, and with digital advertising, and that kind of thing. And so with the advent of the mind-blowing ChatGPT outputs late 2022, you had some ideas for how you could be driving real commercial value immediately with that tool. Do you want to tell us about some of those? Zack, it\\'s been fun having you on the show today talking about immediate commercial value that anyone can derive from AI today, specifically from ChatGPT. Thanks so much for being on the show and having a laugh with us. Is there any way that people should follow you or get in touch with you after the episode if they have questions? Yeah,\"\"\"\n",
    "\n",
    "\n",
    "print(summarizer(ARTICLE, do_sample=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6fa02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
