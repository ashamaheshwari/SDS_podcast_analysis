{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8fb172f",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8056cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb1ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds = pd.read_csv('../data/superdatascience.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890ac8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 682 entries, 0 to 681\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   episode_name     682 non-null    object\n",
      " 1   length_episode   682 non-null    object\n",
      " 2   context_episode  682 non-null    object\n",
      " 3   guest_name       682 non-null    object\n",
      " 4   guest_info       682 non-null    object\n",
      " 5   text_episode     680 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 32.1+ KB\n"
     ]
    }
   ],
   "source": [
    "sds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4251eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>guest_info</th>\n",
       "      <th>text_episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SDS 381: How to Avoid Failing at Digital Trans...</td>\n",
       "      <td>60 minutes</td>\n",
       "      <td>BusinessData Science</td>\n",
       "      <td>Podcast Guest: Tony SaldanhaWednesday Jul 08, ...</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is episode number 381, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDS 061: Discovering Data Science workflows an...</td>\n",
       "      <td>62 minutes</td>\n",
       "      <td>Machine LearningData SciencePython</td>\n",
       "      <td>Podcast Guest: Daniel WhitenackThursday Jun 15...</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 61 with data s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SDS 049: Great tips on building a successful A...</td>\n",
       "      <td>65 minutes</td>\n",
       "      <td>BusinessDatabase</td>\n",
       "      <td>Podcast Guest: Jim HadleyThursday May 04, 2017</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 49 with Founde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SDS 029: AI in Recruitment, Machine Learning, ...</td>\n",
       "      <td>66 minutes</td>\n",
       "      <td>BusinessMachine LearningData ScienceArtificial...</td>\n",
       "      <td>Podcast Guest: Ben TaylorFriday Feb 24, 2017</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 29, with Chief...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SDS 254: Two Wolves</td>\n",
       "      <td>6 minutes</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Podcast Guest: Kirill EremenkoFriday Apr 19, 2019</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>This is FiveMinuteFriday, episode number 254, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        episode_name length_episode  \\\n",
       "0  SDS 381: How to Avoid Failing at Digital Trans...     60 minutes   \n",
       "1  SDS 061: Discovering Data Science workflows an...     62 minutes   \n",
       "2  SDS 049: Great tips on building a successful A...     65 minutes   \n",
       "3  SDS 029: AI in Recruitment, Machine Learning, ...     66 minutes   \n",
       "4                                SDS 254: Two Wolves      6 minutes   \n",
       "\n",
       "                                     context_episode  \\\n",
       "0                               BusinessData Science   \n",
       "1                 Machine LearningData SciencePython   \n",
       "2                                   BusinessDatabase   \n",
       "3  BusinessMachine LearningData ScienceArtificial...   \n",
       "4                                       Data Science   \n",
       "\n",
       "                                          guest_name  \\\n",
       "0  Podcast Guest: Tony SaldanhaWednesday Jul 08, ...   \n",
       "1  Podcast Guest: Daniel WhitenackThursday Jun 15...   \n",
       "2     Podcast Guest: Jim HadleyThursday May 04, 2017   \n",
       "3       Podcast Guest: Ben TaylorFriday Feb 24, 2017   \n",
       "4  Podcast Guest: Kirill EremenkoFriday Apr 19, 2019   \n",
       "\n",
       "                                          guest_info  \\\n",
       "0  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "1  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "2  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "3  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "4  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "\n",
       "                                        text_episode  \n",
       "0  Kirill Eremenko:\\tThis is episode number 381, ...  \n",
       "1  Kirill:\\tThis is episode number 61 with data s...  \n",
       "2  Kirill:\\tThis is episode number 49 with Founde...  \n",
       "3  Kirill:\\tThis is episode number 29, with Chief...  \n",
       "4  This is FiveMinuteFriday, episode number 254, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28de401d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_16047/2714993561.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  sds['guest_name'] = sds['guest_name'].str.replace(r'(\\b[A-Za-z]{3}\\s\\d{2},\\s\\d{4}\\b)', '')\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_16047/2714993561.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  sds['guest_name'] = sds['guest_name'].str.replace('Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday', '')\n",
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_16047/2714993561.py:26: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  sds['context_episode'] = sds['context_episode'].str.replace('([a-z])([A-Z])', r'\\1 \\2')\n"
     ]
    }
   ],
   "source": [
    "# Extracting episode_number and episode_name from episode_name column\n",
    "sds['episode_number'] = sds['episode_name'].str.split(':', expand = True)[0]\n",
    "sds['episode_name'] = sds['episode_name'].str.split(':', expand = True)[1]\n",
    "sds['episode_number'] = sds['episode_number'].str.replace('SDS', '')\n",
    "\n",
    "# Removing Podcast Guest text from guest_name column\n",
    "sds['guest_name'] = sds['guest_name'].str.split(':', expand = True)[1]\n",
    "\n",
    "# Removing minutes from length_episode column\n",
    "sds['length_episode'] = sds['length_episode'].str.split(' ', expand = True)[0]\n",
    "\n",
    "# Extracting date from guest_name column and making a new column episode_date\n",
    "sds['episode_date'] = sds['guest_name'].str.extract(r'(\\b[A-Za-z]{3}\\s\\d{2},\\s\\d{4}\\b)', expand = False).str.strip()\n",
    "sds['episode_year'] = sds['episode_date'].str.split(',', expand = True)[1]\n",
    "\n",
    "# Replacing/removing date in guest_name column \n",
    "sds['guest_name'] = sds['guest_name'].str.replace(r'(\\b[A-Za-z]{3}\\s\\d{2},\\s\\d{4}\\b)', '')\n",
    "\n",
    "# Extracting day from guest_name column and making a new column episode_day\n",
    "sds['episode_day'] = sds['guest_name'].str.extract(r'(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday)', expand = False).str.strip()\n",
    "\n",
    "#Replacing/removing day in guest_name column \n",
    "sds['guest_name'] = sds['guest_name'].str.replace('Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday', '')\n",
    "\n",
    "#Adding spaces between some words in context_episode column\n",
    "sds['context_episode'] = sds['context_episode'].str.replace('([a-z])([A-Z])', r'\\1 \\2')\n",
    "\n",
    "# changing the data types for episode_number and length_episode\n",
    "sds['episode_number'] = sds['episode_number'].astype('int')\n",
    "sds['length_episode'] = sds['length_episode'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b22dd355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>guest_info</th>\n",
       "      <th>text_episode</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_year</th>\n",
       "      <th>episode_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Avoid Failing at Digital Transformation</td>\n",
       "      <td>60</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Tony Saldanha</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is episode number 381, ...</td>\n",
       "      <td>381</td>\n",
       "      <td>Jul 08, 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discovering Data Science workflows and the im...</td>\n",
       "      <td>62</td>\n",
       "      <td>Machine Learning Data Science Python</td>\n",
       "      <td>Daniel Whitenack</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 61 with data s...</td>\n",
       "      <td>61</td>\n",
       "      <td>Jun 15, 2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        episode_name  length_episode  \\\n",
       "0     How to Avoid Failing at Digital Transformation              60   \n",
       "1   Discovering Data Science workflows and the im...              62   \n",
       "\n",
       "                        context_episode          guest_name  \\\n",
       "0                 Business Data Science      Tony Saldanha    \n",
       "1  Machine Learning Data Science Python   Daniel Whitenack    \n",
       "\n",
       "                                          guest_info  \\\n",
       "0  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "1  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "\n",
       "                                        text_episode  episode_number  \\\n",
       "0  Kirill Eremenko:\\tThis is episode number 381, ...             381   \n",
       "1  Kirill:\\tThis is episode number 61 with data s...              61   \n",
       "\n",
       "   episode_date episode_year episode_day  \n",
       "0  Jul 08, 2020         2020   Wednesday  \n",
       "1  Jun 15, 2017         2017    Thursday  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9243b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting dataframe on episode number\n",
    "sds = sds.sort_values('episode_number').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "165923a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Kirill:\\tThis is episode number 53 with Aspiring Data Scientist Virginia Mendonca.(background music plays)Welcome to the SuperDataScience podcast. My name is Kirill Eremenko, data science coach and lifestyle entrepreneur. And each week we bring you inspiring people and ideas to help you build your successful career in data science. Thanks for being here today and now let’s make the complex simple.(background music plays)Hello, hello, hello. Hope you're having a great week, a very exciting and interesting week, and today we've got an inspiring guest. Virginia is an aspiring data scientist. So Virginia came from a background in databases and now she's decided to transition her career into data science. And the reason for that is because she has a greater vision for her future. She has a vision of doing good for the world. And she can see that it will be much easier to do that by knowing data science. How cool is that.In this podcast, we talked about quite a few things. We talked about how Virginia goes about understanding what skills she needs to learn and how to break into the space of data science, about understanding when it's appropriate to take a step back in your career and take a step sideways without regretting all the effort that you've put into your career, but instead leveraging your career to build a new career in a different space, such as data science.We also talked about how goals and dreams are different and how it's important to have a dream and be passionate about it and always work towards it and how to line yourself up for success in your dream. How not to just jump at it, but actually understand the right career path that you need to select for yourself based on what type of person you are in order to line yourself up for success in your dream, in your vision for your future.So a very interesting and inspiring podcast, especially if you are in the outskirts of just starting into your career, of just starting out into the space of data science, or if you already have a career but you want to transition into the space of data science. And that's what we're going to be talking about today. And without further ado, I bring to you Virginia Mendonca, an aspiring data scientist.(background music plays)Welcome everybody to the SuperDataScience podcast. Today we’ve got a very special guest, Virginia Mendonca calling from Slovakia. How are you going Virginia today?Virginia:\\tAll fine here. Thank you for inviting me.Kirill:\\tOh it's great to have you. So tell us a bit about yourself. You are a student. You're studying data science. You're trying to get into this space. Is that correct?Virginia:\\tYes. I'm very thrilled to understand data science. It's been a while I am into this study, basically online courses which I've been finding one interesting then another. And that's it. I'm studying and finally I found a chance to go deeper in it.Kirill:\\tOk, awesome. And you're listening to the podcast at the same time. Because the way we met, you actually sent me a long comment on how I could do the podcast better. Or basically some tips, which I really appreciated about how I communicate with guests and so on. So how are you finding the podcast?Virginia:\\tIt's because I find it an amazing and brilliant idea from you that I thought maybe I should tell him some tips that if I can help him with something and if he can see this, maybe he will think about it. Because it would be nice to improve. Just improve. When you see something that's really great, you think about improving it. When you don't believe in it, you don't even go there. And you wouldn't bother with this. But this for me is a really great way to reach out to all the data scientists and future data scientists, to empower their vision and that's what moves us.Kirill:\\tYes, yes. And thank you, that was a great thing to hear. Really appreciated the comments and definitely something I take on board. And then I was a bit straightforward, and I said ok, cool, looked at your LinkedIn and I was so surprised by your background. I couldn't not invite you onto the show. And then it was very interesting because when we just started the call, just now for people listening, we were just on the call before the podcast, and I honestly thought that Virginia is from Bratislava and that she's travelled to all these different places. But it turns out it's a completely different story and it's even crazier than I thought. So tell us a bit about your background. Where are you from and how has your life taken you to all these different countries, all these different places in the world?Virginia:\\tWell, first of all I would like to note that now I understand why the recruiters come to me already thinking that I am from Slovakia. It's not clear. But now I think I will make it clear on LinkedIn. Anyway, my life has been challenging, mostly challenged by myself. When I was in Brazil, I was a DBA, working with SQL Server.Kirill:\\tSorry, just to start, you're actually from Brazil? Because we still haven't gotten that clear.Virginia:\\tYes. I am Brazilian. Totally Brazilian!Kirill:\\tOk.Virginia:\\tAnd I started working with databases. It was my first experience with the IT area. Since then, I've spent 7 years working with databases, mostly SQL Server. I was working in Brazil, and I felt like I missed some international business knowledge. I wanted to improve my business knowledge because I felt it was needed to have my own business. So thinking much about it, I thought about studying it outside the country to have a bolder idea of it. So I went to Ireland. I was in Dublin for a year studying and after that, I really liked the style here in the European Union and I decided to stay. And then I applied for jobs in all of Europe. And the first one to give me an opportunity was AT&T here in Slovakia. So I thought, why not? And there I go.Kirill:\\tAmazing, amazing. So you challenged yourself to get out of your comfort zone. Big change from Brazil to Dublin. Even just temperature-wise, it's crazy!Virginia:\\tYes. Mainly from Brazil to Ireland. Because in Slovakia, right now you can feel it's warm outside. It's 18 degrees. And it can even reach much more, like 30 degrees! In Ireland, it's super windy and cold. And that's what I faced the entire year I was there. And a few sunny times.Kirill:\\tSo Slovakia is a bit better than that?Virginia:\\tYeah, it is.Kirill:\\tFantastic. There’s so many places we can start, but let’s probably start with your decision to stop your career in database administration and move to data science and data analytics. What triggered that change? For somebody listening to this podcast, if they have a career of 7 years in a certain area, they might be attached to it, they might be thinking, “I’m already very good at this. If I decide to go to data science or data analytics, I will have to start from zero. I will lose all of the years of effort that I’ve put into my career and the progression in my career that I’ve had.” So how did you go about thinking about that challenge? It’s such a big step to move to data science.Virginia:\\tFirst of all, it’s about the perspective you take over the situation. If you see this like an opportunity to increase your skills, your real skills, it’s never lost. Even the database knowledge, managing database knowledge that I’ve got, it will help me to understand, to have a broader view over the data science itself because we need to know also where it is stored and also how it is managed, it’s the backstage of this focus. So I think every knowledge adds up, mainly when we’re talking about data science. Because you can find people from all the other professions.I’ve been reading and listening and watching videos and people that have other backgrounds, they can even reach data science and be successful in it. So I’ve been very keen to go into this path which offers such broad ways to go. Like, I can use it like a tool in whatever I would like to study, and this really fits on me because I love having different options and freedom to choose and go wherever I want to go. So this is perfect because I can apply it in whatever I feel that is interesting.By the way, statistics is something that I had before. When I started my university life, the first course I did was statistics and I thought, “No! When am I going to use that?” At that time, I was a teenager and now I understand. Maybe now I can finally use and understand that knowledge.Kirill:\\tOkay. Wow, that’s a great overview. I also had a course in statistics at university. At the time, it was so vague in terms of the applications, how would you ever apply this unless you go into actuarial sciences or something very specific, but now I actually rediscovered statistics for myself just recently when I was creating the statistics course. It’s so interesting. There’s so many different applications you can do in analytics and data science.Yeah, thank you so much for that overview. It’s great that you have this perspective, that you’re not missing out. You’re actually learning something new. You’re progressing in a bit of a different direction, but at the same time you’re leveraging your skills where you can. I think Einstein said that if you’re not learning, you’re dying, something like that. So, if you feel that you’re not learning in your career, then why stay there, right?Virginia:\\tExactly. Yeah. I believe knowledge totally adds up. You’re never losing. You’re always increasing your capacities or perspective, actually. The more experience you have, the more knowledge you have, the more different perspectives you can have over happenings in your life. That’s all it’s about.Kirill:\\tYeah, totally. So what was the first step that you took? Was it that degree in Dublin? Was that your first step into data science, into analytics?Virginia:\\tActually, that was into business. I had no idea I would end up in data science. Actually, I am into this passion for having my own business and never thought that I could use a tool like data science to help me out. Lately I had this insight, like three months ago, I’ve been reconsidering to change my career because I felt very interested in the course. Mainly there’s a “Data Science A-Z” course that you offer on Udemy. That was amazing. I was really enjoying it and most of the time at work thinking of it, nothing else. So I thought, “Oh, my God. This is interesting. I could have many insights and if I had my own business it would leverage my career, my business itself to the proper insights.” I was thinking about it and I was studying this and during three months I was really keen for doing this. And inside AT&T I found this possibility. There were open positions and I just applied for it.Kirill:\\tOkay. That’s really cool, that you just applied and it happened that there were positions that you were interested in at AT&T at the time.Virginia:\\tYeah, it was a series of coincidences. I was feeling super interested in understanding it deeper and also there were these positions available at AT&T and I saw them. Usually I never see and this one really caught my attention, obviously, because this interests me. So I told them I have to decide if I will go for it, is this what I find more meaningful for me and to start this career in this area.Kirill:\\tOkay. That’s really cool. Tell us a bit more about AT&T. I’ve encountered AT&T in America. They do mobile phones, they sell mobile services. Is that the same company that you’re working for? Do they do the same thing in Europe?Virginia:\\tYes, it’s exactly the same company, but here they don’t do the same. Here we are managing the services or — in this case, I was into managing the database, the systems that are actually in there, in the U.S.A. So I was basically taking care of services in U.S.A., not in here.Kirill: Oh, okay. So it’s like an outsourced operation from the U.S. in Europe.Virginia:\\tExactly.Kirill:\\tInteresting. So what do you do currently at AT&T? I see on your LinkedIn it says ‘data integrity asset analyst’. What does a data integrity asset analyst do?Virginia:\\tWell, the moment I changed to this position, it is inside the asset life-cycle management of AT&T. It takes care of the assets, all the information of the AT&T assets. So we have to gather this, we have to collect all the data from software and hardware altogether from different database. Basically, as far as I can figure out, they’re being gathered by software that is called Asset Manager. Through these, we collect and analyse the data from AT&T systems and then we can compare and understand the overall data integrity.Kirill:\\tOkay. Very interesting. It sounds like you’re very involved in that first, initial part of the data science lifecycle where you’re kind of data preparation, data collection, data cleaning maybe. Not necessarily the full suite but that’s kind of your main focus. Is that correct?Virginia:\\tExactly. I see it at the beginning. I see they are cleaning the data. I can start to imagine all the things to do and I feel really excited to apply what I’m learning and also to use the tools like Tableau which we learn in your course.Kirill:\\tOkay. So does AT&T have Tableau or Power BI?Virginia:\\tAT&T has a partnership with Microsoft and we obviously have access to Power BI. But before I was hired, I was talking to the manager and I was really interested in having this experience with Power BI and the work, but she said we’re still not going to work with this. So I cannot wait for the time to bring it there somehow, find a way to make it more available.Kirill:\\tOkay. Wow, that’s very interesting. Sometimes it happens in life, I’m sure a lot of our listeners have the same situation where they don’t have access to the tools that they want to learn. In fact, I had the same situation. I was working at a company in the industry and I didn’t have access to R, Tableau, even SQL. So that was very challenging—Virginia:\\tFrustrating?Kirill:\\tFrustrating, exactly. I only had Excel. So I had to talk to managers and I had to ask them to actually bring those tools in. I had to make business cases why those tools should be here, why they’re important and so on. But in the meantime, what do you do? When you don’t have access to the tools that you want to learn at work, what do you do about progressing your learning anyway?Virginia:\\tThat’s exactly what I’ve done. I have asked for access to the ITO service which takes care of this are at AT&T. I have done these requests and also stated why I need it, and they’re still like—well, I’ve got to install Tableau because I’ve got to prove that it’s related, but the others are still on the go. By now, it’s what interests me, and also Excel. It’s helpful. So that’s it. That’s what I can use at work.Kirill:\\tOkay, interesting. And in terms of your role at AT&T, when you started that role—how many years ago was that again?Virginia:\\tThe role of DBA?Kirill:\\tNo, at AT&T.Virginia:\\tIt was 2015. January 2015.Kirill:\\tOkay. So you’ve been in that role for some time. I just want to understand for the benefit of our listeners, how do you think ahead in terms of a career at a company? Did you just jump at a role because you liked it or did you take something into consideration and you thought, “Okay, this role will take me to this type of data science work, which I want to do.” Did that happen in real life? What’s the situation there?Virginia:\\tWell, before taking this role, I was really studying the options I had. AT&T has an amazing software tool, let’s say web service, that offers us the possibility to see the career progression. So, in the area of data science, graphics are also showing how many are getting into this job, how many are getting out and even what you have to know. And a portal to get this knowledge is also there. So a specific subject into the data science area and how to get there and the progression also, where you end up.Like in this case, data analyst in the asset life-cycle management, I would be in the quality management. It would be the end of my career in this area in AT&T. (Laughs) So AT&T gives this—let’s call it Career Intelligence and iCareer too. They are two websites from AT&T that give us a background. Like we can have a clear idea where do we go if we choose this role. That’s what I was doing. I was really concerned where I would end up if I choose this. This was from the choice that I had, the most interesting, the most similar to what I would like to have, at least start an experience hands-on with data.Kirill:\\tOkay. That’s very interesting. And what would your recommendation be to listeners of the podcast who are considering a career in data science? How would you advise them to think about their career? What things should they take into consideration? Because making the first move in your career is a big thing. Like applying for a job, getting the job, and agreeing to a job is a huge step. So what would you recommend to them to consider when making these decisions?Virginia:\\tFirst of all, I think this should be based on knowing yourself, what you like doing the most, so that you won’t regret your decision later on. Because you’re totally sure about who you are, your values, and what you like most. Once you are aware of that, you can make a clear decision. Not because this is the big fashion of the moment and the area that will earn you lots of money if you go successfully, but because you really find it meaningful in your life, you really find this is a tool that you can go totally into without regret. So if you’re feeling that, I totally support you on choosing, on deciding. If not, I support you in studying exactly where you want to go, what you feel most attracted to before taking this decision.Kirill:\\tOkay. That’s very good advice because I agree with you that there’s so many areas of data science that a person could go into. There are so many different tools that you can study, so many different types of data science, so many different applications, methodologies and so on. It’s probably impossible to learn everything and be very good at everything and have a career in everything. You’re going to have to choose inevitably. So I totally second that opinion. You have to understand what you like, what’s the best thing, what’s the best fit for you personally regardless of what the hype is about. If everybody is talking about machine learning, but you don’t like Python programming or R programming, maybe you should be doing something else.Virginia:\\tFor example, you can see people are excited by Java programming. Since I entered IT, it was like the boom, all my colleagues were going for that, but I said, “No. I don’t feel like programming. I admire if you’re doing it with all of your passion, but if not, it doesn’t make any sense.” It’s 8 hours – if for example you’re working at a company, 8 hours of your life daily for frustrating tasks. I think we should really consider the paths we take based on what we most like or who we think we are and who we really are.Kirill:\\tExactly. I agree with that. For all students listening to this out there, I often get asked the question, “Which course should I start with?” You know, Kirill, you have like 20 courses on data science. Which should I take? Where should I go?” And the thing is, the answer for everybody is different. It depends on what you feel like, what is the best thing for you. Don’t get distracted by the fact that just now we released the course on deep learning or we released a course on something else. And that’s like the hype of the situation.You really have to be honest with yourself what is the best thing for you. If you like visualization, if you like Tableau, just do Tableau, do visualization and get really good at it. This field is booming so fast that there’s going to be job opportunities pretty much in any space of data science, wherever you decide to go.Virginia:\\tYeah, I would consider to look at yourself, what you feel more interested. Like, when you experience curiosity you are trying out. What made you to want to try that out? It’s an interest. How far does interest go? How many times you’ve been into this? How much are you really interested? So that’s what you like doing the most. That’s how I figured it out.Kirill:\\tI was about to ask, what did you figure out for yourself? What is your most interesting thing in data science?Virginia:\\tWell, first of all, it’s business. My idea is finally having business, mostly in the area of social development, like social organizations. And I would really like to create my own business in this area or at least make part of this. I cannot find any other tool other than data science to help me out with these to gather the best of it, like to see the trends and instead of just making profits—like, you can take the tools and make profit with your personal business, but you can also do it with a good social purpose. We are here to add up in the society, and why not? That’s super powerful to boost my intention to have my own business in this area.Kirill:\\tInteresting. Let’s talk a bit more about that. I noticed in your LinkedIn you actually—(Laughs) It sounds like I’m stalking you on your LinkedIn, that’s all I’ve been talking about! I’ve just got it open right now in front of me. You have been involved in quite a few volunteer opportunities. For instance, you were involved in the Africa Centre. Can you tell us a bit more about that just briefly so that we can get a feel for what kind of person you are? And then we’ll talk more about business opportunities in data science.Virginia:\\tYeah. In Ireland I had to study and I could work also for a limited time. I decided to go for things I really was interested in. Like, I was already into business and I was very close to the idea of how could I influence society, which are the NGOs here that are doing something about society? So the ones that I have noted that I am more keen to help are about the refugees and also these excluded societies like black, poor — just excluded societies, people that are just left without much options. So I went for that. I went to these institutions to check what they were doing and to see how I could be helpful for them. And that’s basically it.Africa Centre is gathering the youths, the teenagers mostly to bring the consciousness about the service provided, cultural services for them to keep their roots alive, to feel that they are not alone, that they have the support. It’s amazing job, what they do. I was directly involved with the director of the company and I had nice ideas with him to improve the business. I was mostly managing the projects that he had, like altogether. We had other people from his staff to promote this information to the African community inside Ireland.Kirill:\\tOkay. That’s very interesting. Thanks for that breakdown. Very noble thing to do, to participate in volunteer opportunities. Now moving on to your idea of using data science in business for good, can you tell us a bit more about that? I know before the podcast you mentioned a company called DataKind and how they use data for social good. Maybe let’s start there. What is DataKind, what do you know about them, and how do they use data science for good?Virginia:\\tWell, first of all, I know Jake Porway, he is the founder and executive director of DataKind. I actually found him because I was checking which companies working into data science are interested in working with social good. So I found this DataKind company which does work that I really admire. Basically, they’re helping to bring together data scientists to promote high impact in social organizations, to better collect, to better analyse, to better visualize the data in the service of humanity to decrease poverty, to decrease violence and all issues that we have in the society.Kirill:\\tVery interesting. It sounds like a very passionate person and somebody that I would love probably to invite to the podcast as well.Virginia:\\tYeah, that would be very interesting, to have this person. And there is also a woman — because I’m kind of a feminist — there is also a woman in this area. I don’t know if you heard about her, but—Kirill:\\tWhat’s her name?Virginia:\\tClaudia Perlich. She’s the Chief Scientist in Dstillery. That is also a company. In her case, she is providing market intelligence. She has a brilliant mind and is a really great data scientist in the area. I get inspired with her and her data mining knowledge. She has some presentations on YouTube that inspire me, too. So, basically, both of them together is my view of a good data scientist.Kirill:\\tOkay, that’s pretty interesting. Very inspiring people and very inspiring initiative, sounds like it. But what about your idea? What are you thinking of using data science in your business to help use analytics for good?Virginia:\\tWell, using the prediction models like Claudia does to figure out the trends into social issues basically regarding refugees, which is a critical issue here in the European Union. So I’m really interested in gathering the data to offer them support, shelter specifically, mainly care of children. But I am aware that I need to be in touch with many, many other companies and NGOs that do this same service to have a broader experience, not just what I had in Ireland but much more contact. And in this reality that I ended up in Slovakia, I’m a bit far from it, but it is still my biggest desire. We are talking about the end line, my biggest desire to use and develop great knowledge about data science on helping me to furthermore invest on this business idea.Kirill:\\tOkay, that’s pretty cool. So you’re still searching? Still developing your network and contacts to start a business?Virginia:\\tYes.Kirill:\\tIf you don’t mind me asking, why are you so confident about starting a business? There’s so many different areas you could apply data science on. Why are you so set on starting a business and what helps you keep that passion alive?Virginia:\\tWell, that’s a great question. Honestly, I was always troubled in my life with the idea of starting up my own business. I say ‘troubled’ because the society’s conventional ways don’t usually convey to supporting our creativity. Most people are training to be part of an already existing working idea. Therefore, pursuing my own way to do my own business, it’s something that would really give me satisfaction. I don’t have to follow the rules of any other person that created any other idea.I have these values that brought me to a specific idea and I would like to put it in practice. Of course, with the best skills that I have, so I would build it strongly. And why not? We are usually raised to go with the flow and just work there to have money and keep ourselves fine, but I think life is much more than that. We are here and we are very valuable so we can add with our own ideas and create our own ways.Kirill:\\tThat’s very inspiring. Thank you for sharing that. What would you say to somebody listening to this podcast who maybe thinks similar to you? I think many people — maybe everybody even – has some sort of passion, some sort of ideas of how the world could be better. What would you say to those people about how they can get excited about that? And what kind of first steps can they take in the direction of starting their own business, in the direction of becoming more independent in their thinking and not just performing the work that they’re doing at their jobs – even though they might like it – but also creating that opportunity for themselves to implement these ideas into something material and make them come to life?Virginia:\\tI think it’s all about passion. When you have been honest with yourself in choosing that career that you really like, this might be a natural result because you are so excited in this area that you start to have your own ideas. And why not put them in practice? So I would advise to who is listening and is into this same perspective of mine, the same objective, I would advise you to just pursue your passion. Just because it’s comfortable, don’t let it be like that. Go for the challenge. Your passions are going to hold you tight there and will make you succeed if you are really into it. So don’t be afraid and really try if you find this is your passion. That’s what I would advise.Kirill:\\tFantastic. Thank you for sharing that, it’s great. And you mentioned challenges. What is the biggest challenge that you’re facing right now in terms of making all of this come to life?Virginia:\\tThe biggest challenge right now is how to apply the knowledge into my work because I want to make it real and I know that data science is about real problems, it’s about reality. We can solve it. So I want to have this knowledge I’m gathering, apply it into my work – this is the starting point. So I will be more and more familiar with it and then have a broader experience. And this is the biggest challenge because the biggest experience would be what will guide me to my dream basically.Kirill:\\tOkay, gotcha. That’s very interesting. Yeah, it’s very interesting how you think about it. You want to first start by getting the experience and then move onto your dream. It’s interesting you mentioned that because I was actually thinking about that myself just recently. What I do in my business and what I’m working with, a lot of that would have not been possible if I have not spent enough time at university, at my career in Deloitte where I was doing consulting, at my career in the industry where I was building a data science team. And at the time for me it felt like maybe it was just exciting projects.At Deloitte there was lots and lots of exciting, fun things, I was flying all over Australia doing really cool data science projects and then maybe it was just overcoming challenges. Also there was a sense of obligation that you have to have a job to pay the bills and so on and so forth. And slowly my dream was growing and growing and growing into something bigger with time.But now looking back, I see that if I had not done the job at the industry, if I had not done the career at Deloitte, I wouldn’t have had the right experience, expertise and background in order to do what I’m doing now. And I’m really thankful to my past self for spending that time, those three years or more if you include university and other jobs, in doing what I did because it helped me build all this vision and especially the expertise to do the things that I want to do now to actually make my dream come true. So that’s some great advice, I think.Virginia:\\tYeah, you are building yourself. You are finding out what you like most and now you are receiving the product of that. I believe the result is this.Kirill:\\tYes. So, for those listening out there, I think it’s a great tip that if you have a dream of doing something, then probably when you’re young, it’s harder to understand the pathway to your dream. You just go with the flow or you do what you’re passionate about. But even doing what you’re passionate about is a great compass in life. It helps you because it will guide you to your dream anyway. But if you’re already a bit experienced, you know what life is all about – it’s kind of hard to know, but you know a thing or two – it’s a bit easier to sit down and think, “Okay, what is my dream? And how do I build my path towards my dream?”This is interesting. I was saving this up for a Five Minute Friday episode, but I might say it here. There’s a difference between dreams and goals. This was told to me by my mentor who was taught this by his mentor, so it’s trickled down quite a long way. Dreams are things that you want to accomplish in life full stop. It’s just something that you would want to accomplish one day, whereas goals are dreams which have a timeline. So once you say, “I want to do this by this date, that’s a goal.” But if you don’t have a date and it’s just something you want to do, something that you’re passionate about, something that you’re working towards, it’s a dream.Virginia:\\tMakes sense.Kirill:\\tYeah, thank you. So it’s important to understand not just what your goal is for the next year, next three years, next five years, but to understand what your dream is. Because the thing with dreams and goals is if you get them wrong, if you set your dreams as goals, if you say, “I want to start a business in three years,” then what will happen is you will get frustrated if you’re not coming closer to your goal, if two years pass and you’re not even one step closer. But if it’s a dream, then you will still be doing what you’re passionate about and your passion will guide you towards your dream and one day it will become a goal.Virginia:\\tI believe that it is very productive if you set your dreams as a background to your goals. They are essential for you to reach your goal. Without them, maybe you’ll never realize. And some people just like to dream about it and not really put in practice. So the goal will make you realize what you really want. Sometimes in a point of your life you have such a specific dream and through your goals you maybe are reaching there but on the way, you find something else.So in this pursuit of your dreams, you are finding who you are, what you really want. Dreams can change too, and we should put them in the background of our goals and bear in mind that it can change. And we should try, many times, to really figure out how to see it and think about it, but we have to have hands on to understand where we really want to go, not just what appears to be.Kirill:\\tFantastic. I love it. I love the concept of having your dream as the background for your goals and for things you’re doing. That’s a great idea, so that everything you’re doing and learning and working on is with that in mind so you always think, “How is that in the direction of my dream and how is that going to help my dream?” That’s a great idea, I think. Okay, I have just a couple of quick questions towards wrapping up. In your learning of data science, what is a recent win that you had that you can share with us, something that you’re proud of that you’ve accomplished, some breakthrough that you had? Is there something that you can share with us?Virginia:\\tLearning and—Kirill:\\tOr maybe in your role. Either/or.Virginia:\\tThe fact itself that I got to change my career to this data analyst position is just a start, it’s just a beginning, it’s really something I’m really happy about, really excited. But I have less than one month in this position so what I could have done, it’s hard to say it is solid by now. I would like to apply what I’m learning, I would like to visualize the data and the trends, where it is going. There are many things that I would like to do, but I need to have more experience to understand the process behind it and finally to see the trends and the insights about it. It’s too early to say something.Kirill:\\tNo, that’s a good answer. You just got into this new position. And I just realized that you were a tech specialist in database administration at AT&T and it just only happened a month ago. I thought it was actually two and a half years ago, but it just happened a month ago that you moved into data science. Very exciting. Congratulations on that.Virginia:\\tThank you. This achievement itself is really exciting for me.Kirill:\\tAnd it happened inside AT&T, right?Virginia:\\tYes.Kirill:\\tI’ve heard a lot about that and I’ve seen that happen. To keep talented people, companies open up opportunities to move around within the company. Do you have any advice on that? How would somebody who is in the company that they love, how would they approach the question of, “I actually want to change my role to be more focused on data science?”Virginia:\\tFirst of all, your manager should be keen with this idea. I always had great communication with my manager and in AT&T, we have to go directly to the manager to talk about this idea of changing position. And also, when we go to apply on the website to [indecipherable 49:44] change, it automatically goes through the permission of the manager. So if you have a good understanding with your manager, and mostly if your manager is aware of your skills, where they are going to, what are your passions, and is willing to support you.In AT&T it happens like that. Your manager is going to help you. Fortunately, in my case, that’s what happened. My manager said he would support me in this passion that he has seen, that he acknowledged. I have more focus on data than anything else, so he advised me and told me not to be afraid. So, first of all, analyse how is the situation. If your manager knows you well enough to believe that you can really change to this new position. If not, I think you should work on this relationship, if the politics are similar to AT&T. I don’t how it works in other companies, but that’s how it works for me. Fortunately I saw this position available so I could apply for it and all went fine.Kirill:\\tOkay. And how would you compare an interview – I’m assuming that was an interview – an interview when you’re already inside the company versus an interview when you’re joining a company fresh? Is it different?Virginia:\\tIt’s much more comfortable. You feel much better then. You are at home, you’re just changing rooms. You know everybody. I have a good relationship with my former colleagues and the actual colleagues are also amazing so they welcomed me and everything was — I know how the process works in AT&T, so it’s easier to go for it and it’s easier to change inside, I believe.Logically, they feel more interested in their own people than in the external ones because they already know the process so we will skip the part of teaching how it works, going through trainings. Because when I was at AT&T for the first three months, I was in too many trainings to understand the process and to understand how it works there. So when they skip this, it’s an advantage. I felt like this.Kirill:\\tOkay, that’s great. Thanks a lot for sharing it. I think that can be useful inspiration to a lot of our listeners who might be considering other roles, like, being in data science but then thinking, “Oh, this whole interview process is challenging.” But maybe there are roles for data science in your organization already that you could consider for yourself. And that brings us up to the end. We’re running out of time already. Thank you so much, Virginia, for coming on the podcast. I just have one last question for you. What is a book that you can recommend to our listeners that could help them become better data scientists?Virginia:\\tWell, I would actually recommend an audio book that I’ve lately been into and has been giving me insights about the main tool that you have to have before everything – that is statistics. “Naked Statistics” is the name of the audio book you can find on audible by Charles Wheelan.Kirill:\\tOkay, great. Thank you. What did you like about the book?Virginia:\\tIt is inspiring. It’s telling in practical terms how statistics is not boring at all when you find meaningful data through it. It’s just simplifying the terms. Most people are taught about how bad statistics is because of the hard terms to understand. But when you find meaningful data behind it, you will just think the opposite. You’ll just find it amazing. That’s what I’m feeling. I’m still listening and this has been inspiring me lately, altogether with your courses which are really, really good.Kirill:\\tThank you. So, “Naked Statistics” – guys, check out that audio book. Virginia, how can our listeners follow you or contact you if they’d like to know more about how your career progresses and what you achieve and maybe one day how you use data for good?Virginia:\\tI have a website in Jimdo. I don’t know if you are aware, but it’s a platform to create websites. I have created my homepage there so you can know more about me there altogether with LinkedIn. At Jimdo, it’s just virginiammg.jimdo.com.Kirill:\\tOkay. virginiammg.jimdo.com. I will definitely include the links in the show notes, and also LinkedIn. Once again, thank you so much for coming on the show and sharing your experiences and most importantly, your experiences in learning and vision for your future and how you think about your vision. I think it’s very inspirational, what you’ve shared.Virginia:\\tI thank you very much for bringing me here and sharing this with your listeners. Thank you very much, Kirill.Kirill:\\tThank you. Have a great day. Bye.Virginia:\\tYou too. Bye-bye.Kirill:\\tSo there you have it. I hope you enjoyed today’s podcast. We definitely talked a lot about career-related things and all these different aspects to selecting your career, selecting how you want to progress towards your future, understanding what you’re good at and what you’re actually passionate about.My favourite part of this episode was when we spoke about how you line yourself up for success in the future. You might have a dream, but maybe it’s not the best idea to just jump at your dream right away. Instead, get some experience, create a name for yourself or get the right skills and tools in place in order to be successful in your dream. Virginia definitely showed a great example of that where she has a dream of doing good for the world through data, but she also understands that she needs to develop those data science skills first before she can jump into that and that’s exactly what she’s doing.I think that was a very inspiring message that was delivered there and definitely something for you to consider in your career. Where do you want to end up? Where do you want your career, your life to take you? And what skills or expertise or experience do you think you need to line up in order to be successful at that? So something to consider and, as always, you can find the show notes for this episode at www.superdatascience.com/53. There you can also get the links to Virginia’s LinkedIn – don’t forget to connect with her there – and her website. And on that note, I wish you a pleasant rest of the week and I look forward to seeing you next time. Until then, happy analyzing.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds['text_episode'].loc[52] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c663fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column host_episode to sds dataframe\n",
    "sds['host_episode'] = 'Kirril Eremenko'  # Set initial value to 'Kirril Eremenko '\n",
    "\n",
    "# Set value to 'Jon Krohn' from column 430 to 681\n",
    "sds.loc[430:681, 'host_episode'] = 'Jon Krohn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2507a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc10f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds.to_csv('../data/sds_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['guest_info'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b10a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['text_episode'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['guest_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['guest_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d7bd1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kirill:\\tThis is episode number 39 with Director of Data Science at VSCO Ruben Kogel.(background music plays)Welcome to the SuperDataScience podcast. My name is Kirill Eremenko, data science coach and lifestyle entrepreneur. And each week we bring you inspiring people and ideas to help you build your successful career in data science. Thanks for being here today and now let’s make the complex simple.(background music plays)Hello everyone. Today we\\'ve got the legend, Ruben Kogel, returning for podcast session number 2. Ruben was my very first guest on the SuperDataScience show, back in August/September 2016, and since then it\\'s been about 6 months, and guess what. His podcacst, his session, has been downloaded and listened to 10,000 times. Over 10,000 people have listened to his session. How incredible is that? Very excited about all of the knowledge that people gained from that one episode that we recorded back in 2016.So it\\'s going to be very exciting to catch up today again, and we had a fantastic chat. We talked about many different things, and specifically here is a couple of them. So Ruben joined the team at VSCO and he built up a data science capability from the ground up. And he mentions the three points that he focused on when building the capability, so this will be very valuable to those of you who are looking forward towards more senior roles, where you\\'ll be in charge of some elements of the data science inside the organisation.Also, we talk in detail about what Ruben is looking for in people who he is hiring for VSCO. Ruben right now is hiring data scientists for a team in VSCO and he explains the actual skillsets and mentalities that he\\'s looking for in people he is hiring. And apart from all that, of course, there\\'s lots and lots of other value that we\\'ve discussed on this podcast, and I just want to reiterate again, Ruben is hiring, so at the very end of the podcast, we speak about how you can get an opportunity. And VSCO is actually in Oakland, San Francisco, and I know that a lot of you guys are in the San Francisco Bay Area, and a huge number of you are in California.So if you are interested in a data science position at a company with an amazing culture with Ruben as your mentor, this is an opportunity to die for. So if you\\'re interested in that, if you\\'re open to new opportunities, even if you\\'re not, I would highly recommend checking out their job description. You can get it if you go to Ruben\\'s LinkedIn or the show notes. You\\'ll be able to see the link to it, but in short, it\\'s bit.ly/VSCOdatajob. So definitely check that out. I think that there\\'s going to be so much interest in this opportunity, it\\'s going to be a first come first served basis. Definitely make sure to jump on top of this.And on that note, without further ado, I bring to you the legend, Ruben Kogel, Director of Data Science at VSCO.(background music plays)Welcome everybody to the SuperDataScience podcast, and today, by popular demand, I have our favorite guest Ruben Kogel back on the show. Hi Ruben, how are you today?Ruben:\\tI\\'m doing great. It\\'s great to be back. Thank you for having me again.Kirill:\\tAwesome. What an intro, right?Ruben:\\tYeah!Kirill:\\tAnd your podcast, 10,000 views. It\\'s mind-blowing. 10,000 downloads all over the world, people listening, watching. How do you feel about that?Ruben:\\tI\\'m kind of shocked! I always think like it\\'s not real! Because it\\'s just like you and I recording this podcast just a few months ago, so it\\'s kind of weird thinking that it had that reach. But it\\'s really great and amazing. I think it is also a testament to how good a job you did at marketing the podcast and reaching out to your audience, so really great.Kirill:\\tThanks man, thanks. But the thing that I think is -- you didn\\'t tell me before the previous podcast, but you were actually a radio host yourself! You gave me a little hint about it afterwards, and I looked you up, and you -- everybody listening, right away go and run and check out Ruben\\'s old podcast, which is called \"All That Swing\", right?Ruben:\\tYeah, \"All That Swing\". Yeah, it was a short-lived podcast!Kirill:\\tBut I listened to it, I couldn\\'t stop listening. It\\'s so fun, you mixing the music and so on. And no wonder that podcast started out well, because it was my first session and yet you had all this experience! So it’s a testament to you, you drove it home, man.Ruben:\\t(Laughs) Thanks. You want to hear a funny story? When I did this podcast, I had zero experience doing a radio show, a podcast, and I was really doing it out of a basement on some radio somewhere. I didn’t think anyone was listening to it. And one day someone calls in, and we had like this old phone ringing, so you had to wrangle and get the phone, and the person is like, “I really liked the piece of music you just played. I like the podcast, but can you stop saying ‘um’ in between every sentence?” It’s the kind of thing you don’t realize when you talk on the radio, on a podcast, but all those fillers, they are very, very visible and people can hear them on the other end.Kirill:\\tYeah. So how did you get rid of them?Ruben:\\tI don’t think I did. (Laughs)Kirill:\\t(Laughs) Okay, gotcha. You took that feedback on board, totally took it on board.Ruben:\\tYou know, I did a lot of editing. That’s what I did.Kirill:\\tYeah. I know what you’re saying. Oh, the editing, I remember the days. When you’re sitting at editing, you’re thinking “It’s probably a good idea to actually improve my skills so I spend less time editing.”Ruben:\\tExactly, yes. (Laughs) It’s definitely a good experience.Kirill:\\tYeah, totally. And it’s good even for data science, in terms of presentation later on, when you’re talking to people and presenting data stuff. Like, any kind of public speaking, whether it’s podcast or anything else, I think it’s a good experience.Ruben:\\tYeah, totally.Kirill:\\tSpeaking of data science, after the last podcast—it was very interesting. You were at Udemy and we recorded the podcast. And before I could release it, you had already left Udemy, so I had to put like a little disclaimer on the page that “Actually, Ruben is no longer with Udemy.” And that’s a testament to how popular and valuable data scientists are. So tell us a little bit about where you went and what have you been up to for the past six months?Ruben:\\tYeah. Shortly after recording our podcast, I accepted a position at VSCO. VSCO is a platform or mobile app for editing. It’s very popular amongst people who post photos on Instagram. They use it to edit photos because it has a really nice collection of presets and editing tools. But it’s more than that. It’s also a community of expression. We have a lot of professionals, so professional photographers posting photos on VSCO, discovering other people. It’s really a great, great community of photographers that we are building. I actually knew the tool and the app from doing some casual photography and I was really attracted to the challenge of starting a new data team and really building the data function at VSCO, not just pulling data and running analysis, but actually thinking around what kind of data do we need, how do we structure the data, what is the best way to look at it, how can I have the most impact on the product decision, on the strategy of the company. So it’s been a very interesting challenge.Kirill:\\tOh, that’s really cool. Like, building it from the ground up, when you come in and there’s pretty much zero, or a little bit, but you have full flexibility and full control. Is that right?Ruben:\\tYeah, there was already data and tools in place, but what was missing is a sense of direction and also we were at a crossroad where we were using too many vendors, too many tools, everything was competing, people were looking at different dashboards, different vendors to get their information. We just needed to rationalize a little bit how we were looking at things and also we needed to put in place a structure that would be scalable with the audience and the future of the app. So even though there were a lot of tools and great things that had been put in place, when I came in I had this mandate to actually take a look at everything, at all the vendors, all the tools, all the data that we had and decide which one we kept, which one we got rid of, how we would structure the data and what would be our 2 or 3-year strategy for collecting, storing and utilizing data.Kirill:\\tOkay. That’s really cool. So how did you go about that challenge? What was your thinking process?Ruben:\\tThe way I went about it was I talked to a lot of people. I set about to reach out or ask people to connect me with other people who worked at similar companies that had faced similar challenges and started just talking to them. And in the process of talking with them, some themes started to emerge, and some tools, and I started to form some opinions about what was better than other solutions. So, to give you more concrete examples, I spoke with the Head of Engineering at Slack, Head of Data Analytics at Instacart, people at Pandora, people at Twitter. I also started reading a lot of blog posts and it helped me get my thoughts around “Do we need to go with like a full-on data lay, put everything in Hadoop and then use Hive or Pig to look at the data and build dashboards on top of it? Should we use a solution like Tableau, which seems to be popular with larger organizations? Should we maybe use Redshift? Should we go into Google BigQuery?”So all those questions came and I had to sort of organize like, “Okay, why do we need to have these different solutions? What are the needs they are serving and what is the best architecture that will let us address all of the needs, that is both cost-effective but also scalable?”Kirill:\\tWow, that sounds like a really cool thing. I’m looking forward to digging into that right now because I think after a lot of the podcast sessions that we’ve had on SuperDataScience, people have slowly started to build up a good overview, understanding of all the tools that exist out there, and all the types of data science that exist. I think this could be like a good summary of how to put it all together. So, you spoke to all those people, you found out what they do, what kind of tools they use in that and what their strategic directions are. And how did you then assess your situation and what is relevant to you and then take those pieces of advice and implement them in your organization?Ruben:\\tYeah, that’s a good question. The other piece I only alluded to was that I had to look at the needs in my organization and the fact that I was a very small data team. I was basically a data team of one, so it was going to be impossible to provide the entire organization with on-going analysis. I had to find a solution that was more scalable.And what I realize is that for companies like us, that have a mobile app, or have like a platform that is consumer facing, a lot of the analysis comes down to recording events, recording taps, clicks, people going from one screen to the next and counting how many people did a particular action in a particular week in the U.S. versus not the U.S., on iOS, Android, etc. And for this type of analysis, there were already standalone solutions that existed and that were doing a fairly good job of it and also enabled anyone in the company to look at the data without being an expert in SQL—in fact, without knowing SQL at all.And so I realized that there were really different needs in the company. There was this need, especially for product people, designers, engineers, to have a quick look at the data, knowing over time how many people have published a photo, how many people have republished a photo, dice it maybe by country, operating system, and having that tool that let them explore the data very quickly and draw time series was extremely valuable. And if we were to rebuild that tool from the ground up, it would take enormous effort and resources and we wouldn’t even be able to match the kind of simplicity and latency that this tool offered.Clearly, there was a need here that was at the moment filled by a tool called Mixpanel. We can talk more about Mixpanel and the alternatives, but there was this need that had been identified specifically for product engineer people. There was a second need around creating dashboards and reporting tools that were very clean and that sort of conveyed a sense of truth, because oftentimes you come into these organizations, and people have been looking at data from different ways and it’s not normalized, so the CEO might be seeing something, the COO will see something else, the analyst will see something else entirely. So having a place where people can agree this is the truth, this is what’s happening on our app with our audience was extremely important. So that talks to the dashboards reporting piece.And the third part was around having a place that let analysts and data scientists do deeper analysis. That is the concept of a data warehouse. That’s the concept of you put all the data in one place, all the data is cleaned up, is verified, and that led people who manipulate SQL to do deeper analysis, do maybe some clustering or things that are deeper than just doing a time series or reporting. So, once I had identified the three needs – the product event analytics on one hand, dashboarding, and deeper data analysis – I think it was a matter of choosing the right technology and the right tools, making sure it was both cost-effective and scalable.Kirill:\\tYeah. Wow! That’s a really cool overview. I like what you said that in an organization like this, you need to really think about how you’re collecting the data. You need to set up the right data points for event analytics or for other things that you want to know what’s been happening with your app, how are people interacting with it. So, you set up those data points, and then you also look at the different needs in your company. You spoke about three: you’ve got the product engineers, you’ve got the dashboards, and you’ve got the deeper analytics for—Ruben:\\t—the analysts.Kirill:\\tYeah. So, is it like many different people, or does everybody have access to all of the data? Is it one team predominantly working on all of these things? For instance, product engineers, I understand they would have their own access. But for instance, dashboards and deeper analytics—is that one team, is that your team working on it? Or do you have separate teams for each one of these three points that you identified?Ruben:\\tIn terms of building those tools and data access, it’s actually different processes. The product analytics suite—we use Mixpanel, and Mixpanel basically hooks up to your mobile app and you just have to set up a hook for them and they automatically download all of the event, clean it up, augment it with location, add in some anonymous, unique ID, and put it in a very high-performance database and put a user interface on top of it to let anyone ask questions without writing in SQL.In that particular case, we are buying a service from this vendor, it’s a very high-performance service, and you’d be amazed. Like, running a query on billions of rows typically takes a second or two, so it’s a very, very optimized database, they actually run it directly in C. It’s not even SQL, it’s not Java, it’s like directly in C when you enter some command. So, it’s really optimized both for data reliability and data performance.Kirill:\\tOkay, fantastic. How many users do you have so that we know what numbers we’re talking about?Ruben:\\tOn a monthly basis, we have an audience of about 40 million people worldwide, and basically we have a billion events flowing every day. And because we like to instrument everything, we will record any time someone goes onto one screen, tap on a button, maybe do a quick view on an image, republish the image, do an editing, what kind of editing they did, what were the parameters, the sliders, everything. We have like billions and billions of events flowing, so in order to manipulate that, you need a very high performance data pipeline and database system.Mixpanel deals with all of that as a service. We don’t have to worry about any of it as long as the events are defined by our engineering team in the app, so they hardcode the events. As long as that happens, Mixpanel can collect all of it at the end of the app. They use an SDK and they organize, clean up everything, and make it accessible.Kirill:\\tGotcha. That’s very interesting that you mentioned how you collect all the data. Sometimes I hear comments from data scientists that there’s too much data, there’s too much data in the world, in their organization, and they’re getting overwhelmed with it. To be fair, not all data is useful. You can’t extract information, you can’t get insights from every single piece of data that you have. Most of the time you have to be very selective and only some of the data is going to tell you some stories. What is your view? Is it efficient for you guys to collect all this data and then go through it and actually pick out only the important stuff? For somebody else, would you recommend to instead just collect the data that is actually necessary? Why did you guys take this approach of collecting absolutely everything?Ruben:\\tThere are two reasons to collecting all of the events we do. And by the way, we don’t collect absolutely everything. There are things that we don’t collect but we do err on the side of collecting more than less. So, there are two reasons to that. One is, oftentimes you have product managers that are launching features and they are interested in understanding how users interact with a particular feature.To give you an example, let’s say that we just launched a subscription product, so we added a little tile on our apps so that people can click on it, they get brought into the store, and then in the store they can browse different products, including the subscription. So we are interested in following exactly what people are doing. We want to know how many people saw the tile, clicked on it, got into the store, viewed the product that is a subscription, and then eventually purchased it.Because once you have that entire view, you can start optimizing the flow, you can start finding maybe there’s a problem somewhere and that’s why your conversions are not good. So, it is important that you really have access to all of the data so you know exactly what’s going on and you know exactly how to optimize your app to maximize engagement and revenue. That being said, you may not need to record everything at all time. There are events that are only important to record for a certain period of time when you’re trying to optimize things and after that you can stop recording them.But it’s easier to over-instrument than under-instrument because what’s costly is not the instrumentation itself, what’s costly is then the storage and parsing through the data. But the storage itself, you can make a decision later on of “We are keeping this data and we are not keeping this data.” And I think that’s where the data scientists come in because they have an intuition of what is important and what isn’t important and they can parse the data and sort of separate the two.Kirill:\\tGotcha. Very, very cool. That’s some good advice, just record as much as you can and then remove some of it. Can you walk us through a recent example, out of what you can disclose, of how you went about in a project? I think in a situation like this, with all this data, it’s very important to ask the right questions, right? If you have so much data and then you don’t know exactly which question you are asking, you can get very lost. So can you walk us through a project and start off by how the person or whoever was requesting this project, how you guys went about asking the right questions and then solving it?Ruben:\\tSure. A project that I completed with something was looking at people who converted for a subscription. There was a general question of “Who are the people who are buying subscriptions and are they behaving differently after buying a subscription than they were beforehand?” And the question came to me exactly this way, so very general, and it was on me to start engaging the conversation and start specifying like, “Okay, what exactly do we mean by ‘Who are those people?’ Why are we interested in this question?” Basically, it was a question that came from one of the investors that got transmitted through our CEO.And basically I was trying to understand what exactly we’re trying to get out of it to help me orient the analysis. You know, it quickly became clear that the question was really a marketing question. We have all these millions of users that are potential buyers, but we know they are not all as likely to purchase, so we’d like to know who’s more likely to purchase because there are two things: one, that will tell us what is the size of the opportunity; and two, that will tell us who should we market this product to to be more effective in our messaging and be more effective with our marketing dollars. So once that was clarified—Kirill:\\tSorry, if I could interrupt here — what were the other options? It’s a marketing question. What were the other options that it could have been, just so we’re up to speed? What were you pondering? What decisions were you making?Ruben:\\tI think it could have been—you know, we just want to know, generally speaking, what those people look like in terms of maybe their behaviours in the app, or it could have been a question of what do those people look like in and of itself, like descriptive questions. You know, “We have all these people buying. Tell us a little bit more about them.” But instead, I took it as comparative questions. “We have all these people buying. What makes them different from the other people and what makes them more likely to buy?”Kirill:\\tOkay, gotcha. So a comparative question, as in an absolute question. For instance, when you were saying that, it came to my mind that you could have been asked that question to identify what they look like, not because you want to sell to them, but because once they’re in there you want to better service them, you want to maybe identify which products they like once they’re in the subscription membership. But instead, as you say, this indeed is a marketing question, so two different types of questions.Ruben:\\tYeah, exactly.Kirill:\\tSorry I interrupted you there.Ruben:\\tSo, once that was clarified, I think it became fairly straightforward because I know there are only a limited number of actions that can predict that someone is more engaged and is more likely to purchase the subscription, and all I did really was to collect all of those actions into one big table and then run some sort of analysis. It was not even a fancy statistical analysis, it was just a propensity analysis.So what I did is I said to myself, “Well, the things that are predictive of whether someone will buy a subscription probably are whether they’ve purchased something in the past and how much of it they have. Have they been active in the last 30 days, and how active have they been. What country they are in, because that might affect their purchasing power. Whether they are iOS or Android. So the list is really not that long, and once you have all of that, it’s really a matter of doing the right comparison.What I find was the most challenging piece of the analysis was not collecting the data or knowing which event to look at, but more like doing an apple to apple comparison because, for example, you might have a group of people who purchased the subscription in February, but out of that group, there are people who sign up to VSCO in February. So they have no history before February.You also have people who were completely inactive in the 30 days prior and somehow came back to VSCO because they saw an ad on Facebook or Google, so they randomly came back. You had to be very careful because you can’t compare the people who just signed up in February and bought a subscription with people who were active in January and didn’t buy the subscription. So I think it’s important to establish the right comparison here, which in this case was, “Let’s take a segment of people who were active in the 30 days prior to February and let’s look at the people who did purchase and the people who did not purchase.” Because then we have like a fixed base of the people who did that same thing, they looked exactly the same in January, but somehow one portion of them did purchase and one portion of them did not purchase. So establishing that baseline is very important, and once you have that, it makes it a lot easier to compare the two groups.Kirill:\\tYeah, very cool. Love it. And you mentioned you do some propensity modelling on that. Why did you choose propensity modelling over logistic regression or other types of classification techniques?Ruben:\\tBecause I think I didn’t want to overwhelm our team with unnecessary complexity. I didn’t think that the goal here was to have one formula that would predict the probability of someone buying. I thought more important was to surface trends and surface propensity according to different dimensions. So to be specific, the kind of thing that we looked at is, “Does the fact that you are on iOS make you more likely to buy a subscription, and if yes, by how much?” It doesn’t matter that you’re on iOS and you live in Australia and maybe you’ve used like three paid presets in the last 30 days. Altogether increase gives you a likelihood of 30% or whatever it is. What matters is, on each individual dimension, how much more likely you are to convert because then we can start narrowing down our marketing effort to those people. And we can also separate out the effect of all these different variables. So, in a way, it’s a much more natural and clear analysis to communicate to the marketing manager rather than coming up with a long logistic regression forming at the end.Kirill:\\tYeah, got it. And that’s been a very interesting kind of trend that I’ve seen in this podcast. A lot of the time, people like yourself who have the skills, who have the access to the tools and methodologies, you sometimes (but not always) choose to use a simpler approach simply because you have a further agenda after your analysis is complete. You’re not just delivering a consultant report. You’re part of a team. You’re building something. You want the company to succeed. You want the marketing manager to understand what’s going on rather than having this convoluted formula which might add an extra 10% or 2% accuracy, but overall it’s not going to add that much more value because they don’t understand how to use it properly.Ruben:\\tExactly. I think here the key is that you want your recommendation to be actionable. You want people to understand what the analysis says and to be actionable, so telling someone that being in the U.S. gives you like a 50% lift over other people to convert or having purchased a paid preset in the last 30 days gives you like a 60% lift, that is much more clear and actionable than saying “The overall probability is blah-blah-blah.”Kirill:\\tYeah, gotcha. Very interesting example. Thanks for that. The other thing I wanted to ask you and really pick your brain on, being in your position, as we discussed at the start, just before the podcast, you are a Director of Data Science, but a lot of the stuff that you’re doing is also strategic. It’s also which database systems are we going to implement, who’s going to have access to what and so on. You’re performing the role of Chief Technology Officer in combination with Director of Data Science, as I understand it.A big part of that is spreading the culture of data across the organization. And that’s something I’ve personally faced in different roles I’ve been in, and it’s often tough to get that culture or appreciation across to people so that they become data advocates, that they help you out, that they look for these things in their own roles, how they can apply data and so on. So, how have you been dealing with that? What kind of challenges have you faced and the opposite – what wins have you had in the space of data culture in your organization?Ruben:\\tYeah, it’s a good question because I think you touched on something that’s much more practical than running a machine learning algorithm or regression, it’s like how do you have an impact on your organization and how can you be effective? I would say that generally speaking, people are open-minded and everybody wants to be data-driven. The problem is that sometimes data is not accessible, or it’s too complicated, or people don’t have the time or patience to figure out exactly what’s going on.And so my role as Head of Data at VSCO is to sit down with people and make sure that one, they have access to the data that they need, but also that when they are trying to make a decision, and they always want to make a data-driven decision, but when they are making that decision, that they are looking at the right data, they are looking at it the right way, and they understand the trade-off of the data and they understand the limitation of what the data can say. So, to give you a concrete example, we actually have a weekly meeting between my team and the product team where it’s kind of like a freewheeling meeting, but more often than not we talk about some of the analysis that I came up with, or we talk about some of the A/B tests that the PMs run.It’s actually a forum where I get a chance to educate the team on how to interpret data, how to interpret the results of an A/B test and what the data says and what the data doesn’t say. It’s been really the source of great conversations. In particular, we’ve had great conversations around how to interpret the results of an A/B test, what is significant, what is not significant, whether one week of data is sufficient, should we look at just one metric, should we look at more metrics and retention, etc. I think the key here is really having an on-going conversation and trying to serve the needs of the people who are making decisions and are trying to use data to make decisions.Kirill:\\tYeah, that’s great. I think that’s a very valuable thing as well, training up the staff and having that opportunity. It’s good that they’re very open to meeting up with you on a weekly basis and having this discussion because that’s a first step, for people to be open with that. And what’s your vision for that? What’s your vision for spreading the data culture in the organization? I know that you’re still in the early days, just six months there. But say in two or three years, how would you like to see every employee in the company? To what level would you like them to be able to interact with data?Ruben:\\tYeah, I think there are already tools in place that let people access the data. We talked about Mixpanel. We also have a dashboarding tool that lets people see the key metrics and play with the key metrics a little bit. I think the key is that I want to be able to automatically answer 90% or 95% of people’s general questions. I think the role of the data team is not to do data pools and do like a SQL query to find out the number of users who did that or the number of people who’ve purchased in China or in South Korea in the last month. All of this should be answered automatically with self-service analytics, something that we talked about in our previous podcast. So there is that.The second part is also that people who make decisions around data, particularly product managers, I want to make sure that we have a very solid framework for setting up and analysing A/B tests. Basically it means that we have a playbook of “Okay, these are the rules of how you design an A/B test, how many people you put in each bucket. Do not touch your A/B test for like two weeks so that you don’t mess up the bucket. And then, when you analyse the results, I want to you to go into this dashboard and to not just a particular funnel, but look at bunch of other metrics and check that they are not affected, or check that the retention is also there.”It’s basically a combination of making sure that everybody has access to the tools and is comfortable with using the tools, so they go through training, but also setting up for more specific use cases, like funnel analysis, A/B test analysis, setting up like a playbook and making sure that the people who are going to own those features know how to run the analysis, because at the end of the day, I think even doing an A/B test analysis is something that’s pretty programmatic, you know, you can follow a set of rules. I don’t have to redo the analysis every time. I don’t have to have my team redo the analysis. I can just set up the dashboard, set up the guidelines, and have the owner of the product do the analysis on their own. So that’s kind of like my vision for how I would educate the team around the use of data and how I would empower the team to use data.Kirill:\\tOkay. That’s pretty cool. What it reminds me of is, there’s a company in San Diego called Digital Marketer. It’s a large company for marketers and how to do online ads and stuff like that. But I like how they’ve got it set up. They’ve got like a set of onboarding training which, actually, they have been so successful within the company that they have made them available. You can subscribe to them, and in SuperDataScience we use some of their trainings as well. You can subscribe to them and your staff can go through this training and some of them are like A/B tests and statistical analysis for marketers, of course. But at the same time, it’s pretty valuable and I like the structured approach. It kind of reminded me when you said that a lot of it has to do with education, so when somebody new starts, or maybe once in a while employees can go through these trainings and educate themselves on how to use these tools properly. That’s very important.The other thing I wanted to ask you while we’re on this topic, you’ve touched on A/B tests several times, so maybe you can educate us a little bit. What is your rule of thumb for an A/B test? What should the sample size be for an A/B test to most likely be statistically significant? Do you have a rule of thumb?Ruben:\\tObviously, it really depends on the size of your audience, the number of people who will see the particular thing that you’re changing, and the conversion rate. There are like pretty standard calculators online that will tell you, you know, “You need that many people.” Typically, in our case we need like 5,000-10,000 people in each bucket because we are interested in looking at meaningful changes.One of the things that I warn people against is running a lot of A/B tests just trying to optimize the button or an image and trying to see small changes because I don’t think that’s the right way of running an A/B test because one is, you will always have false positives. Even when you run a test at 95% confidence, it still means like 1 in 20 you’ll have a false positive. So if you run five tests in parallel, all of a sudden you have a much higher chance of just hitting a false positive.And second is because I think it’s important to, even when you run an A/B test, to have a hypothesis behind it. You’re not just testing random combinations of things. You are testing a hypothesis. You are saying, “I’m going to change the conversion flow on my store from A to B” or “I’m going to make the shopping cart much more prominent and therefore I think that people will see it and I think people will convert at a higher rate.” So it’s important to test the hypothesis and it’s also important to hold yourself accountable to a big change. You don’t want to optimize things and move like conversion from 10% to 10.1%. You want something that will move it meaningfully, that will move it from 10% to 11% or 12% or 15%. I think that’s the right way of running A/B tests. And when you do that, it also means that you don’t need as big of a sample because you are really looking for big changes. And if you don’t see a big change, then maybe it’s not that meaningful of a test.Kirill:\\tYeah, gotcha. And last time you were on the podcast, you recommended a book by Nate Silver, “The Signal and the Noise.” I actually have it here. I’m reading it and I know I probably should have read it years ago, it’s so good, but it talks a bit about what you mentioned now, and I want to reiterate this point for our listeners. Your tests that you’re running, they have to be meaningful and they have to make sense, right? Because in the book, Nate Silver does a good comparison of Bayes, who was 18th century or something like that, and Fisher, who was 20th century or maybe he was 19th century; Bayesian probabilities and inference versus Fisherian, as they call it, probability and inference, and how Fisher didn’t really like Bayes for this concept. A lot of the stuff that we do, especially in this just pure statistical testing, is actually developed from the concept of the—what were we talking about—Ruben:\\tFrequentist statistics?Kirill:\\tYeah, frequentist statistics, exactly. And therefore, we forget sometimes about the whole purpose, the whole idea behind the test. He has a good example in the book that if you use this approach, of just standard A/B testing, standard frequentist statistics, you can kind of prove that frogs can predict earthquakes just because there’s some correlation there, but correlation doesn’t always imply causation. So that’s a good example of you have to think about that what you’re testing makes sense. There’s no point even thinking about testing that frogs can predict earthquakes because it just doesn’t make sense. Even if you have a positive result, it’s most likely going to be a false positive, you know in advance. I think that kind of stands to the point which you raise.Ruben:\\tYeah, I totally subscribe to that. I think it’s important to be thoughtful when you set up experiments and when you analyse A/B tests.Kirill:\\tYeah, exactly. All right, moving on to my next area of discussion, your LinkedIn says you’re hiring. It seems like this is a credo that you carry through life. (Laughs) Wherever you go, you are hiring data scientists. I don’t think we talked much about this last time, but this will really benefit people listening. What are the skills—not just skills, what are the qualities that you want in your ideal candidate when you are hiring data scientists?Ruben:\\tThat’s a great question because I think there’s a lot of misconception about what it takes to be a data scientist and how do you get hired. There are a couple of things that are important. The first thing is sort of like a general business intuition and communication skills. I think it’s easy for people to get mired into complicated analysis, trying to spin up Python and run this crazy regression, maybe boosted trees or whatever, but not being able to one, bring in the right ingredients in the analysis, and two, explain what comes out of the analysis.Let me be a bit more specific. Let’s say that you were tasked with predicting churn of your customer base. I think probably one of the most important pieces of this work would be to come up with the right variables, the right features in your analysis that are most likely to predict churn. In order to do that, you really need some business sense and intuition. You need some data intuition so that you construct the right features in your analysis. And when you have the right feature, usually that’s like 80% of the job. It almost doesn’t matter what techniques you use to identify the most important features, having them in your dataset is the most important part and they will always come out at the end. So that’s very, very critical.And the second thing is then being to explain to a lay audience what does the result of the analysis mean because, again, if you’re just writing a technical note that no one will read, then you have zero impact in your company. You want to be able to talk to the CEO, to the product manager, to the marketing manager, and tell them like, “I looked at the data and the data says these are the five things that predict churn and these are the rank order of the things that predict churn.”Kirill:\\tYeah, totally. Break it down to them and make it digestible, accessible, the insights. And actionable, as you say.Ruben:\\tExactly. So that basically speaks to both business intuition and communication skills. I think what’s important on top of that is also structured thinking. Like what you just said, the ability to take a problem that is very vague and complex and breaking it down into more manageable pieces and coming up with a data question that corresponds to that business problem. Earlier we talked about subscription and the business question was like, “What do our people who subscribe look like?” You have to be able to turn this into an actual data question that will yield a meaningful answer, and the data question is like, “Oh, let’s look at all the people that were active in the month of January. Let’s look at their activity in terms of editing and purchasing, etc., and let’s look at what makes them more likely to convert than not.”So this ability to critical thinking, structured thinking, is also extremely important. And all of that has nothing to do with skills and knowledge. It’s really more about a way of thinking and grappling with problems. Now, obviously, there are important skills and knowledge. Number one, at least in my line of work, is SQL. You can’t really go very far without knowing SQL. Fortunately, SQL is a fairly simple language, so I would never hold it against a candidate if they are not experts in SQL because I think anyone can learn it. But having that baseline is important, and also having a very good understanding of statistics is crucial, I think. By that, I don’t mean to know every distribution and every statistical test on the Earth. I mean understanding a few statistical concepts and understanding them very, very well. Because people will come up with edge cases and this and that, that unless you’re very well steeped into your statistics you will not be able to answer.Kirill:\\tGotcha. That’s very interesting. I want to get back to that in a second, but before, I want to comment on what you said about it’s not about the skills. I totally agree with that. For instance, even when we’re hiring at Super Data Science, we not as much look at what the person can do in terms of how experienced they are or what skills they have.Personally, I look for passion. I look for drive. I look for purpose, meaning. I look for people who are eager, who can’t sit still. They want to know everything, and even before you’ve spoken to them, they already know everything about your company, they already looked everywhere and they know what they can improve, they come with value add propositions and so on. Those are the people that add value to the bottom line. I just wanted to comment on your point that it’s not only about the skills. In fact, it’s less about the skills than it’s about the type of person you are.Ruben:\\tYeah, I totally agree. In fact, there are a lot of skills that can be learned. I spoke about SQL being an easy language. You know, if someone can demonstrate that they have the ability to learn, they are very curious and they want to learn, then I wouldn’t at all hold it against them that they are not experts in SQL. Because I know that they will be able to master it and there are things that are more important to me than their pure technical skills on a programming language.Kirill:\\tYeah, I totally agree. And speaking of statistics, can you give us a few concepts, hypothesis testing, A/B testing, things that you think are important for a person to know, just examples, and then our listeners can pick and choose from there what they would want to focus on.And I’m asking because I very often get this question. You know, people start understanding the skills and the techniques and methodologies and tools in data science, but then they are still left with this bit of uncertainty that there’s so much statistics out there. Which concepts should they focus on in order to, as you say, when they come in to an organization, be well-grounded and be able to stand their ground in terms of statistical discussions and presenting their findings and things like that?Ruben:\\tThat’s a great question. I think you’ve mentioned a few. So, hypothesis testing is absolutely fundamental. And there are subtleties in hypothesis testing. It’s not something that’s very intuitive—in fact, it’s not intuitive at all, so really mastering the language and the logic behind hypothesis testing is very important, in part because that’s what people use to prove or disprove a hypothesis. That’s what people use to accept or reject an A/B test, so understanding that is very critical.Also, understanding the key statistics that are used to accept or reject an A/B test, whether it’s like a chi-squared test or whether it’s just a t-test between two variables is important. One other thing that I think is also important is to understand the concept around the central limit theorem. The fact that when you have individual events or individual users and you group them together, you always end up having some sort of a normal distribution.If you take—let’s say that we were looking at the average number of photos edited per cohort on VSCO, so we start with the January cohort, the February cohort, the March cohort, and we just take the average of number edited per cohort, it will obey a normal distribution, even though people individually are certainly not editing photos on a normal distribution. If you just took the distribution of the number of photos edited per person in a given month, that is an exponential distribution. You have more people editing one, then two, then three, then four. It’s monotonous and it’s decreasing. However, when you start taking averages, it always follows a normal distribution.So being able to move in and out of this concept and understanding that is actually pretty important, because few people really understand that. Another thing is regression analysis. I think it’s still pretty key. It’s a simple tool, but it can be pretty powerful when you have a few high-powered features or predictors. So being able to correctly interpret regression analysis, and also knowing the trade-off and the problems with regression analysis is important.Kirill:\\tAwesome. Yeah, the limitations of linear and multiple linear regression.Ruben:\\tYeah, exactly.Kirill:\\tGotcha. That’s been a great overview. So, hypothesis testing, mastering the language and logic, A/B testing, key statistics used for this, so it’s either chi-squared test or a t-test, central limit theorem, being able to jump in and out of understanding how things become normalized or turn into normal distributions when you do certain statistical changes to them, and regression analysis. I want to add one more, my favourite one which I always hold dear to my heart – the law of large numbers. It’s very basic, but the more times you do something, the closer your average is going to be to the expected value. You’ve got to know that one. (Laughs)Ruben:\\tYeah, totally. I totally agree with that.Kirill:\\tAll right. Cool. Okay, time flies with you, Ruben. We’re getting close to the end. I’m like, “We need a third podcast. Where is this going?” But I wanted to do a big shout-out to you, to your hiring in VSCO. I think about 30%-40%—I might be lying here, so I won’t say the statistic, but a huge percentage of our listeners are in San Francisco, not just in California, but specifically in the San Francisco Bay Area. So, guys, VSCO is hiring, and whether you have a job or you don’t have a job already, get in touch with Ruben and first come, first served. Ruben, you’ll probably get bombarded. (Laughs)Ruben:\\t(Laughs) No, I love the promotion. Thanks for the shout-out.Kirill:\\tYeah. So what’s the best way they can get in touch with you and see if this position is right for them?Ruben:\\tI think they can check it on my LinkedIn. I have a link to the position itself. I encourage people to check it out, see whether it vibes with their interest, with their qualifications. Feel free to either send me a message or apply directly on the website. I guarantee that we look at every single resume. Guarantee it! It’s not a black box, so either one of them works fine.Kirill:\\tAwesome. Gotcha. And I’m just looking at your LinkedIn. If somebody is listening to this in their car or something, it’s very easy to remember – bit.ly/VSCOdatajob. Check it out. If I was looking for a job, I would love to work in a team like that. I’m looking at some of your photos on the VSCO LinkedIn page. It looks like you guys have a really cool office, right? Is the corporate culture there pretty good?Ruben:\\tYeah. It’s actually one of the most amazing companies I’ve worked for. It’s actually really incredible. It’s a bunch of very smart, but very humble people that are extremely collaborative. It’s never about who did what or who forgot to do what or who takes credit for a particular project. It’s always, “Let’s solve this as a team.” If anyone sees any bug or any problem, that person will immediately signal it to the rest of the team and everybody will work to solve it. When there’s a big achievement, the entire team is recognized, not just the one person who drove the project. It’s a very relaxed but also very accountable environment. People know the job that they have to do and they do it because they know that other people rely on them, not because their boss asked them to do it. I really love it for that. In fact, it’s a very flat organization. Some day you might be working with the COO on a project, and another day you might be put in a team with a couple of engineers and product managers working on it. It really doesn’t matter who’s in the room and who asked to do it, everybody will perform the same.Kirill:\\tFantastic! Whoever gets this job or jobs, I’ve got an idea. Let me know that you applied from the podcast and you got the position and then next time I’m in San Francisco, you, Ruben and I will all go out for dinner and have a fun chat about how all this happened and came to be. (Laughs)Ruben:\\tAbsolutely. Dinner is on me.Kirill:\\tDeal. Thanks a lot for coming on the podcast once again and sharing all of this overwhelm of knowledge. Yeah, incredible.Ruben:\\tThanks for having me again. It was again a pleasure to talk to you and to your listeners.Kirill:\\tSo there you have it. I hope you enjoyed today’s session. Lots and lots of valuable information. So diverse, right? We talked about so many different things.We talked about the three points that Ruben focused on when he came into the organization. Ruben actually gave us a case study breakdown of how he went about analysing a project and answering questions and actually posing the right questions to answer in the first place. I think that was a very valuable example. Then we talked about the statistical concepts that Ruben is looking for in his ideal candidate and I think that was very valuable.I’m kind of torn between the two, what is the most valuable for me, the example that he gave of the case study, where there’s these two types of ways that you could pose a question, or the statistical breakdown. They both have merits, but I’ll probably lean towards the statistical concepts that he outlined. That is very valuable, just having that summary of the five statistical points that you guys have been asking me for so many times, like “What do you learn in statistics?” Well, there you go. We’ve outlined them in the podcast and you can always reference these when you’re researching statistics for your career.And speaking of careers, don’t forget that Ruben is hiring, so definitely check out his link. You can get all of the links and show notes at www.superdatascience.com/39 and there you’ll see the link to the job he’s posted. I don’t think it’ll be up for long, especially with this podcast coming out, you know, thousands of people listening to it per day, or especially in the first few days. So jump on it early, get in touch with Ruben, and I look forward to all of us catching up and having dinner together in San Francisco when I’m there next time. So make sure you get that job and I’ll see you there soon. And thank you so much for being on this show. I really appreciate you spending an hour with us today. And I can’t wait to see you next time. Until then, happy analyzing.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds['text_episode'].loc[38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f496ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc1397c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the text over the rows\n",
    "\n",
    "def text_split(df, column):\n",
    "    \n",
    "    sds_index = column.str.findall('(?:^|\\\\xa0|(?:\\\\n)+)([A-Za-z\\s]+):').explode().to_frame()\n",
    "    sds_index['episode_index'] = 1 \n",
    "    sds_index['episode_index'] = sds_index.groupby(sds_index.index)['episode_index'].cumsum()\n",
    "    sds_index = sds_index.reset_index().set_index(['index','episode_index']).rename(columns = {column.name :'speaker'})\n",
    "    #sds_index\n",
    "    split_text = column.str.split('(?:^|\\\\xa0|(?:\\\\n)+)[A-Za-z\\s]+:', expand = True).stack().to_frame()#.droplevel(-1)\n",
    "    \n",
    "    split_text.index = split_text.index.rename(sds_index.index.names)\n",
    "    #return sds_index,split_text \n",
    "    sds_index = sds_index.merge(split_text, left_index = True, right_index=True, how = 'right').droplevel(-1)\n",
    "    return df.merge(sds_index,left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9717973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sds_text = text_split(sds, sds['text_episode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fad1e12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>guest_info</th>\n",
       "      <th>text_episode</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_year</th>\n",
       "      <th>episode_day</th>\n",
       "      <th>host_episode</th>\n",
       "      <th>speaker</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Kirill</td>\n",
       "      <td>This is episode number one with ex-chemical e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Kirill</td>\n",
       "      <td>Hey guys, welcome to the Podcast. I’ve got Ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Ruben</td>\n",
       "      <td>Thank you! Thanks for having me over. I’m doi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ruben Kogel on Self-Serve Analytics, R vs Pyt...</td>\n",
       "      <td>42</td>\n",
       "      <td>Business Data Science Database</td>\n",
       "      <td>Ruben Kogel</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill: This is episode number one with ex-che...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sep 10, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Kirill</td>\n",
       "      <td>Awesome. It’s great to hear you and for those...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Contextual A.I. for Adapting to Adversaries, ...</td>\n",
       "      <td>81</td>\n",
       "      <td>Data Science Artificial Intelligence</td>\n",
       "      <td>Matar Haller</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Jon Krohn:\\t00:00:05\\tThis is episode number 6...</td>\n",
       "      <td>683</td>\n",
       "      <td>May 30, 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>\\t01:17:22Yeah, right. Yeah, as I mean, it act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Contextual A.I. for Adapting to Adversaries, ...</td>\n",
       "      <td>81</td>\n",
       "      <td>Data Science Artificial Intelligence</td>\n",
       "      <td>Matar Haller</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Jon Krohn:\\t00:00:05\\tThis is episode number 6...</td>\n",
       "      <td>683</td>\n",
       "      <td>May 30, 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>Matar Haller</td>\n",
       "      <td>\\t01:17:45\\tHappy to.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Contextual A.I. for Adapting to Adversaries, ...</td>\n",
       "      <td>81</td>\n",
       "      <td>Data Science Artificial Intelligence</td>\n",
       "      <td>Matar Haller</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Jon Krohn:\\t00:00:05\\tThis is episode number 6...</td>\n",
       "      <td>683</td>\n",
       "      <td>May 30, 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>\\t01:17:46\\tNice. Well, yeah, so you mentioned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Contextual A.I. for Adapting to Adversaries, ...</td>\n",
       "      <td>81</td>\n",
       "      <td>Data Science Artificial Intelligence</td>\n",
       "      <td>Matar Haller</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Jon Krohn:\\t00:00:05\\tThis is episode number 6...</td>\n",
       "      <td>683</td>\n",
       "      <td>May 30, 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>Matar Haller</td>\n",
       "      <td>\\t01:18:04\\tThank you for having me. This was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Contextual A.I. for Adapting to Adversaries, ...</td>\n",
       "      <td>81</td>\n",
       "      <td>Data Science Artificial Intelligence</td>\n",
       "      <td>Matar Haller</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Jon Krohn:\\t00:00:05\\tThis is episode number 6...</td>\n",
       "      <td>683</td>\n",
       "      <td>May 30, 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>\\t01:18:12\\tI loved this conversation today. I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47176 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          episode_name  length_episode  \\\n",
       "0     Ruben Kogel on Self-Serve Analytics, R vs Pyt...              42   \n",
       "0     Ruben Kogel on Self-Serve Analytics, R vs Pyt...              42   \n",
       "0     Ruben Kogel on Self-Serve Analytics, R vs Pyt...              42   \n",
       "0     Ruben Kogel on Self-Serve Analytics, R vs Pyt...              42   \n",
       "0     Ruben Kogel on Self-Serve Analytics, R vs Pyt...              42   \n",
       "..                                                 ...             ...   \n",
       "681   Contextual A.I. for Adapting to Adversaries, ...              81   \n",
       "681   Contextual A.I. for Adapting to Adversaries, ...              81   \n",
       "681   Contextual A.I. for Adapting to Adversaries, ...              81   \n",
       "681   Contextual A.I. for Adapting to Adversaries, ...              81   \n",
       "681   Contextual A.I. for Adapting to Adversaries, ...              81   \n",
       "\n",
       "                          context_episode      guest_name  \\\n",
       "0          Business Data Science Database    Ruben Kogel    \n",
       "0          Business Data Science Database    Ruben Kogel    \n",
       "0          Business Data Science Database    Ruben Kogel    \n",
       "0          Business Data Science Database    Ruben Kogel    \n",
       "0          Business Data Science Database    Ruben Kogel    \n",
       "..                                    ...             ...   \n",
       "681  Data Science Artificial Intelligence   Matar Haller    \n",
       "681  Data Science Artificial Intelligence   Matar Haller    \n",
       "681  Data Science Artificial Intelligence   Matar Haller    \n",
       "681  Data Science Artificial Intelligence   Matar Haller    \n",
       "681  Data Science Artificial Intelligence   Matar Haller    \n",
       "\n",
       "                                            guest_info  \\\n",
       "0    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "0    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "0    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "0    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "0    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "..                                                 ...   \n",
       "681  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "681  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "681  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "681  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "681  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "\n",
       "                                          text_episode  episode_number  \\\n",
       "0    Kirill: This is episode number one with ex-che...               1   \n",
       "0    Kirill: This is episode number one with ex-che...               1   \n",
       "0    Kirill: This is episode number one with ex-che...               1   \n",
       "0    Kirill: This is episode number one with ex-che...               1   \n",
       "0    Kirill: This is episode number one with ex-che...               1   \n",
       "..                                                 ...             ...   \n",
       "681  Jon Krohn:\\t00:00:05\\tThis is episode number 6...             683   \n",
       "681  Jon Krohn:\\t00:00:05\\tThis is episode number 6...             683   \n",
       "681  Jon Krohn:\\t00:00:05\\tThis is episode number 6...             683   \n",
       "681  Jon Krohn:\\t00:00:05\\tThis is episode number 6...             683   \n",
       "681  Jon Krohn:\\t00:00:05\\tThis is episode number 6...             683   \n",
       "\n",
       "     episode_date episode_year episode_day     host_episode       speaker  \\\n",
       "0    Sep 10, 2016         2016    Saturday  Kirril Eremenko           NaN   \n",
       "0    Sep 10, 2016         2016    Saturday  Kirril Eremenko        Kirill   \n",
       "0    Sep 10, 2016         2016    Saturday  Kirril Eremenko        Kirill   \n",
       "0    Sep 10, 2016         2016    Saturday  Kirril Eremenko         Ruben   \n",
       "0    Sep 10, 2016         2016    Saturday  Kirril Eremenko        Kirill   \n",
       "..            ...          ...         ...              ...           ...   \n",
       "681  May 30, 2023         2023     Tuesday        Jon Krohn     Jon Krohn   \n",
       "681  May 30, 2023         2023     Tuesday        Jon Krohn  Matar Haller   \n",
       "681  May 30, 2023         2023     Tuesday        Jon Krohn     Jon Krohn   \n",
       "681  May 30, 2023         2023     Tuesday        Jon Krohn  Matar Haller   \n",
       "681  May 30, 2023         2023     Tuesday        Jon Krohn     Jon Krohn   \n",
       "\n",
       "                                                     0  \n",
       "0                                                       \n",
       "0     This is episode number one with ex-chemical e...  \n",
       "0     Hey guys, welcome to the Podcast. I’ve got Ru...  \n",
       "0     Thank you! Thanks for having me over. I’m doi...  \n",
       "0     Awesome. It’s great to hear you and for those...  \n",
       "..                                                 ...  \n",
       "681  \\t01:17:22Yeah, right. Yeah, as I mean, it act...  \n",
       "681                              \\t01:17:45\\tHappy to.  \n",
       "681  \\t01:17:46\\tNice. Well, yeah, so you mentioned...  \n",
       "681  \\t01:18:04\\tThank you for having me. This was ...  \n",
       "681  \\t01:18:12\\tI loved this conversation today. I...  \n",
       "\n",
       "[47176 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60b72bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text = sds_text.rename(columns = {0 : 'episode_split_text' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17a65043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "episode_number  guest_name        \n",
       "342              Kirill Eremenko      1\n",
       "514              Jon Krohn            1\n",
       "244              Kirill Eremenko      1\n",
       "242              Kirill Eremenko      1\n",
       "518              Jon Krohn            1\n",
       "                                     ..\n",
       "30               Kirill Eremenko      2\n",
       "31               David Tanaskovic     2\n",
       "32               Kirill Eremenko      2\n",
       "34               Kirill Eremenko      2\n",
       "35               David Venturi        2\n",
       "Name: episode_split_text, Length: 270, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds_text.groupby(['episode_number','guest_name'])['episode_split_text'].count().sort_values().head(270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2b38972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>guest_info</th>\n",
       "      <th>text_episode</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_year</th>\n",
       "      <th>episode_day</th>\n",
       "      <th>host_episode</th>\n",
       "      <th>speaker</th>\n",
       "      <th>episode_split_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AB Testing, Kissmetrics and ways to a better ...</td>\n",
       "      <td>64</td>\n",
       "      <td>Data Science Data Visualization</td>\n",
       "      <td>David Tanaskovic</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 31, with my go...</td>\n",
       "      <td>31</td>\n",
       "      <td>Mar 02, 2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AB Testing, Kissmetrics and ways to a better ...</td>\n",
       "      <td>64</td>\n",
       "      <td>Data Science Data Visualization</td>\n",
       "      <td>David Tanaskovic</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 31, with my go...</td>\n",
       "      <td>31</td>\n",
       "      <td>Mar 02, 2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Kirril Eremenko</td>\n",
       "      <td>Kirill</td>\n",
       "      <td>\\tThis is episode number 31, with my good frie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         episode_name  length_episode  \\\n",
       "30   AB Testing, Kissmetrics and ways to a better ...              64   \n",
       "30   AB Testing, Kissmetrics and ways to a better ...              64   \n",
       "\n",
       "                    context_episode          guest_name  \\\n",
       "30  Data Science Data Visualization   David Tanaskovic    \n",
       "30  Data Science Data Visualization   David Tanaskovic    \n",
       "\n",
       "                                           guest_info  \\\n",
       "30  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "30  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "\n",
       "                                         text_episode  episode_number  \\\n",
       "30  Kirill:\\tThis is episode number 31, with my go...              31   \n",
       "30  Kirill:\\tThis is episode number 31, with my go...              31   \n",
       "\n",
       "    episode_date episode_year episode_day     host_episode speaker  \\\n",
       "30  Mar 02, 2017         2017    Thursday  Kirril Eremenko     NaN   \n",
       "30  Mar 02, 2017         2017    Thursday  Kirril Eremenko  Kirill   \n",
       "\n",
       "                                   episode_split_text  \n",
       "30                                                     \n",
       "30  \\tThis is episode number 31, with my good frie...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds_text[sds_text['guest_name'] == ' David Tanaskovic ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86339c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38                                                     \n",
      "38    \\tThis is episode number 39 with Director of D...\n",
      "Name: episode_split_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sds_text['episode_split_text'].loc[38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467cd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text['episode_split_text'] = sds_text['episode_split_text'].str.replace('\\\\t|\\\\n|\\\\xa0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d9470",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text['episode_split_text'] = sds_text['episode_split_text'].str.replace('\\(?\\d{2}:\\d{2}\\):| ?(\\d{2}:)+\\d{2}', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text['episode_split_text'].apply(lambda x: isinstance(x, str) and len(x.strip()) == 0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14698db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text = sds_text[sds_text['episode_split_text'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e577cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4143fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_text.to_csv('../data/sds_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a770d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_text.to_frame().rename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds['text_episode'].str.split('(?:^|\\\\xa0|(?:\\\\n)+)[A-Za-z\\s]+:', expand = True).stack()#.droplevel(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f989fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds['text_episode'].str.split('(?:^|\\\\xa0|\\\\n)[A-Za-z\\s]+:', expand = True).stack().loc[677]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3613b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_index = sds['text_episode'].str.findall('(?:^|\\\\xa0|(?:\\\\n)+)([A-Za-z\\s]+:)').explode().to_frame()#.shape#.stack().loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the speakers from the text and creating index\n",
    "\n",
    "#sds_index = sds['text_episode'].str.findall('(?:^|\\\\xa0|(?:\\\\n)+)([A-Za-z\\s]+:)').explode().to_frame()\n",
    "#sds_index['episode_index'] = 1 \n",
    "#sds_index['episode_index'] = sds_index.groupby(sds_index.index)['episode_index'].cumsum()\n",
    "#sds_index = sds_index.reset_index().set_index(['index','episode_index']).rename(columns = {'text_episode':'speaker'})\n",
    "#sds_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e750b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_index['episode_index'] = sds_index.groupby(sds_index.index)['episode_index'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9935418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1baf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_index = sds_index.reset_index().set_index(['index','episode_index']).rename(columns = {'text_episode':'speaker'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d594bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(set(sds['text_episode'].str.findall('(^|\\\\xa0|\\\\n)[A-Za-z\\s]+:').explode().index)) #.stack().droplevel(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606bf67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds['text_episode'].str.findall('(^|\\\\xa0|\\\\n)[A-Za-z\\s]+:').explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_guest = sds[~((sds['guest_name'] == ' Kirill Eremenko ') | (sds['guest_name'] == ' Jon Krohn '))].copy().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds_host = sds[(sds['guest_name'] == ' Kirill Eremenko ') | (sds['guest_name'] == ' Jon Krohn ')].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d5bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_host['context_episode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d639c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_host[sds_host['context_episode'] == 'Data Science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00316fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_guest['context_episode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19945d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['context_episode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230520b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141975b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sds_guest['text_episode'].loc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab700cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['text_episode'] = sds['text_episode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['text_episode'].apply(lambda x: pd.Series(x.split('[A-Z][a-z]+:')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['text_episode'].str.split('[A-Z][a-z]+:', expand = True).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33449e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_split[sds_split['guest_name'] == ' Jon Krohn ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_split.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sds = sds.merge(sds_split.to_frame(),left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_guest.to_csv('../data/sds_guest.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ead9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds[sds['context_episode'] == 'Data Science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b4f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['episode_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e37edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['text_episode'].loc[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc68516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = BeautifulSoup(text, 'lxml').get_text(separator=' ', strip=True)\n",
    "\n",
    "#text = re.findall(r'[a-z]+', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37950fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['guest_info'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec256e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
