{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8056cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb1ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds = pd.read_csv('../data/SDS_1_678.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890ac8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 678 entries, 0 to 677\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   episode_name     678 non-null    object\n",
      " 1   length_episode   678 non-null    object\n",
      " 2   context_episode  678 non-null    object\n",
      " 3   guest_name       678 non-null    object\n",
      " 4   guest_info       678 non-null    object\n",
      " 5   text_episode     676 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 31.9+ KB\n"
     ]
    }
   ],
   "source": [
    "sds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28de401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['episode_number'] = sds['episode_name'].str.split(':', expand = True)[0]\n",
    "sds['episode_name'] = sds['episode_name'].str.split(':', expand = True)[1]\n",
    "sds['guest_name'] = sds['guest_name'].str.split(':', expand = True)[1]\n",
    "sds['length_episode'] = sds['length_episode'].str.split(' ', expand = True)[0]\n",
    "sds['episode_number'] = sds['episode_number'].str.replace('SDS', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d921d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the data types for episode_number and length_episode\n",
    "sds['episode_number'] = sds['episode_number'].astype('int')\n",
    "sds['length_episode'] = sds['length_episode'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2507a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 678 entries, 0 to 677\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   episode_name     678 non-null    object\n",
      " 1   length_episode   678 non-null    int64 \n",
      " 2   context_episode  678 non-null    object\n",
      " 3   guest_name       678 non-null    object\n",
      " 4   guest_info       678 non-null    object\n",
      " 5   text_episode     676 non-null    object\n",
      " 6   episode_number   678 non-null    int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 37.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256692e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_2311/3544791578.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  sds['guest_name'] = sds['guest_name'].str.replace(r'(\\b[A-Za-z]{3}\\s\\d{2},\\s\\d{4}\\b)', '')\n"
     ]
    }
   ],
   "source": [
    "# Extracting date from guest_name column and making a new column episode_date\n",
    "sds['episode_date'] = sds['guest_name'].str.extract(r'(\\b[A-Za-z]{3}\\s\\d{2},\\s\\d{4}\\b)', expand = False).str.strip()\n",
    "\n",
    "# Replacing/removing date in guest_name column \n",
    "sds['guest_name'] = sds['guest_name'].str.replace(r'(\\b[A-Za-z]{3}\\s\\d{2},\\s\\d{4}\\b)', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "442c292a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    678\n",
       "Name: episode_date, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds['episode_date'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e94a1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sds[\"episode_guest\"] = sds['guest_name'].str.extract(r'(\\b[A-Z][a-z]+\\s[A-Z][a-z]+)', expand = False).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23528c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_2311/1816012116.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  sds['guest_name'] = sds['guest_name'].str.replace('Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday', '')\n"
     ]
    }
   ],
   "source": [
    "# Extracting day from guest_name column and making a new column episode_day\n",
    "sds['episode_day'] = sds['guest_name'].str.extract(r'(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday)', expand = False).str.strip()\n",
    "\n",
    "#Replacing/removing day in guest_name column \n",
    "sds['guest_name'] = sds['guest_name'].str.replace('Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c681c9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>guest_info</th>\n",
       "      <th>text_episode</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Avoid Failing at Digital Transformation</td>\n",
       "      <td>60</td>\n",
       "      <td>BusinessData Science</td>\n",
       "      <td>Tony Saldanha</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is episode number 381, ...</td>\n",
       "      <td>381</td>\n",
       "      <td>Jul 08, 2020</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discovering Data Science workflows and the im...</td>\n",
       "      <td>62</td>\n",
       "      <td>Machine LearningData SciencePython</td>\n",
       "      <td>Daniel Whitenack</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 61 with data s...</td>\n",
       "      <td>61</td>\n",
       "      <td>Jun 15, 2017</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great tips on building a successful Analytics...</td>\n",
       "      <td>65</td>\n",
       "      <td>BusinessDatabase</td>\n",
       "      <td>Jim Hadley</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 49 with Founde...</td>\n",
       "      <td>49</td>\n",
       "      <td>May 04, 2017</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI in Recruitment, Machine Learning, and wher...</td>\n",
       "      <td>66</td>\n",
       "      <td>BusinessMachine LearningData ScienceArtificial...</td>\n",
       "      <td>Ben Taylor</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 29, with Chief...</td>\n",
       "      <td>29</td>\n",
       "      <td>Feb 24, 2017</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two Wolves</td>\n",
       "      <td>6</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>This is FiveMinuteFriday, episode number 254, ...</td>\n",
       "      <td>254</td>\n",
       "      <td>Apr 19, 2019</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>True Personalization Through Reinforcement Le...</td>\n",
       "      <td>61</td>\n",
       "      <td>Machine LearningData ScienceArtificial Intelli...</td>\n",
       "      <td>Peyman Hesami</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is episode 293 with Dat...</td>\n",
       "      <td>293</td>\n",
       "      <td>Sep 04, 2019</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>Becoming Seasoned At Failure</td>\n",
       "      <td>69</td>\n",
       "      <td>BusinessData Science</td>\n",
       "      <td>Michelle Keim</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is Episode Number 299 w...</td>\n",
       "      <td>299</td>\n",
       "      <td>Sep 25, 2019</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Making the Public Graphically Literate</td>\n",
       "      <td>65</td>\n",
       "      <td>Data ScienceData Visualization</td>\n",
       "      <td>Alberto Cairo</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is episode number 271 w...</td>\n",
       "      <td>271</td>\n",
       "      <td>Jun 19, 2019</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Intuition, Frameworks, and Unlocking the Powe...</td>\n",
       "      <td>58</td>\n",
       "      <td>BusinessData Science</td>\n",
       "      <td>Piyanka Jain</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is episode number 363 w...</td>\n",
       "      <td>363</td>\n",
       "      <td>May 06, 2020</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>The Highest-Paying Programming Languages for ...</td>\n",
       "      <td>5</td>\n",
       "      <td>BusinessData Science</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>(00:05):\\nThis is Five-Minute Friday on the Hi...</td>\n",
       "      <td>520</td>\n",
       "      <td>Nov 04, 2021</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          episode_name  length_episode  \\\n",
       "0       How to Avoid Failing at Digital Transformation              60   \n",
       "1     Discovering Data Science workflows and the im...              62   \n",
       "2     Great tips on building a successful Analytics...              65   \n",
       "3     AI in Recruitment, Machine Learning, and wher...              66   \n",
       "4                                           Two Wolves               6   \n",
       "..                                                 ...             ...   \n",
       "673   True Personalization Through Reinforcement Le...              61   \n",
       "674                       Becoming Seasoned At Failure              69   \n",
       "675             Making the Public Graphically Literate              65   \n",
       "676   Intuition, Frameworks, and Unlocking the Powe...              58   \n",
       "677   The Highest-Paying Programming Languages for ...               5   \n",
       "\n",
       "                                       context_episode          guest_name  \\\n",
       "0                                 BusinessData Science      Tony Saldanha    \n",
       "1                   Machine LearningData SciencePython   Daniel Whitenack    \n",
       "2                                     BusinessDatabase         Jim Hadley    \n",
       "3    BusinessMachine LearningData ScienceArtificial...         Ben Taylor    \n",
       "4                                         Data Science    Kirill Eremenko    \n",
       "..                                                 ...                 ...   \n",
       "673  Machine LearningData ScienceArtificial Intelli...      Peyman Hesami    \n",
       "674                               BusinessData Science      Michelle Keim    \n",
       "675                     Data ScienceData Visualization      Alberto Cairo    \n",
       "676                               BusinessData Science       Piyanka Jain    \n",
       "677                               BusinessData Science          Jon Krohn    \n",
       "\n",
       "                                            guest_info  \\\n",
       "0    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "1    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "2    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "3    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "4    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "..                                                 ...   \n",
       "673  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "674  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "675  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "676  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "677  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "\n",
       "                                          text_episode  episode_number  \\\n",
       "0    Kirill Eremenko:\\tThis is episode number 381, ...             381   \n",
       "1    Kirill:\\tThis is episode number 61 with data s...              61   \n",
       "2    Kirill:\\tThis is episode number 49 with Founde...              49   \n",
       "3    Kirill:\\tThis is episode number 29, with Chief...              29   \n",
       "4    This is FiveMinuteFriday, episode number 254, ...             254   \n",
       "..                                                 ...             ...   \n",
       "673  Kirill Eremenko:\\tThis is episode 293 with Dat...             293   \n",
       "674  Kirill Eremenko:\\tThis is Episode Number 299 w...             299   \n",
       "675  Kirill Eremenko:\\tThis is episode number 271 w...             271   \n",
       "676  Kirill Eremenko:\\tThis is episode number 363 w...             363   \n",
       "677  (00:05):\\nThis is Five-Minute Friday on the Hi...             520   \n",
       "\n",
       "     episode_date episode_day  \n",
       "0    Jul 08, 2020   Wednesday  \n",
       "1    Jun 15, 2017    Thursday  \n",
       "2    May 04, 2017    Thursday  \n",
       "3    Feb 24, 2017      Friday  \n",
       "4    Apr 19, 2019      Friday  \n",
       "..            ...         ...  \n",
       "673  Sep 04, 2019   Wednesday  \n",
       "674  Sep 25, 2019   Wednesday  \n",
       "675  Jun 19, 2019   Wednesday  \n",
       "676  May 06, 2020   Wednesday  \n",
       "677  Nov 04, 2021    Thursday  \n",
       "\n",
       "[678 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c75c13a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Tony Saldanha ', ' Daniel Whitenack ', ' Jim Hadley ',\n",
       "       ' Ben Taylor ', ' Kirill Eremenko ', ' Brian Dowe ', ' Jon Krohn ',\n",
       "       ' Aaron Bare ', ' Kirill and Hadelin ', ' Caroline McColl ',\n",
       "       ' Matt Corey ', ' Matthew Rosenquist ', ' Khuyen Tran ',\n",
       "       ' Stratos Hadjioannou ', ' Jaclyn Rice Nelson ',\n",
       "       ' Risto Miikkulainen ', ' Steve Fazzari ', ' Christopher Bishop ',\n",
       "       ' Mark Meloon ', ' Muhsin Karim ', ' Hilary Mason ',\n",
       "       ' John Johnson ', ' Artem Vladimirov ', ' Erik Bernhardsson ',\n",
       "       ' Jon Skeet ', ' Andy Kriebel ', ' Rama Akkiraju ',\n",
       "       ' Arthur Shectman ', ' Richard Hopkins ', ' Marc Sarfati ',\n",
       "       ' Orly Lobel ', ' Kirill and Mitja ', ' Kristen Sosulski ',\n",
       "       '  Ilya Eremenko ', ' James Hodson ', ' Luke Barousse ',\n",
       "       ' Ayodele Odubela ', ' Laurence Moroney ', ' Jeremie Harris ',\n",
       "       ' John Peach ', ' Edis Gonuler ', ' Kimberly Grauer ',\n",
       "       ' Rongyao Huang ', ' Sean Casey ', ' Emily Robinson ',\n",
       "       ' Eric Weber ', ' Mariya Sha ', ' Aziz Mamatov ',\n",
       "       ' Anima Anandkumar ', ' Dr Alex Antic ', ' Pieter Abbeel ',\n",
       "       ' Kirill, Hadelin and Marc ', ' Kirill and Marc ', ' Frank Kane ',\n",
       "       ' Doris Xin ', ' Gary Saarenvirta ', ' Noah Gift ',\n",
       "       ' Michael Segala ', ' Isaac Reyes ', ' Christina Maslach ',\n",
       "       ' Kenneth Stanley ', ' Vitaly Dolgov ', ' Emmanuel Letouzé ',\n",
       "       ' Ajay Singh ', ' Kevin Getch ', ' Lauren Zhu ', ' Neelabh Pant ',\n",
       "       ' DJ Patil ', ' Amy Brand ', ' Sarah Catanzaro ',\n",
       "       ' George Mathew ', ' Kirill, Vitaly and Hadelin ',\n",
       "       ' Sadie St. Lawrence ', ' Urie Suhr ', ' Melanie Mitchell ',\n",
       "       ' Kirill Eremenko and Hadelin de Ponteves ', ' Philip Gradwell ',\n",
       "       ' William McKnight ', ' Nic Ryan ', ' Jessica Merlet ',\n",
       "       ' Nicole Büttner ', ' Noam Brown ', ' Nick Pape ',\n",
       "       ' Syafri Bahar ', ' Magnus Ekman ', ' Dominic Ligot ',\n",
       "       ' Erica Greene ', ' Sinan Ozdemir ', ' Eugene Dubossarsky ',\n",
       "       ' Andrew Borisov ', ' Josh Muncke ', ' Emanuele Carbone ',\n",
       "       ' Zhamak Dehghani ', ' Husayn Kassai ', ' Kirill and Anthony ',\n",
       "       ' Leigh and Daniel Pullen ', ' Avinash Kaushik ', ' Myra Strober ',\n",
       "       ' Mary Loubele ', ' Ken Jee ', ' Adrian Rosebrock ',\n",
       "       ' Konrad Kopczynski ', ' Jes Allen ', ' Tina Huang ',\n",
       "       ' Balaraman Ravindran ', ' Mike Wimmer ', ' Jared Lander ',\n",
       "       ' Miles Brundage ', ' Mark Freeman ', ' Zack Weinberg ',\n",
       "       ' Juan Gabriel Gomila Salas ', ' Ulf Morys ', ' Xinran Liu ',\n",
       "       ' Randal Scott King ', ' Dan Shiebler ', ' Serg Masís ',\n",
       "       ' Hadelin de Ponteves ', ' Clem Delangue ', ' Andrei Lyskov ',\n",
       "       \" Brian T. O'Neill \", ' Parinaz Sobhani ', ' Samuel Hinton ',\n",
       "       ' Ot Ratsaphong ', ' Tim Lafferty ', ' Jennifer Cooper ',\n",
       "       ' Raul Popa ', ' Deborah Berebichez ', ' Paul Brown ',\n",
       "       ' Kian Katanforoosh ', ' Matt Dancho ', ' Tracy Crossley ',\n",
       "       ' Tom Davenport ', ' Melanie Subbiah ', ' Morgan Mendis ',\n",
       "       ' Monica Kay Royal ', ' Shashank Kalanithi ',\n",
       "       ' Karen Jean-Francois ', ' Tarry Singh ', ' Stephen Welch ',\n",
       "       ' Daniel Obodovski ', ' Wes McKinney ', ' Carlos Aguilar ',\n",
       "       ' Asieh Ahani ', ' Mars Buttfield-Addison ', ' Ann K. Emery ',\n",
       "       ' Dawn Song ', ' Vincent D. Warmerdam ', ' Deblina Bhattacharjee ',\n",
       "       ' Bradley Voytek ', ' Jonathan Mucha and Ogo Ezeofor ',\n",
       "       ' John Elder ', ' Erin LeDell ', ' Kirk Borne ', ' Carl Massy ',\n",
       "       ' Harpreet Sahota ', ' Carly Taylor ', ' T. Scott Clendaniel ',\n",
       "       ' Garth Zoller ', ' Ivor Lok ', ' Manasi Vartak ',\n",
       "       ' Dmitry Korneev ', ' Virginia Mendonca ', ' Kate Strachnyi ',\n",
       "       ' Matt Harrison ', ' Colin Sloss ', ' Francesco Corea ',\n",
       "       ' Sam Flegal ', ' Ruben Kogel ', ' Javier Luraschi ',\n",
       "       ' Jason Widjaja ', ' Chris Dutton ', ' Andrew Jones ',\n",
       "       ' Vin Vashishta ', ' Charlotte Deane ', ' Gabriela de Queiroz ',\n",
       "       ' Dominic Roe ', ' Marco Caviezel ', ' Jose Quesada ',\n",
       "       ' Piatetsky-Shapiro ', ' Andreas Mueller ', ' Emre Kiciman ',\n",
       "       ' Dr. Andreas Hopfgartner ', ' Megan Putney ',\n",
       "       ' Cole Nussbaumer Knaflic ', ' Jodie Burchell ', ' Luis Blanco ',\n",
       "       ' Brandon Rohrer ', ' Ayobami Ayodeji ', ' Harshal Sanap ',\n",
       "       ' Andy Kriebel and Eva Murray ', ' Kerri Twigg ',\n",
       "       ' Jaco Van Der Berg ', ' Thomas Wiecki ', ' Michael Galarnyk ',\n",
       "       ' Michael Colella ', ' Vitaly and Kirill ', ' Drew Conway ',\n",
       "       ' Rio Branham ', ' Vince Petaccio II ', ' Mike Taveirne ',\n",
       "       ' Alexander Holden Miller  ', ' Hadley Wickham ', ' Emma Whyte ',\n",
       "       ' Andreas Kretz ', ' Eva Murray ', ' Josh Starmer ',\n",
       "       ' Anthony Metivier ', ' Jonathan Flint ', ' Kate Strachny ',\n",
       "       ' Ryan Compton ', ' Nisha Iyer ', ' Adrian Kosowski ',\n",
       "       ' Thomas Obrist ', ' Rob Trangucci ', ' Nicholas Cepeda ',\n",
       "       ' Philip Bourne ', ' Kirill and Paulo ', ' Lillian Pierson ',\n",
       "       ' Josh Coulson ', ' Lucy D’Agostino McGowan ', ' Eoin Murray ',\n",
       "       ' Richard Downes ', ' John David Ariansen ', ' Jeroen Janssens ',\n",
       "       ' Veerle van Leemput ', ' Nick Singh ', ' Keith McCormick ',\n",
       "       ' Peter Bailis ', ' Claudia Perlich ', ' Sasha Prokhorova ',\n",
       "       ' David Niemi ', ' Wesley Engers ', ' Amanda Obidike ',\n",
       "       ' Greg Coquillo ', ' Sarah Nooravi ', ' Guillermo Cecchi ',\n",
       "       ' Steve Nouri ', ' Brett Tully ', ' Tom Brown ', ' Kimberly Deas ',\n",
       "       ' Theunis Barnard ',\n",
       "       ' Urie Suhr, Ben Taylor and  Hadelin De Ponteves ',\n",
       "       ' Josh Kennedy ',\n",
       "       ' Mark Skinner, Rachel Wang, Ben Taylor & Pablos Holman ',\n",
       "       ' Ingólfur Ingólfsson ', ' Wardah Inam ', ' Experfy ',\n",
       "       ' Damian Mingle ', ' Ashwin Chirag ', ' Benjamin Todd ',\n",
       "       ' Joe Reis and Matt Housley ', ' Brad Klingenberg ',\n",
       "       ' Jean-Pierre Labuschagne ', ' Nate Fox ', ' Deepak Prasad ',\n",
       "       ' Stefanie Molin ', ' Gabor Solymosi ', ' Denis Rothman ',\n",
       "       ' Jorge Zuloaga and Lindsey Zuloaga ', ' Beau Walker ',\n",
       "       ' Kristen Kehrer ', ' Zachary Loertscher ', ' Khai Minh Pham ',\n",
       "       ' Brendan Hogan ', ' Juval Löwy ', ' Derek Schoettle ',\n",
       "       ' Xiao-Li Meng ', ' Shayan Mohanty ', ' Konrad Körding ',\n",
       "       ' Jennifer Hill ', ' Yaw Tan ', ' Jeff Wald ', ' Sean Taylor ',\n",
       "       ' Nathan Stephens ', ' John Langford ', ' Chrys Wu ',\n",
       "       ' Jen Underwood ', ' Christina Stathopoulos ', ' Barr Moses ',\n",
       "       ' Josey Parks ', ' Wah Loon Keng ', ' Randy Lao ',\n",
       "       ' David Langer ', ' Susan Walsh ', ' Horace Wu ',\n",
       "       ' Vincent Gosselin ', ' Greg Pavlik ', ' SuperDataScience Team ',\n",
       "       ' Dave Niewinski ', ' Carlos Hervás García ', ' Rachel Phang ',\n",
       "       ' Jose Portilla ', ' Mikiko Bazeley ', ' Maureen Teyssier ',\n",
       "       ' Pablos Holman ', ' Chip Huyen ', ' Rico Meinl ', ' Greg Poppe ',\n",
       "       ' Margot Gerritsen ', ' Kevin Perko ', ' Justin Fortier ',\n",
       "       ' Favio Vazquez ', ' Anna Foard ', ' Tristen Tyler Blake ',\n",
       "       ' Adam Weinstein ', ' Tim Kraska ', ' Douglas Eisenstein ',\n",
       "       ' Anjali Srivastava ', ' Matthew Russell ', ' Dr. Wilson Pok ',\n",
       "       ' Adrian Clarke ', ' Josh Hortaleza ', ' Erika Dorland ',\n",
       "       ' Sidney Arcidiacono ', ' Kevin Hu ', ' Nadieh Bremer ',\n",
       "       ' David Venturi ', ' Ross Dawson ', ' Roman Yampolskiy ',\n",
       "       ' Kris Tait ', ' David Tanaskovic ', ' Josh Wills ',\n",
       "       ' Mollie Pettit ', ' Tuatini Godard ', ' Eu Jin Lok ',\n",
       "       ' Austin Ogilvie ', ' Peyman Hesami ', ' Michelle Keim ',\n",
       "       ' Alberto Cairo ', ' Piyanka Jain '], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds['guest_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82407a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/9_r9v9px7_v0q69b5zcbnmsm0000gn/T/ipykernel_2311/824675729.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  sds['context_episode'] = sds['context_episode'].str.replace('([a-z])([A-Z])', r'\\1 \\2')\n"
     ]
    }
   ],
   "source": [
    "sds['context_episode'] = sds['context_episode'].str.replace('([a-z])([A-Z])', r'\\1 \\2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e90ae44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>guest_info</th>\n",
       "      <th>text_episode</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Avoid Failing at Digital Transformation</td>\n",
       "      <td>60</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Tony Saldanha</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is episode number 381, ...</td>\n",
       "      <td>381</td>\n",
       "      <td>Jul 08, 2020</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discovering Data Science workflows and the im...</td>\n",
       "      <td>62</td>\n",
       "      <td>Machine Learning Data Science Python</td>\n",
       "      <td>Daniel Whitenack</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 61 with data s...</td>\n",
       "      <td>61</td>\n",
       "      <td>Jun 15, 2017</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great tips on building a successful Analytics...</td>\n",
       "      <td>65</td>\n",
       "      <td>Business Database</td>\n",
       "      <td>Jim Hadley</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 49 with Founde...</td>\n",
       "      <td>49</td>\n",
       "      <td>May 04, 2017</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI in Recruitment, Machine Learning, and wher...</td>\n",
       "      <td>66</td>\n",
       "      <td>Business Machine Learning Data Science Artific...</td>\n",
       "      <td>Ben Taylor</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is episode number 29, with Chief...</td>\n",
       "      <td>29</td>\n",
       "      <td>Feb 24, 2017</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two Wolves</td>\n",
       "      <td>6</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>This is FiveMinuteFriday, episode number 254, ...</td>\n",
       "      <td>254</td>\n",
       "      <td>Apr 19, 2019</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>True Personalization Through Reinforcement Le...</td>\n",
       "      <td>61</td>\n",
       "      <td>Machine Learning Data Science Artificial Intel...</td>\n",
       "      <td>Peyman Hesami</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is episode 293 with Dat...</td>\n",
       "      <td>293</td>\n",
       "      <td>Sep 04, 2019</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>Becoming Seasoned At Failure</td>\n",
       "      <td>69</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Michelle Keim</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is Episode Number 299 w...</td>\n",
       "      <td>299</td>\n",
       "      <td>Sep 25, 2019</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Making the Public Graphically Literate</td>\n",
       "      <td>65</td>\n",
       "      <td>Data Science Data Visualization</td>\n",
       "      <td>Alberto Cairo</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is episode number 271 w...</td>\n",
       "      <td>271</td>\n",
       "      <td>Jun 19, 2019</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>Intuition, Frameworks, and Unlocking the Powe...</td>\n",
       "      <td>58</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Piyanka Jain</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill Eremenko:\\tThis is episode number 363 w...</td>\n",
       "      <td>363</td>\n",
       "      <td>May 06, 2020</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>The Highest-Paying Programming Languages for ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Business Data Science</td>\n",
       "      <td>Jon Krohn</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>(00:05):\\nThis is Five-Minute Friday on the Hi...</td>\n",
       "      <td>520</td>\n",
       "      <td>Nov 04, 2021</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          episode_name  length_episode  \\\n",
       "0       How to Avoid Failing at Digital Transformation              60   \n",
       "1     Discovering Data Science workflows and the im...              62   \n",
       "2     Great tips on building a successful Analytics...              65   \n",
       "3     AI in Recruitment, Machine Learning, and wher...              66   \n",
       "4                                           Two Wolves               6   \n",
       "..                                                 ...             ...   \n",
       "673   True Personalization Through Reinforcement Le...              61   \n",
       "674                       Becoming Seasoned At Failure              69   \n",
       "675             Making the Public Graphically Literate              65   \n",
       "676   Intuition, Frameworks, and Unlocking the Powe...              58   \n",
       "677   The Highest-Paying Programming Languages for ...               5   \n",
       "\n",
       "                                       context_episode          guest_name  \\\n",
       "0                                Business Data Science      Tony Saldanha    \n",
       "1                 Machine Learning Data Science Python   Daniel Whitenack    \n",
       "2                                    Business Database         Jim Hadley    \n",
       "3    Business Machine Learning Data Science Artific...         Ben Taylor    \n",
       "4                                         Data Science    Kirill Eremenko    \n",
       "..                                                 ...                 ...   \n",
       "673  Machine Learning Data Science Artificial Intel...      Peyman Hesami    \n",
       "674                              Business Data Science      Michelle Keim    \n",
       "675                    Data Science Data Visualization      Alberto Cairo    \n",
       "676                              Business Data Science       Piyanka Jain    \n",
       "677                              Business Data Science          Jon Krohn    \n",
       "\n",
       "                                            guest_info  \\\n",
       "0    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "1    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "2    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "3    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "4    Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "..                                                 ...   \n",
       "673  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "674  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "675  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "676  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "677  Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "\n",
       "                                          text_episode  episode_number  \\\n",
       "0    Kirill Eremenko:\\tThis is episode number 381, ...             381   \n",
       "1    Kirill:\\tThis is episode number 61 with data s...              61   \n",
       "2    Kirill:\\tThis is episode number 49 with Founde...              49   \n",
       "3    Kirill:\\tThis is episode number 29, with Chief...              29   \n",
       "4    This is FiveMinuteFriday, episode number 254, ...             254   \n",
       "..                                                 ...             ...   \n",
       "673  Kirill Eremenko:\\tThis is episode 293 with Dat...             293   \n",
       "674  Kirill Eremenko:\\tThis is Episode Number 299 w...             299   \n",
       "675  Kirill Eremenko:\\tThis is episode number 271 w...             271   \n",
       "676  Kirill Eremenko:\\tThis is episode number 363 w...             363   \n",
       "677  (00:05):\\nThis is Five-Minute Friday on the Hi...             520   \n",
       "\n",
       "     episode_date episode_day  \n",
       "0    Jul 08, 2020   Wednesday  \n",
       "1    Jun 15, 2017    Thursday  \n",
       "2    May 04, 2017    Thursday  \n",
       "3    Feb 24, 2017      Friday  \n",
       "4    Apr 19, 2019      Friday  \n",
       "..            ...         ...  \n",
       "673  Sep 04, 2019   Wednesday  \n",
       "674  Sep 25, 2019   Wednesday  \n",
       "675  Jun 19, 2019   Wednesday  \n",
       "676  May 06, 2020   Wednesday  \n",
       "677  Nov 04, 2021    Thursday  \n",
       "\n",
       "[678 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da26b99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Kirill Eremenko         190\n",
       " Jon Krohn               105\n",
       " Kirill and Hadelin        9\n",
       " Ben Taylor                8\n",
       " Hadelin de Ponteves       6\n",
       "                        ... \n",
       " Clem Delangue             1\n",
       " Randal Scott King         1\n",
       " Xinran Liu                1\n",
       " Ulf Morys                 1\n",
       " Piyanka Jain              1\n",
       "Name: guest_name, Length: 330, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds['guest_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd74e55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4       True\n",
       "       ...  \n",
       "673    False\n",
       "674    False\n",
       "675    False\n",
       "676    False\n",
       "677     True\n",
       "Name: guest_name, Length: 678, dtype: bool"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds['guest_name'].isin([' Kirill Eremenko ', ' Jon Krohn '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d70e68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>length_episode</th>\n",
       "      <th>context_episode</th>\n",
       "      <th>guest_name</th>\n",
       "      <th>guest_info</th>\n",
       "      <th>text_episode</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_date</th>\n",
       "      <th>episode_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two Wolves</td>\n",
       "      <td>6</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>This is FiveMinuteFriday, episode number 254, ...</td>\n",
       "      <td>254</td>\n",
       "      <td>Apr 19, 2019</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Have a Mentor</td>\n",
       "      <td>22</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>This is Five Minute Friday episode number 150,...</td>\n",
       "      <td>150</td>\n",
       "      <td>Apr 21, 2018</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do Lobsters Grow?</td>\n",
       "      <td>5</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>This is Five Minute Friday episode number 134:...</td>\n",
       "      <td>134</td>\n",
       "      <td>Feb 24, 2018</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wheel of Life</td>\n",
       "      <td>9</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>(00:04):\\nThis is FiveMinuteFriday, Wheel of L...</td>\n",
       "      <td>420</td>\n",
       "      <td>Nov 20, 2020</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Breaking patterns</td>\n",
       "      <td>8</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>This is Five Minute Friday episode number 78: ...</td>\n",
       "      <td>78</td>\n",
       "      <td>Aug 11, 2017</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>History of Data Science - Part 1</td>\n",
       "      <td>20</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>This is FiveMinuteFriday, The History of Data ...</td>\n",
       "      <td>340</td>\n",
       "      <td>Feb 14, 2020</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>How to get a job in Data Science</td>\n",
       "      <td>8</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>This is Five Minute Friday episode number 38: ...</td>\n",
       "      <td>38</td>\n",
       "      <td>Mar 24, 2017</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>Communicate Your Needs</td>\n",
       "      <td>7</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>(00:04):\\nThis is FiveMinuteFriday, Communicat...</td>\n",
       "      <td>410</td>\n",
       "      <td>Oct 16, 2020</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Think Bigger</td>\n",
       "      <td>6</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>(00:05):\\nThis is FiveMinuteFriday, episode nu...</td>\n",
       "      <td>400</td>\n",
       "      <td>Sep 11, 2020</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Failure</td>\n",
       "      <td>6</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Kirill Eremenko</td>\n",
       "      <td>Subscribe on Website, Apple Podcasts, Spotify,...</td>\n",
       "      <td>Kirill:\\tThis is Five Minute Friday episode nu...</td>\n",
       "      <td>34</td>\n",
       "      <td>Mar 10, 2017</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          episode_name  length_episode context_episode  \\\n",
       "4                           Two Wolves               6    Data Science   \n",
       "5                        Have a Mentor              22    Data Science   \n",
       "6                How do Lobsters Grow?               5    Data Science   \n",
       "7                        Wheel of Life               9    Data Science   \n",
       "11                   Breaking patterns               8    Data Science   \n",
       "..                                 ...             ...             ...   \n",
       "656   History of Data Science - Part 1              20    Data Science   \n",
       "661   How to get a job in Data Science               8    Data Science   \n",
       "664             Communicate Your Needs               7    Data Science   \n",
       "670                       Think Bigger               6    Data Science   \n",
       "672                            Failure               6    Data Science   \n",
       "\n",
       "            guest_name                                         guest_info  \\\n",
       "4     Kirill Eremenko   Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "5     Kirill Eremenko   Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "6     Kirill Eremenko   Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "7     Kirill Eremenko   Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "11    Kirill Eremenko   Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "..                 ...                                                ...   \n",
       "656   Kirill Eremenko   Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "661   Kirill Eremenko   Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "664   Kirill Eremenko   Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "670   Kirill Eremenko   Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "672   Kirill Eremenko   Subscribe on Website, Apple Podcasts, Spotify,...   \n",
       "\n",
       "                                          text_episode  episode_number  \\\n",
       "4    This is FiveMinuteFriday, episode number 254, ...             254   \n",
       "5    This is Five Minute Friday episode number 150,...             150   \n",
       "6    This is Five Minute Friday episode number 134:...             134   \n",
       "7    (00:04):\\nThis is FiveMinuteFriday, Wheel of L...             420   \n",
       "11   This is Five Minute Friday episode number 78: ...              78   \n",
       "..                                                 ...             ...   \n",
       "656  This is FiveMinuteFriday, The History of Data ...             340   \n",
       "661  This is Five Minute Friday episode number 38: ...              38   \n",
       "664  (00:04):\\nThis is FiveMinuteFriday, Communicat...             410   \n",
       "670  (00:05):\\nThis is FiveMinuteFriday, episode nu...             400   \n",
       "672  Kirill:\\tThis is Five Minute Friday episode nu...              34   \n",
       "\n",
       "     episode_date episode_day  \n",
       "4    Apr 19, 2019      Friday  \n",
       "5    Apr 21, 2018    Saturday  \n",
       "6    Feb 24, 2018    Saturday  \n",
       "7    Nov 20, 2020      Friday  \n",
       "11   Aug 11, 2017      Friday  \n",
       "..            ...         ...  \n",
       "656  Feb 14, 2020      Friday  \n",
       "661  Mar 24, 2017      Friday  \n",
       "664  Oct 16, 2020      Friday  \n",
       "670  Sep 11, 2020      Friday  \n",
       "672  Mar 10, 2017      Friday  \n",
       "\n",
       "[190 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds[sds['guest_name'] == ' Kirill Eremenko ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b07ea1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 678 entries, 0 to 677\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   episode_name     678 non-null    object\n",
      " 1   length_episode   678 non-null    int64 \n",
      " 2   context_episode  678 non-null    object\n",
      " 3   guest_name       678 non-null    object\n",
      " 4   guest_info       678 non-null    object\n",
      " 5   text_episode     676 non-null    object\n",
      " 6   episode_number   678 non-null    int64 \n",
      " 7   episode_date     678 non-null    object\n",
      " 8   episode_day      678 non-null    object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 47.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f63a521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Kirill:\\tThis is episode number 61 with data science speaker Daniel Whitenack.(background music plays)Welcome to the SuperDataScience podcast. My name is Kirill Eremenko, data science coach and lifestyle entrepreneur. And each week we bring you inspiring people and ideas to help you build your successful career in data science. Thanks for being here today and now let’s make the complex simple.(background music plays)Hello everybody and welcome to the SuperDataScience podcast. Very excited about this new episode. Today we've got an interesting guest, Daniel Whitenack. Daniel is a Data Scientist at Pachyderm, but in addition to his normal role, he is a renowned speaker in the world of data science. Daniel presents at dozens, literally dozens, of conferences per year, and he talks about things like Python, Pachyderm, the language Go, machine learning, and data science workflows, machine learning workflows, and lots and lots of other topics.So today we have a very great opportunity to have Daniel on the podcast, and what we spoke about were quite a few things. We talked about Pachyderm and what the mission of the company is, we also talked about data science workflows. And I think that was a very powerful part of data science, something that is developing in data science, and if you want to see and prepare yourself for the future of data science, this can be a very valuable set of skills to look into. And in this podcast you will find out exactly what data science workflows are and how you can get more involved in learning about data science workflows and getting up to speed with what is going on in this space of data science.Then we'll also talk about a bit about the programming language of Go. We talked about mentorship and what role it plays in both the careers of mentees and mentors. Of course, towards the end we talked about a bit of Daniel's experience in data science.So a very saturated podcast. You'll learn quite a lot, especially if you are interested in understanding the end to end data science process. Not just the ad hoc data analytics, but becoming a well-rounded data scientist. You will get some very valuable tips from today's show.And on that note, I can't wait to get started. So without further ado, I bring to you Daniel Whitenack, a data scientist at Pachyderm.(background music plays)Welcome everybody to the SuperDataScience podcast. Today I've got a very exciting guest, a multi-time speaker at data science conferences, Daniel Whitenack. Hi Daniel, how are you going today?Daniel:\\tHi, I'm doing really well. Thank you for having me.Kirill:\\tThank you for coming, it's a great honour to have you on. I've seen a couple of your YouTube videos and actually we crossed paths at the ODSC conference. Tell us a bit about where you're calling in from. Where are you located?Daniel:\\tYeah, I'm in Lafayette, Indiana, which is about 2 hours from Chicago and an hour from Indianapolis. It's where Purdue University is, if anybody is familiar with that.Kirill:\\tThat's very interesting. But it's a rare cse for you to be at home, right? As I understand, you're at all these conferences, always presenting. Tell us a bit more about that. Why are you so passionate about presenting at conferences?Daniel:\\tYeah, I really found that where I learn the most is when I'm in community with other data scientists, with other engineers. I really thrive off of things like coder views and other things like that, I think have really been where I've learned, so I've gained an appreciation for the community, the tech community, and want to be able to be involved as much as I can in that community, and give back content and really get feedback on the projects that I'm working on, hear about what other people are working on, and yeah, just be plugged in in that way.Kirill:\\tGotcha, gotcha. And what do you present on most of the time? Or is it a variety of topics that you talk about usually?Daniel:\\tYeah, so there's a few different areas I guess. I talk pretty frequently about Pachyderm, the open source project that I work on full time. Then I also sometimes talk about Go. So I'm a little bit of a Go programming language nerd, and sometimes talk about that and some of the interesting data things going on there. And then the third case, I'm really passionate about data science workflows and sustainable data science workflows. As we develop the field of data science, what are the best practices that we need to be following, and those sorts of things. That's a really interesting topic for me.Kirill:\\tWonderful. And I hope we can cover that off and go into a bit more depth on the podcast about that. I think that's a very exciting topic as well.Daniel:\\tYeah!Kirill:\\tOk, beautiful. So tell us a bit about what you do. Who is Daniel Whitenack, what are you currently doing? You mentioned you were working at Pachyderm, yeah?Daniel:\\tI’m working full-time with Pachyderm. They’re an open source project, like I mentioned, but there’s also a company around it, so similar to Docker. Docker is a company and open source project. It’s a project that does data pipelining and data versioning, so I work full-time with them as a data scientist. Most of the rest of the team are really brilliant distributed systems and backend engineers that have really built up the core of the system, and I came on as a data scientist because really where the system is relevant is for data scientists and for data engineers. So I’m kind of like a liaison to that community. I also work with a lot of our users that have machine learning workflows and other data science workflows and I help them utilize the system. And then I also produce a lot of tutorials, demos, work on the docs, and then occasionally talk at different events. So I’m a little bit all over the place, but generally kind of data science guy.Kirill:\\tOkay, gotcha. And tell us about how is the product or the things that you create at Pachyderm, how is that used by users or companies or other people that are users of these things that you create?Daniel:\\tSure, yeah. So, one of the things that I worked hard on is really trying to understand I guess a sustainable production scale machine learning workflow, kind of like a template that people could use for their various machine learning workflows, whether that’s in Python or R or TensorFlow or whatever it is. So I kind of created this template and then wrote up some docs around it and then when users come in with those sorts of workflows, then there’s an R example, a Python example, a TensorFlow example that I’ve written, to point them to and show them how they can start developing a data pipeline with this kind of template as a model.So that’s kind of one example of something that I’ve worked on, but right now I’m working on some streaming examples, streaming analysis, and kind of figuring out what are some of the best practices with our system around streaming workflows and how’s the easiest and best way for a data scientist or an analyst to start streaming analysis in Pachyderm and start from not nothing, but kind of like a template that’s a good foundation.Kirill:\\tOkay, gotcha. Is my understanding correct that somebody has a data science project and then they want to turn that into something that’s repeatable, something that can be taken from end-to-end, not just as an ad hoc analysis but can be done many times, then they use Pachyderm to create that workflow and then they just have to input the data, tweak the parameters and they get their output? Is that what Pachyderm is for?Daniel:\\tExactly, yeah. It’s a production environment for data science workflows. For example, you can create a data pipeline that includes model training and pre-processing and inference and have all those steps connected and also be scalable and, like you said, be repeatable as well. So it’s a very holistic view of “These are all the steps of my processing. I’m going to connect them all so I know what’s going into where and then I’m also going to version and track my data so I know what data was coming into and out of the various stages and so I have reproducibility and tracking or provenance of all these things that are happening.\\xa0Kirill:\\tGotcha. I understand. Until you gave me that sticker at ODSC—remember you gave me the sticker for Pachyderm with the elephant?Daniel:\\tYeah. It’s a pretty good sticker. (Laughs)Kirill:\\tYeah. And until you gave me that sticker, I honestly didn’t know about Pachyderm. So what would you say to people who are listening to this podcast who don’t know about Pachyderm? Why would you say that it can be an advantage for them to go and learn about Pachyderm and start applying that in their work and see how they can bring that into their organizations?Daniel:\\tYeah. I really think, you know, in the data science community, there’s a lot of struggle right now around giving data science teams ownership of their data pipelines. And there’s a lot of inefficiencies in data scientists actually pushing things into production, a lot of times, because maybe the only distributed framework or production scale framework that they know about are like Java/Scala type frameworks like Hadoop and Spark. And maybe the data science team, as a lot of data science teams are, they don’t really like working in Java/Scala or maybe they have a bunch of different tools that they’re using, you know, R and Python and other things.So Pachyderm is a really great solution for those data science teams to be able to create a cluster very easily that’s able to run production scale things, but also able to run the tools and the frameworks and the languages that they’re used to and that they already like so that they don’t have to waste time re-implementing things in Java/Scala. They can have a stage in R, a stage in Python, they can run a batch script in one stage. And all of that is kind of unified and tied together in a very unified and very sustainable way, but it also allows them to maintain that simplicity and ownership over the tools and the frameworks that they really like using.Kirill:\\tI understand. And probably a big advantage to that as well is that in a lot of organizations, data science is seen as kind of an additional function and once you’ve done the analytics, you pass on the models and everything to the business intelligence group. I’ve been in situations like that where you have to pass it on to the BI team and then they re-implement all of that in SQL. And in this case you’re kind of taking ownership of that so you don’t have to tell somebody how to re-implement that, there’s no middleman, you have full ownership and full control of the data science models and things and products that you develop for the organization.Daniel:\\tYeah, I totally agree. And in doing that, really what you’re doing is you’re setting yourself up hopefully for a little bit easier management of your processes. Because when you have that sort of hand-off scenario, whether it’s re-implementing within the business intelligence team, or you’re giving it to Java/Scala engineers to implement on big data infrastructure, what you end up with is data scientists who don’t understand the implementation and engineers who don’t understand the modelling or the analysis, so then when things go wrong, or when you need to update things, there’s a lot of inefficiencies with understanding “Who should I contact? Who has the right knowledge to fix this?” and there’s also inefficiency, of course, in the re-implementation.Kirill:\\tGotcha. I understand. I totally agree with that. Yeah, that’s really cool. I already learned so much. I might as well just end the podcast here. I think that was so much value. I’m joking, of course. We’ve got so much more to cover. Are you happy to go into a bit of data science workflows and tell us a bit about that?Daniel:\\tSure. I would be happy to.Kirill:\\tOkay, cool. So what is a data science workflow, and what are the components of a data science workflow?Daniel:\\tData science is very diverse, so it’s hard to pin down one workflow for everything because data science now, when we talk about producing data-driven processes, that’s happening at all levels of a business from optimizing what servers you spin up in AWS all the way to optimizing your sales pipeline. So it’s kind of at all levels of the business, both impacting internal processes and external processes. But in general, I would say a data science workflow often involves some type of stage where you’re doing some cleaning of your data, you’re gathering data, maybe you’re aggregating it to produce some sort of dataset that you’re working off of. And then you’re doing some sort of arithmetic or processing on that dataset, maybe that’s statistics or maybe that’s a convolutional neural net, it’s some sort of arithmetic, and then there’s some sort of conveyance of those results or maybe post-processing of those results.And these different stages could themselves involve various different stages. You know, you might have to transform your dataset or aggregate your dataset in five or six or seven different stages or ways before you actually get a feature set that you want to use in a model. So there’s these workflows that are by their very nature multi-stage, and one of the problems that I’m really seeing in data science and I think will probably resonate with the listeners very well is that you get all these stages and then you very, very quickly start losing track of what’s going into what. And especially if you’re handing off things to other members of your team to review or to build on, they have trouble understanding the whole workflow that you intended, especially if you leave the company and then they have to build on it.So there’s this real problem around workflows. And then if you add on top of that not only that you’re doing all these multi-stage things, but that eventually you actually have to deploy some of that stuff into your company’s infrastructure, that’s kind of overwhelming on top of things. There’s just this giant overwhelming elephant in the room that is this workflow thing. And that’s really, like I said, where a lot of my passion is. I think these are the problems that the data science community is really dealing with a lot right now. You know, we’re developing very sophisticated modelling techniques, which is really cool and we should be doing that, and I think we will continue to do that, but in a lot of business scenarios the problem is not that you’re not able to be sophisticated enough on the modelling side, the problem is you actually need to put together this workflow in some way that it produces value within a business. So I think that piece has still got some kinks in the data science world.Kirill:\\tOkay, gotcha. That’s a great description. For example, I can totally imagine that Pachyderm is a great tool that helps solve that problem. But is Pachyderm sufficient on its own to solve that problem, or does the person that’s faced with this challenge, do they need to have some sort of knowledge about workflows and understanding? I’m kind of getting to what kind of tips and hacks or tricks or things can you recommend and suggest to people that are faced with a challenge like that?Daniel:\\tYeah, what I recommend, even outside of Pachyderm—like you said, at Pachyderm, this is kind of our passion. This is why we’re building our system and at least we think that it addresses many of these issues. But I think in general, whether you ever look at Pachyderm or not, some really best practices that I think that we should be pushing in our workflows first are celebrating and striving for simple solutions to problems, the simplest solution that does provide value.So if I’m on my data team and someone brings a solution to me and I’m supposed to review and it’s some very un-interpretable model that has a lot of complication and we could have solved the same problem with k-Nearest Neighbours or linear regression or something like that, then I’m going to have a big problem with that. Because if we can find those simple interpretable solutions, we should be using them. We should celebrate the fact when we’re able to solve a problem with a simple solution, because that by its very nature is going to be easier to maintain, easier to deploy, it’s going to bring more value to the company because we’re actually going to be able to accelerate that to production faster. So I think that in general is a good tip.I also really recommend to people that, outside of everything else, we shouldn’t be making excuses around reproducibility. Sometimes when I talk about reproducibility, people give me a little bit of pushback because they say, “Oh, well, now we have these random processes and non-deterministic models and other things.” And I kind of push back to them on that because I come from the physics world, and if people kind of know a little bit about the physics world, I worked in quantum mechanics and the electron may be over here when you measure it, it may be over there when you measure it, it’s not always in the same place, but that doesn’t mean that there’s not a very strict theory around it. We know exactly the distributions that we should be expecting.In a similar way, if you have a non-deterministic model or you’re producing more complicated models, you should, before you ever consider actually putting things into production or having your models influence people, whether that’s decision makers in your company or your users, you should have a very good understanding of the range of results that you expect, whether that’s very repeatable results, or whether that’s a range of results, or a distribution. You should have that understanding because it’s very important, as you put those things into your workflows, that you have a very good understanding of how they should be behaving. Because we’re now at a point where the things that data scientists are producing, they’re not just reports for salespeople or something. We’re deciding which way your self-driving car should turn and we’re deciding whether you should or shouldn’t get an insurance policy and other things that are really directly user-impacting. I think having that responsibility and really taking ownership of that responsibility, having a little bit of empathy for the end user and the people that are consuming our models is a really good practice to get into.Kirill:\\tYeah, gotcha. So the tips are: build simple solutions to make them easier to deploy, maintain and get them faster to production, and create reproducible solutions so you kind of know what to expect. And that kind of ties into what you talk about in one of your YouTube videos. Like when your model, you expect it to do one thing, but it’s doing something else, people lose confidence in the reliability of the results that they’re getting.Daniel:\\tExactly, yeah.Kirill:\\tOkay, gotcha. Thanks a lot for that. Moving on, I wanted to touch a little bit on Go. I think through your videos I found out about this programming language and I never knew that it was such a huge community. Tell us a bit about Go. What is Go and how does it compare to programming languages like Python for data science?Daniel:\\tGo is a programming language that came out of Google. It initially was used for a lot of infrastructure projects, so listeners have probably heard of things like Docker or Kubernetes ETCD, maybe InfluxDB and some other things. And it’s been really useful in these projects, mainly because it’s a statically typed language, but it’s very simple and you can be very productive in Go. Engineers have found that they can be very productive in Go while maintaining kind of strict typing, the efficiency advantages of that and the integrity advantages of that, and it’s very easy to deploy it. So you can compile down a Go program into a single statically linked binary and just throw that wherever you want and it will behave exactly the same anywhere.If you don’t have Go installed, that’s fine. It will just run on any architecture you’re running on, so that makes it very, very easy to deploy. I would say, in general, people kind of cling onto it because they can be very productive in the language, it’s very simple and readable, easy to deploy. It just has a lot of nice built-in things. For example, with Python — I think one of the reasons why I initially came to Go is doing asynchronous programming in Python is challenge. You might have to pull in things like Python Twisted and things like that, which get kind of hairy. And in Go, you know, I think I learned Go and implemented my application in Go in the same amount of time as it took me to learn Python Twisted. So I think that’s a testament to just how productive you can be in the language.Kirill:\\tGotcha. And can you explain for us what is asynchronous programming?Daniel:\\tYeah. So, in modern times, we might have a bunch of micro-services in our organization, and maybe we’re consuming off of a queue, like RabbitMQ, or Kafka, or something, rather than pulling from a database or having very static files that we’re processing. So in those cases you need to be able to process requests or to process events concurrently. And by its nature, Python is single-threaded, so you can implement certain frameworks – I mentioned Twisted – that kind of help you with this problem, but Go just naturally has these primitives that allow you to handle concurrency very easily, so it’s very quick to implement those things. And this is being utilized also in packages. Like there’s a neural network package called Gorgonia, which utilizes these primitives in the modelling context, and then there’s packages like Gonum. Listeners are probably familiar with NumPy, but Gonum is kind of similar for the Go world, a lot of numerical computing stuff, and they utilize these primitives. It’s still a relatively new language, so there’s not like a really great consolidation and standardization of everything data science in Go. There’s great neural network stuff, there’s great modelling stuff, there’s great numerical computing stuff and there’s even data frames, there’s a kernel for Jupyter, but all of these things kind of — they’re scattered about the internet and they’re gradually kind of coming together, the people are starting to talk to one another and talk about “We need to decide on formats for this and that.” So some of those things are happening and there’s a lot of momentum in that area, but right now it’s definitely developing.Kirill:\\tOkay. Some very insightful thoughts. And just finishing up the conversation on Go, for somebody who’s never heard of Go before and who’s aspiring to be a data scientist and build a career in this space, at which point or in which circumstances would you recommend looking into learning Go?Daniel:\\tYeah, so I would say for a very, very new data scientist who’s maybe looking for their first position, pretty much all the data science positions will want you to know Python or R, so it’s probably not great for you to just learn Go and say, “I know Go.” But maybe data scientists that are already in companies or maybe looking for new positions, a lot of new companies are maybe implementing their entire stack in Go. And I’ve seen this countless times where people are building their applications on top of Kubernetes and these other infrastructure projects, and maybe a whole company’s stack is written in Go or a lot of it. That’s a really great case for you to say, “Now you want to build some data science applications on top of things. We want to build in some modelling, some analytics.” That’s a really great case where you can say, “Let me dip into this world of Go.” And I can definitely say that you will have a hard time. So there’s pretty much everything you need to do productive data science in the Go world. Like I said, some of it is still developing, but if you’re in that scenario, I would say, “Take a look at the Go world, see if it has what you need, and try out Go because I think you’ll be very pleased with it and your company will be very pleased that it fits very well within the direction they’re going and the engineering efforts in the organization.”Kirill:\\tGotcha. Thank you. And then, once you’ve done that, you can call yourself a ‘Gopher’, is that right?Daniel:\\tExactly, yeah. A Gopher, yeah. So if our listeners are interested, there is a website gopherdata.io. Hopefully someday this will be something like PyData is for Python, but right now it’s mostly just a site with links and some blog articles. But visit that site, there’s a link to resources there, and a really great listing of Go data science projects and different modelling packages and data frames and Jupyter and all that stuff is listed out there.Kirill:\\tGotcha. And the Go community is very big, right? Like thousands and thousands.Daniel:\\tIt is. There’s a public Slack channel now. If you just search for ‘Gopher Slack,’ there’s a public Slack team. Actually, I have it pulled up here right now. Let me get the last count. Right now there is 16,220 people in public Gopher Slack. I mean, 24 hours a day, it’s a very vibrant community. And those are the ones that are just on Gopher Slack.Kirill:\\tGotcha. Understood. Okay, thanks a lot for that excurse. And now I’d like to kind of move a bit to your background. Our listeners are always interested in understanding how people came to data science and your journey is a very interesting one because your journey started in physics, you have a PhD in physics.Again, in one of your YouTube videos you were talking about how you were analysing how electrons bump into atoms and things like that, and what’s going on there. And then you were starting or thinking of applying the same principles to data science. Walk us through a little bit of that. How did you start and how and why did you transition from what you were studying in your degree to data science?Daniel:\\tYeah, I started out in physics. Originally I wanted to be a research professor. I kind of got disillusioned by some things in academia and decided to go into industry. At the time I went into industry, this was six or seven years ago now, at that time, data science wasn’t quite as big as it is now, it existed for a while, but it wasn’t quite as hyped back then. And I really didn’t know what I could do in industry as a physicist. Kind of the urban myth amongst the grad students was that some people somehow ended up in finance and made a lot of money, but that was kind of like the only thing I knew about in industry.So I looked around for a while, and I got the first job with basically whoever would hire me. So I got a job with an IP firm as a ‘technical specialist,’ so basically what I did is I worked with a lot of data scientists and engineers and researchers kind of translating a lot of their math-y stuff into normal human speak for the lawyers. I felt very fortunate that I landed there because actually I saw just a ton of different stuff that was going on in industry all at once, so I was flooded with all of these really brilliant people doing all of these things at Google and at Wolfram and at other companies that were doing really interesting modelling, and a lot of them maybe had physics backgrounds or science backgrounds and I thought, “These people are doing amazing, interesting stuff. I should just do that. That sounds like a lot more fun.”So that’s kind of where I started exploring getting into data science. It seemed like my math and a little bit of computing background would play well with that field. So I started looking around for a first data science position. I did some kind of online trainings. I went through the Thinkful data science course, which I think existed at the time, and was paired with a mentor that helped me figure out what data scientists were doing in industry and the different techniques they were using. That was useful for me not so much in terms of learning new techniques, because actually a lot of these techniques I already knew. It was more just like learning jargon, learning processes that people wanted to hear in interviews. I think that’s one of the real problems with people coming out of academia, is, “Oh, I don’t understand what all this regression stuff you’re talking about is,” but then, “Oh, you’re just doing ordinary least squareds. I’ve done that like 3 million times in my grad school.”Figuring out all that jargon stuff can be daunting, but that really helped me with that and then I got a data scientist position with a start-up in Chicago. I worked there for a number of years. Then I got into consulting as a data scientist. I worked on a bunch of projects, eventually worked on a project with ‘The New York Times’ and ‘The Washington Post’ doing analysis of comment data and then finally ended up with Pachyderm, working on that project with them. So that’s kind of been my journey.Kirill:\\tThat’s really cool. And it’s interesting you mentioned that you had a data science mentor, because from your LinkedIn I can see that you yourself became a data science mentor at Thinkful in 2015. Can you tell us a bit more about that?Daniel:\\tYeah, I did. I think the program that they have has changed slightly since then, but basically the goal of that was to pair data scientists in industry one-to-one with students who are trying to get into data science to really give them a real world perspective on data science and also help them build up some of the skills in Python and modelling and SQL and statistics to get them prepared for hopefully a junior data science position. I did that for a number of years. I had a bunch of different students, and that was a really a great thing as well.This is one thing I recommend. Maybe some of your listeners are new data scientists, but they have some experience – I would highly recommend, whether it’s formal or not, that you develop some mentoring relationships where you’re able to pour into other people. Because like I said, it’s very daunting for people coming out of academia and other fields to kind of figure out these data science worlds. So, just giving them some pointers, maybe meeting with them once or meeting with them once a month or once a week – that can be a huge impact on their life.Kirill:\\tYeah. And I can attest to that, that through those processes, through those meetings and conversations, you also learn yourself. Like, you learn a lot for yourself and cover off the things that you thought you knew but you actually don’t or the person that you’re speaking with, they always have something to offer you back. Even if they don’t know about it, you learn a lot in the process.Daniel:\\tYeah, definitely. Everyone has a different background and the questions that every different person asks are very different. They make you think about problems in so many different ways that it’s really useful for you.Kirill:\\tAnd for somebody who is looking for a mentor, what would you say is the best way to go about that? Maybe Thinkful or maybe there’s other platforms or other tips that you can give to people who are looking for mentors in data science?Daniel:\\tYeah, I would say there’s definitely the online programs, Thinkful and a number of other online peer-to-peer mentorship programs. I would really recommend, maybe as a starting point for people, to get plugged into the local meet-up scene, find a good vibrant data science or machine learning meet-up in your area. You’ll go to like two or three meet-ups, maybe people just care about the pizza and beer that are there and not really about the topic, but then that third one that you go to, the discussion will be really good, people will be really into the topics, so get plugged into that particular one and just put yourself out there and start talking to the different people there, get plugged in locally. That’s maybe going to get you a good local mentorship from one or more people in that community, but it’s also going to really help you as far as developing connections in your local community as you’re trying to get into data science as well.Kirill:\\tOkay, gotcha. That’s been very helpful and I think a lot of people will find that useful in their aspirations for data science. Now I wanted to move onto a bit of an interesting question that I formed as we were going to the podcast. You moved from industry and from consulting into Pachyderm now and you are mostly developing these really cool solutions and products that people can use to make their life easier. But how do you feel about moving away from actually doing data science yourself? Like, in consulting and in the startup, you were actually performing data science to solve business problems. Are you doing any of that now or do you feel any nostalgia about that?Daniel:\\tYeah, that’s a really good question, actually. I think this question generally applies to — you know, there’s data science positions where maybe you work for a company that provides a data science problem and you’re working with a whole bunch of users but maybe you’re not actually involved in the different companies versus like being plugged in every week all the time to the specific problems of a single company. You know, it’s gone in different seasons for me.At first, like you said, I started out in the latter. I was plugged into these companies and I was working on maybe one specific project for a very long period of time and really trying to develop good solutions for that project or maybe a handful of them at a particular company. And I think there are certain advantages and certain learning that goes along with that as far as really understanding a problem very deeply and understanding specific types of data very deeply.And then there is advantages to the former. If you’re working with a lot of different users, like I am now — like, yesterday I was working with image data and today I’m working with log data — it’s a lot of context switching, but you learn a lot about the different scenarios that people are actually dealing with across the landscape of data science.Maybe there’s some bit of nostalgia, but I think for me it’s a different season and it’s a different type of learning. I don’t doubt that later on in my career, I will probably switch back to a season of very intense focus on a small set of problems relevant to a certain company and then I’ll probably fluctuate back. I think for me, that kind of flow back and forth is good because it triggers different parts of my mind and helps me learn different things and it also gives me diversity in what I’m working on. So, yeah, I think it’s just kind of a back and forth for me.Kirill:\\tOkay. And for somebody who is starting into data science, like completely new or who just wants to change their current career and be more focused on data science and move into data science from a different type of world, maybe it’s BI world, or a database role, or statistics, or even arts, anything, the question I have is, what’s the best place for them to start? Should it be something that’s heavily focused on a specific company or on a specific type of work, like you said you had previously, or should it be something that’s more diverse that gives them exposure to more different tools and more different scenarios like what you’re doing now?Daniel:\\tI would say probably the former. I would recommend that people starting out, they do get plugged into a company that is working on a specific handful of problems. I think that for me it was really useful to get plugged in to a start-up where I was initially part of just a two-person data team or maybe it’s like a three or four-person data team, and I think those scenarios are really good for people starting out because, by your very nature in those positions, even though you’re focused on the specific problems at a specific company, you have to wear a lot of different hats. So you’re going to be forced to deploy some things yourself, you’re going to be forced to deal with the data pipelines, you’re going to be forced to learn some ETL, you’re going to be forced to learn database stuff, all of that in addition to whatever statistical or modelling analysis that you’re doing.So in that scenario, for a new person, I think those are really the essential things that you really want to build up. You want to become a well-rounded person that’s comfortable with the end-to-end data process. Probably you’re never going to become the world’s greatest expert on MongoDB or something, but it gives you a little bit of confidence to where if you go into another position or something and maybe it’s not Mongo in that case and they say, like, “Hey, we’re using Cassandra,” and you say, “Oh, I’ve dealt with different databases before. I’ve dealt with different infrastructure. I have at least an exposure that makes me a little bit more comfortable jumping into this scenario.” I think that’s what’s important. And then later on, it’s fine to jump into those consulting and very diverse sets of positions, but I think also on those positions you want to have that confidence in a variety of tooling first, because you’re going to be thrown into a lot of different scenarios and you have to really quickly pick up on those different scenarios.Kirill:\\tGotcha. And I’m really glad you mentioned that because those who are following me for a while, they’ll know that I have a different opinion on that question. I personally always recommend for people to start in consulting if they’re getting into data science, because that’s the path I took. Yes, I did some work before that, but my biggest learnings were when I was at Deloitte for two years, and I was just thrown into different tools, into different industries, into different scenarios. And as you correctly pointed out, you don’t get the opportunity to develop that all-roundedness of a data science approach, but on the other hand you get an exposure and you see all these different areas of data science and I feel you understand better where your career might go. At the same time, I totally respect your opinion on that. I think it’s just two different approaches to how you would go about starting into data science.Daniel:\\tYeah. And to follow up on that, I think you’re very right. I wouldn’t necessarily disagree with that. I think the important thing is that when you’re starting out you’re in a scenario where you’re learning a lot about a diverse set of things. Like you said, in the consulting world, you’re going to be thrown into a lot of scenarios. You’re going to be forced to learn in kind of a smaller team environment. Like I mentioned, you’re going to be wearing a lot of different hats so you’re going to be forced to learn.I think the scenario that is maybe different than both of these is like a very large data science organization where you’re thrown onto a team and really your job is to just produce the next time series model or something like that. And you don’t get quite an overview, like you would in either one of these other two scenarios. Big companies deal with that in various ways, like having a boot camp sort of program or on-boarding sort of program, and some of those work very well. Yeah, that was my comment there, I guess. (Laughs)Kirill:\\tGotcha. And I agree, whichever approach you take, the last thing you want to get is pigeonholed, right? You won’t learn anything if you’re just doing the same thing.Daniel:\\tYeah, that’s a great way to put it.Kirill:\\tOkay, cool. Thanks a lot for that. I’ve got some questions about your experience with data science, kind of like rapid-fire, but totally feel free to go in-depth on them. Are you ready for this?Daniel:\\tYeah.Kirill:\\tOkay, let’s do this. We already talked about the tools a little bit, so I won’t ask that one about what tools you use on the daily basis. Next one is, what’s the biggest challenge you’ve ever had as a data scientist?Daniel:\\tI would say that probably the biggest challenge that I faced is more mindset-related than tooling or modelling-related. When I was first starting out as a data scientist, as often is the case with data scientists, I was working very closely with the CEO and COO of the company that I was working with. There is very much this mindset of, like, “Let’s be data-driven,” and also there was the mindset of we have come to this scenario and “Wouldn’t it be cool if we could predict this?” And then in my curiosity I would say, “Yeah, that would be really cool.” As a scientist with curiosity, I would say that would be really cool and immediately I would jump into two months of work, predict that, I would predict it and then I would bring it to the CEO and COO and they would say, “Oh, it’s cool that we predicted that.” And then everybody sat around and was kind of like, “What do we do now?” And there was nothing we could do with that prediction, let’s say.I think the biggest challenge for me has been to kind of rein in that mindset and really focus when a new problem comes up on asking the right questions when I’m starting out a project, you know, “If I produce this result, will it have actionable consequences? Will it produce value within a company? What form do I need to put this result in such that it produces that value?” I think that’s been the biggest challenge for me.Kirill:\\tGotcha. Okay, that’s a really cool one. I like that. Next one is: What’s a recent win that you can share with us that you had in your career as a data scientist, something that you’re proud of?Daniel:\\tGood question. I think that on the Pachyderm side, we’re seeing a bunch of wins with our users in actually proving out larger production scale data, like data scientists actually being able to produce solutions that scale to this production-sized data. So on that side, I think it’s really great and valuable just to see users actually using what you’re producing in a way that makes them happy. That’s extremely fulfilling and I think that’s a big win.Also, like you said, I’ve been talking at a bunch of places and when I first started talking about some of these workflow things and reproducibility and Docker and Go and other things, I was a little bit of the odd man out, no one really knew what I was talking about. And now — we met at ODSC — and this isn’t a win on my part, I would say, because I didn’t do this, but through the efforts of many people talking about these things, you know, people are talking about these issues now and that just really excites me. People are talking about how do we solve these problems of reproducibility and workflows.Kirill:\\tGotcha. Yeah, that’s really cool. And just speaking of Pachyderm, do you know why the logo is an elephant?Daniel:\\tYeah, so “pachyderm” is the word that is now a defunct classification of animals. At some point, people thought it would be great to classify animals based on the thickness of their skin, which turns out to be an incredibly poor way to classify animals, but pachyderm was like thick-skinned animals, which included elephants and hippos and that sort of thing. So in one way, it’s kind of a poke at the Hadoop ecosystem, whose logo is an elephant, but it’s also in having a data platform or a distributed processing platform, it’s probably a good thing to be thick-skinned and robust, so that’s kind of the dual meaning.Kirill:\\tGotcha. Thanks for that. And you may have answered this question in your previous answer about your recent win, but nevertheless I’ll still ask: What is your one most favourite thing about being a data scientist?Daniel:\\tFor me, probably—when I was in the academic world, I really thrived on the creativity of the research process. I loved it when there was an elegant and creative solution to a problem. In data science you not only get that, but in the research world, oftentimes the end goal is you write a paper and then it’s published and then maybe nothing comes of it.But in the data science world, you get to have that satisfaction of creating a creative elegant solution but then in addition, you get the satisfaction of seeing – if you actually implement it – value being produced very immediately from that solution within the company either for your users or internally. And I think that dual benefit is really what is my favourite thing.Kirill:\\tFantastic. I can totally attest to that. It’s just super great that you get so many intrinsic motivators in data science to continue doing the work you’re doing and wake up in the morning. Okay, question of the day: Where do you think the field of data science is going? From everything you know, from all the things you see, from all the conferences you go to, where do you think this field is going and what should our listeners prepare for to be ready for the future?Daniel:\\tOne thing that we’re starting to see is data science influencing every single part of a business. Even if you’re not a machine learning company, you’re thinking about data science in terms of your infrastructure, in terms of your sales pipeline, in terms of your marketing, in terms of your recommendations for your users. It’s impacting every single part of the business. That’s one thing I see.The other thing that I really see right now is — traditionally, for the past number of years, we’ve seen one side of your organization be data engineering, developing pipelines, doing streaming and other things, and then one side of your organization being data science, doing analysis and modelling and that sort of thing. In my mind, one trend that I see in the industry is really a pressure to push those sides together. You know, I might be a little bit biased because Pachyderm sits in the in-between of those two sides, but I think in general – and this was displayed at ODSC because everywhere you turn there was another data platform solution or a solution to help data scientists deal with infrastructure or deal with their GPUs or whatever it is – I think there is a pressure to push these two sides together and I hope that this will end up with a scenario where data scientists will have real ownership over not only the solutions that they’re creating, but how those are implemented within an organization so that there’s this seamless kind of flow between data science and solutions that are actually impacting business very quickly.Kirill:\\tGotcha. Thank you very much for that. That’s a great insight, meaning that if this is a new area of data science that’s evolving, people should start looking into that early and start thinking about it, kind of preparing and anticipating the future. If that’s going to be something that’s super big in two or three years, why not start learning that stuff now? Why not start getting into it? And then when it comes, you are ahead of the curve and you get the good jobs and you get the high salary and you’re leading that industry rather than just following the trend.Daniel:\\tExactly.Kirill:\\tCool. Thank you so much, Daniel, for coming on the show. It’s been really great hearing first-hand from you about all this, all these insights. How can our listeners contact you or follow you or find you or find out which conferences you’re presenting at if they would like to learn more from you?Daniel:\\tSure. So, I’m @dwhitena on Twitter. So you can find me there. Additionally, if you join the public Pachyderm Slack channel, there’s one of those, you can go to pachyderm.io, there’s a link to it. Or if you’re on the Gopher Slack channel, I’m also dwhitena on those Slack channels so you can message me there. I’m dwhitena on GitHub, you can find out what projects I’m working on there. There’s a repo under there called ‘slides’. I should probably update the name, but for now it’s called ‘slides’ and under the readme there, it does list out where I’m going to be at different conferences coming up this year.Finally, like I mentioned, there’s this Gopher data site if you’re interested in – GoDataScience. There’s a bunch of good resources there and links how to get involved in that community. So there’s a few different ways.Kirill:\\tGotcha. And you also have a blog, datadan.io.Daniel:\\tOh, yeah. Thanks for the reminder. I knew I would miss something. So if you go to datadan.io, I have a blog there where I have a bunch of articles and I also write for the Pachyderm blog and a couple of other places like Intel and YC and some others.Kirill:\\tAnd is it okay for people to connect with you on LinkedIn?Daniel:\\tDefinitely, please do. I just ask that, if I don’t know you, shoot me a message. That way I kind of know the context of what you want to talk about and we can connect.Kirill:\\tGotcha. Just to summarize it for everybody, because you just listed a huge amount of resources, the best place to go, I think, is datadan.io because all of the links are listed on the left – Twitter, GitHub, LinkedIn. You won’t miss anything if you just go there and you’ll see it on the left right away. Okay, thank you very much. I just have one more question for you. What is one book that you can recommend to our listeners for them to become better data scientists?Daniel:\\tI thought about this a while, and there’s a bunch of great books out there. Actually, there’s a bunch of great free books out there, but I think one thing that I would recommend, and I really think that people should take a look at this, it’s called “Rules of Machine Learning.” It’s actually not even a book, it’s just a document that’s online. So if you search for “rules of machine learning Google” or something, this is a document that Martin Zinkevich put out. He’s a research engineer at Google, and the premise is that these are the rules of machine learning or best practices for ML engineering at Google and it’s kind of things that they emphasize there that have been distilled down for a general audience. I would highly recommend those. It talks about your first pipeline. It talks about things that I mentioned: choose a simple, observable and attributable metric, interpretable models. It talks about feature engineering and skewed distributions, complex models. I think it’s a really great resource with a bunch of nuggets of truth in there.Kirill:\\tFantastic. Thank you very much for that. So, that’s “Rules of Machine Learning” by Martin Zinkevich from Google. And on that note, thank you so much, Daniel, for coming onto the podcast and sharing all these valuable insights with our listeners. I think it was great and I think a lot of people will learn so much from what you shared today. Thank you so much.Daniel:\\tExcellent. Thank you.Kirill:\\tSo there you have it. That was Daniel Whitenack of Pachyderm and a very renowned speaker on data science, so if you’re interested to hear more from Daniel, definitely check out his upcoming speaking events, which you can see on GitHub or through his blog. You can find GitHub through his blog and find more on where he’s speaking.In terms of today’s podcast, I hope you enjoyed it. For me personally, the best takeaway or the most valuable takeaway — well, there was a lot of great things mentioned, but probably the most valuable for me was the data science workflows and how that is becoming a growing area of data science as data science is maturing. We all know this is happening. Like, seven or ten years ago, data science wasn’t even a popular thing. People weren’t talking about it as much and you wouldn’t be able to get a degree in data science. But now it’s becoming a field on its own, alongside things like physics, chemistry, biology. It’s being taught at universities and companies are more and more applying data science and this field is slowly maturing. And as that is happening, it is essential, it makes sense, that data science workflows are going to become more and more popular.So it’s a great insight that Daniel shared with us. If you’re looking to build a career in data science, then looking at data science workflows could be a valuable thing, because even though they might not be as popular and as pronounced right now, in two or three or five years’ time, data science workflows are going to be an essential skill. Most likely they’re going to be an essential skill that you will need to have as a data scientist. So, as they say in ice hockey, you could be skating to the puck. You know where that puck, that little black thing they shoot around in ice hockey is going to be, so you’re skating towards the puck to catch it in advance, you anticipate where it’s going to be. You could be doing the same thing here. You could be skating to a puck and learning about data science workflows, so when it does come into play, it becomes big in the world, then you already know these things or a thing or two about data science workflows.So that’s what we talked about today and of course, if you’d like to connect with Daniel, check out his blog. Once again, it is datadan.io. You can get all of the links to his other profiles there as well. Also, we’ll put links to all of the resources for today into the show notes which you can find at www.superdatascience.com/61. And if you enjoyed today’s podcast and you’re listening on iTunes, then take a minute to rate this show and help us spread the word about data science into the world.And on that note, thank you so much for being here. I really appreciate you taking the time and listening to this podcast. I can’t wait to see you next time. And until then, happy analyzing.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds['text_episode'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f558d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e74f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c007f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ead9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds[sds['context_episode'] == 'Data Science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1e37edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Kirill:\\tThis is FiveMinuteFriday, Proximity.\\nKirill:\\tWelcome back to the SuperDataScience podcast ladies and gentlemen. We've got my dear friend in this part, Hadelin here with you today.\\nHadelin:\\tHi Guys. How are you?\\nKirill:\\tSo we're still in Slovenia it's our last day here.\\nHadelin:\\tYes. Sadly it's our last day, but fortunately it's a beautiful sunny day today.\\nKirill:\\tYeah, it's fantastic. I was telling you today morning I found something better than coffee.\\nHadelin:\\tAh, yes. Wow.\\nKirill:\\tYeah. I went for a walk, at 9:00 AM, was coming back, picked up some grass to feed the cows, leaned over and touched the fence with my leg. Like this little tiny fence. I always wondered why the cows don't go over it. And I got the biggest electric shock ever.\\nHadelin:\\tWell, are you going to do that every morning?\\nKirill:\\tPotentially, but it feels like your heart freezes, your whole body is as if you get like a big massive scare, but also like, I don't know, it is just such a strange feeling and you got a rush of energy through your body and I looked it up just now. It was like 7,000 to 8,000 volts.\\nHadelin:\\tWow. And it can go up to 50,000 volts.\\nKirill:\\tCrazy, right?\\nHadelin:\\tYes. So is that better than coffee?\\nKirill:\\tYeah, definitely better than coffee. So much energy like afterwards I was so energized and happy. It's good.\\nHadelin:\\tWell, I'm not sure if I'm going to try it, but I love coffee anyway.\\nKirill:\\tYeah. All right. So what are we talking about today?\\nHadelin:\\tAlright, so today we're talking about proximity and the fact that, proximity is power.\\nKirill:\\tOne of the three core principles by Tony Robbins for success in business.\\nHadelin:\\tYes. What are the other two?\\nKirill:\\tI remember one is momentum.\\nHadelin:\\tYes. And the other one is decisiveness.\\nKirill:\\tDecisiveness. So momentum, proximity is power or proximity and decisiveness.\\nHadelin:\\tWe can talk about them in some other episodes.\\nKirill:\\tYes. The reason we're talking about proximity today is very correlated with where we're actually going and what's going to be happening in the next 24 hours. So we have this project that we're working on. Which, by the way, if you're not up to date yet, in addition to having courses which have been taken by almost a million students, Hadelin and I have a consulting business called Bluelife AI, where we create custom AI solutions for businesses to empower them to leverage artificial intelligence at no upfront cost.\\nHadelin:\\tYes. And the applications like these can be to make massive profits, to increase profitability, to increase the efficiency and to innovate, to solve problems. Many things.\\nKirill:\\tCorrect. And what is happening today is at Bluelife, we have this one project that we're working on where there is a bit of a crisis and things need to be urgently fixed. And our team is, as you know us from our work, our team is all over the world. We have people, in all our businesses, we have people across multiple different countries. There's no centralized location. There's no office. Everybody works from home or from their favorite coffee shop or from a coworking space, wherever they want to. And so in Bluelife AI as well, our team is decentralized. They're all over the place. And so, what are we doing to fix this crisis?\\nHadelin:\\tWell guys, remember in a previous episode we talked about our core skills, our core talent, if I may call them this way. And Kirill's core skill or talent was to have this incredibly powerful inspiration that he can transfer to others. And so when you have a team that is working remotely with different members, working in different countries, and it's hard to meet physically, well, of course at some point, each member is going to need some inspiration. Each member is going to need some coaching or some physical contact, physical connection. So that's exactly what this is about. Not only this is about this, you know, Kirill is going to spread and use his inspiring power on the team. But also this is about brainstorming where we can generate better ideas when we're physically together and,you know, solve the situation.\\nKirill:\\tExactly. And so what we're doing, is that the team, one of the team leads or the team lead for this project was currently in... Where was he?\\nHadelin:\\tFrance.\\nKirill:\\tNo, Cyprus or Crete.\\nHadelin:\\tOh, Crete, you're right.\\nKirill:\\tIn Crete. I keep confusing.\\nHadelin:\\tHe's based in France, but he was actually on holidays in Crete.\\nKirill:\\tAnd so, he was about to fly back to Paris and yes, we were talking about the project. We tried to see if we can solve the problem online as we usually do, but this is quite a big issue. So we were like, okay, no, change your flights. Like this was all last minute, he was about to get on the flight already.\\nHadelin:\\tRight after the call he just directly went to the airport and flew to Venice.\\nKirill:\\tYeah. So we changed, we're going to change his flights, instead of going to Paris he is going to Venice. And then from there he is taking a train to Trieste, or Trieste, I don't know.\\nHadelin:\\tTrieste.\\nKirill:\\tIt's a city in Italy on the very east side of Italy near Slovenia, actually, it's about a two hour train. So he was already in Venice last night. Now he's taking a train to Trieste and we're getting in the car and driving down Trieste and we're meeting up with him there. We're going to be brainstorming on a solution, which we will find in today's afternoon and we'll have dinner. And then, he'll fly back to Paris tomorrow morning.\\nHadelin:\\tHe'll fly back to Paris with a new mindset, a new energy, a new belief for this project.\\nKirill:\\tYes. And a massive action plan of what to do.\\nHadelin:\\tA massive action plan. That's right. That's also so important.\\nKirill:\\tExactly. And so what I guess the conclusion of all this is that, proximity is power in many ways. If you want to learn from people, you need to get yourself near them. If you want to make people successful, you need to get yourself near them. If you want to complete projects and solve crises and do get stuff done efficiently and fast, you need to get yourself near. We live in a digital world where every everything can be done online. Don't forget that actually when you're in person next to someone, it's a completely different story. And Hadelin and I can both attest, we worked for how long together before we met?\\nHadelin:\\tThree years.\\nKirill:\\tNo, no. Like before we met in person, we worked like eight months or something.\\nHadelin:\\tOh, yes.\\nKirill:\\tYeah. So we started working online together, for eight months we worked together. It was fantastic. We're getting things done. But then when we met for the first time, boom, new level.\\nHadelin:\\tThat's true.\\nKirill:\\tAbsolute new level.\\nHadelin:\\tYes. And so, we gave this example of our employee who's going to meet us and leverage the proximity for ourselves. But, it's the same for us. We go to conferences to meet high level people, who have much more experience than us and much more knowledge and much more, well power actually and from them, we learn a lot. And we learn so much that it really is almost a breakthrough each time.\\nKirill:\\tExactly. So you got to think about who in your life can you get more proximity to who should you get more proximity to. It might be professionally like a mentor or a coach or might be in a personal life. Maybe you're not spending enough time with your spouse, maybe your parents or maybe your kids that need more proximity from you. Maybe your friends, maybe a certain location needs more proximity for you to get better inspired or get things done there. What else could you need proximity from person or a person needs their proximity?\\nHadelin:\\tWell, it's not only about physical contact, but it's also about learning from the experience of others. So, well, you know, if we do this exercise again of listing all the possible ideas of proximity, I am sure we would end up with a hundred ones. So you have conferences, meetups. Now we have great websites like meetup.com when you can, meet up with some people who have the same interest or vision as you. You also have workshops. You also have universities. You know, you can take some courses, part-time courses in a university. Well you have many ideas for proximity.\\nKirill:\\tYeah. And I thought of another one, building your network, right? Great to meet people on Linkedin and get them in your network. But you also want to then find the ones that are local, close to you and invite them for coffee and say: Hey, if you have 10 minutes on Friday, I'll shout you a coffee. And that's, even though you don't know where this is going to go, you're not after a specific outcome. You're not maybe looking for a job right now. Just do that. And if you do that like five times a month for two, three years, you're going to end up with a massive network of people who are you very close with. And when you do need a job or when you do want to upgrade, or you do want to help somebody else get a job, or you want to start a project, build a business or whatever, you have some questions you need to solve, you will have those connections because you leverage this power of proximity that now you know these people very well in person. You've built these connections.\\nHadelin:\\tVery true. For example, I'm on a group, Facebook group, Linkedin group, and each month I get like three, four, or even five invitations to events where I can meet people, discuss, have drinks, and yes, by doing this, well, you increase your network considerably.\\nKirill:\\tFantastic. So there you go. Proximity is power. Hope you guys found this useful. And we'll see you next time.\\nHadelin:\\tSee you guys.\\nKirill:\\tUntill next time, happy analyzing.\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds['text_episode'].loc[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49378a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0908ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds[sds['length_episode'] <= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9cef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds[sds['episode_day'] == 'Friday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc68516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = BeautifulSoup(text, 'lxml').get_text(separator=' ', strip=True)\n",
    "\n",
    "#text = re.findall(r'[a-z]+', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37950fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['guest_info'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e352a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c916ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6418ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sds['length_episode']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31750a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe469e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['length_episode'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde3fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds['context_episode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec256e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
